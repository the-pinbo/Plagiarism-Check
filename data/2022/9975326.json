{
    "abstract": "Online reviews influence consumers\u2019 purchasing decisions. However, identifying fake online reviews automatically remains a complex problem, and current detection approaches are inefficient in preventing the spread of fake reviews. The literature on fake reviews detection lacks a comprehensive and interpretable theory-based model with high performance, which enables us to understand the phenomenon ...",
    "articleNumber": "9975326",
    "articleTitle": "Fake Online Reviews: A Unified Detection Model Using Deception Theories",
    "authors": [
        {
            "preferredName": "Mujahed Abdulqader",
            "normalizedName": "M. Abdulqader",
            "firstName": "Mujahed",
            "lastName": "Abdulqader",
            "searchablePreferredName": "Mujahed Abdulqader"
        },
        {
            "preferredName": "Abdallah Namoun",
            "normalizedName": "A. Namoun",
            "firstName": "Abdallah",
            "lastName": "Namoun",
            "searchablePreferredName": "Abdallah Namoun"
        },
        {
            "preferredName": "Yazed Alsaawy",
            "normalizedName": "Y. Alsaawy",
            "firstName": "Yazed",
            "lastName": "Alsaawy",
            "searchablePreferredName": "Yazed Alsaawy"
        }
    ],
    "doi": "10.1109/ACCESS.2022.3227631",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9975326/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION I.</div><h2>Introduction</h2></div><p>People increasingly use online review applications to convey their thoughts, on various items, such as products and local companies <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\">[1]</a>. These reviews tell consumers about the experiences of others using certain items. These items have a quality that can only be judged after usage <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a>. Online reviews heavily influence consumers\u2019 purchasing decisions. Unfortunately, some companies create fake reviews to influence consumers\u2019 impressions of their or their competitors\u2019 goods <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>.</p><p>Fake online reviews have several characteristics. First, they are described as online reviews written by people based on their imaginations without actual experience <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\">[4]</a>. Second, fake reviews have a core characteristic which is their ability to mislead consumers <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>. Third, there are two main ways to produce fake reviews, namely: human-generated and computer-generated way <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>. Fourth, fake reviews can be written by different types of consumers, online merchants, or platforms. Fifth, fake reviews are multilingual <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>, <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a> and come from different cultures. Sixth, reading the text of online reviews is insufficient for humans to differentiate between truthful and fake reviews <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a>.</p><p>Consequently, determining how to automatically identify inaccurate and fraudulent fake reviews is a difficult problem. The challenge of identifying fake reviews is referred to as the problem of fake review detection <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\">[10]</a>. Current detection approaches are inefficient in preventing the spread of fake reviews because fraudulent users routinely submit fake reviews with new features to avoid detection <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>.</p><p>When fraudulent users employ basic deceptive techniques, the traditional detection methods fail to distinguish between normal and fraudulent users. For example, they may mimic regular users by posting both truthful and fake reviews <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>. Therefore, an accurate fake reviews detection model is required.</p><p>When developing a model to detect fake reviews that use features from deception theories, feature engineering plays a significant role to identify, manipulate, select and extract the most valuable features of fake reviews from raw data. This helps simplify the model and achieve better results in detecting deceptive behavior in fake reviews.</p><p>Consumer purchasing decisions, product reputations, sales volumes, and merchant profits are all influenced by reviews <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_1\">[12]</a>, <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_1\">[13]</a>, <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_1\">[14]</a>. More than 80% of shoppers in the United States read Internet reviews before buying a product <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a>. Only a 1% increase in hotel rating scores might result in a 2.6% increase in sales per room <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\">[15]</a>. Restaurants sell 19% more frequently when given an extra half-star score <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_1\">[16]</a>. A one-star decrease in a company\u2019s Yelp rating results in a 5%\u20139% decrease in revenue <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\">[17]</a>. The percentage of fake reviews can reach up to 33.3% <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a>. Approximately 10.3% of online products were subjected to review manipulation <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a>.</p><p>Recently, Amazon observed a significant increase in unverified reviews (reviews lacking the \u201cverified purchaser\u201d label) <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\">[20]</a>. In March 2019, 99.6% of 1.8 million unverified ratings were five stars. In comparison, from 2017 to 2018, there were an average of 300 thousand unverified reviews every month, with only 75% of them being 5-star <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\">[20]</a>.</p><p>While fake reviews have a significant impact on e-commerce, detecting them is crucial, but complicated. Detection of fake reviews is easy when the user shows apparent suspicious behavior, such as leaving reviews every day using different devices, because normal users do not post reviews daily and do not use various devices to do so <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_1\">[21]</a>. However, this problem has become complicated because of the deception strategies. Fraudulent users change their techniques to avoid detection systems <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_1\">[21]</a>. Some of them attempt to appear normal by including links to well-known entities <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>. Some of them pay people to participate in spam activities through crowdsourcing platforms <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_1\">[22]</a>. Alternatively, they generate fake reviews using deep learning models <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_1\">[23]</a>. For example, on Twitter, they discovered that some fake followers avoided detection systems by writing reviews or following real people <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>.</p><p>Although almost all studies developing new algorithms and methods to detect fake reviews claim that their algorithms have a high level of accuracy, the frequency of fake reviews continues to rise <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>. Therefore, continuing to develop approaches or algorithms for detecting fake reviews is a priority. To achieve this, we need to investigate the features of fake reviews to distinguish between truthful and fake reviews accurately <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>.</p><p>New features can be extracted from the data to focus on deception in the behavior of fraudulent users, especially when the detection methods are limited by the available attributes in the data of the user. We cannot listen to users\u2019 voices, see facial reactions, or observe body language. Instead, we can only deal with their access to the platform, written reviews, and ratings with time and frequency dimensions.</p><p>Consumers have a trust issue when it comes to online reviews; they must read and compare reviews carefully <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>. On the one hand, reviews are incredibly beneficial because they provide important information that helps consumers in the purchase decision to spend their money on high-quality items and services <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>. In addition, online sellers are highly affected by fake reviews, which can damage their reputations and businesses.</p><p>Fake reviews give a negative view to consumers, which damages platforms\u2019 reputations and reduces the number of consumers <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>. Platforms that allow users to write reviews need to improve their fake reviews detection systems regularly, which is critical for maintaining the platforms\u2019 trustworthiness and providing a high-quality user experience for consumers seeking information <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>.</p><p>The problem of fake reviews requires continuous research to deeply understand it and find effective solutions, while fraudulent users continuously change their techniques to avoid detection systems. This issue is still increasing and affecting platforms, consumers, sellers, and researchers, and it still requires considerable effort to analyze, solve, and reduce the consequences. Consumers need truthful experience information for online products, whereas sellers need to maintain their reputations and businesses. Platforms need to provide trustworthiness for consumers and sellers and guarantee fair competition. Therefore, detecting and cleaning fake reviews from platforms with high accuracy will guarantee more trustworthy and fair platforms for consumers and sellers.</p><p>We can summarize the challenges and limitations of fake online reviews detection as follows: First, one of the most important difficulties presented by fake reviews is that even expert customers cannot spot them accurately, in addition to their exponentially growing number. As a result, there are few labeled datasets to be used as the gold standard for training classification methods <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>, <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_1\">[24]</a>. Second, reviews are written in many languages <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>, <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a>, with most studies focusing on English. Third, a class imbalance can be observed in several datasets <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a>, where the proportion of reviews labeled as fake is tiny compared to reviews labeled as truthful <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_1\">[25]</a>. Fourth, the limitation in the number of available data attributes in the public datasets <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>. Some attributes are required, such as the email address, sign-in location, and IP address <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>. Fifth, the problem of concept drift which is the continuous change in the features of online reviews over time <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_1\">[26]</a>. One of the reasons for concept drift is that once fake reviewers learn fake detection criteria, they adjust their behavior to appear normal, making the criteria useless <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>. Sixth, there is a lack of interpretability in deep-learning-based models for fake reviews detection. Regardless of their high performance, they are still untrusted because of their varying performance from one dataset to another <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a>. The study of interpretability can be carried out by focusing on fundamental theories <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a>.</p><p>We still need an interpretable trustful model with high performance for fake reviews detection, which is theory-based and enables us to understand the phenomenon from a psychological perspective using the data of the reviewer\u2019s behavior and the review\u2019s content. The model needs to be interpretable in a deeper manner so that humans can understand the reason for the model\u2019s decision and its psychological interpretation.</p><p>Our model covers the most well-known deception theories from two different perspectives in psychology to analyze suspected content and behavior. Unlike previous works that considered a limited number of deception theories, focused only on the old perspective in deception theories, had unclear mapping between theoretical constructs and practical features, focused on the content of reviews and neglected the behavioral side, or were built without considering any fundamental theories.</p><p>Our research objectives (ROs) include:\n<ul style=\"list-style-type:disc\"><li><p><b>RO1</b>: Synthesize deception aspects from deception theories to formalize a theoretical model of fake reviews detection.</p></li><li><p><b>RO2</b>: Specify deception features that can be engineered from the available attributes in open-source datasets.</p></li><li><p><b>RO3</b>: Develop a feasible fake online reviews detection model based on the selected deception features.</p></li><li><p><b>RO4</b>: Apply feature extraction methods to retrieve the features related to deception aspects from the available attributes in online reviews.</p></li><li><p><b>RO5</b>: Test the performance of our unified deception-based fake reviews detection model.</p></li></ul> Accordingly, our research questions (RQs) are:\n<ul style=\"list-style-type:disc\"><li><p><b>RQ1</b>: What deception aspects from deception theories should be considered to capture the behavior of fraudulent online customers?</p></li><li><p><b>RQ2</b>: What are the possible features that can be extracted from the available attributes in open-source customer reviews to reflect the relevant aspects of deceptive behavior?</p></li><li><p><b>RQ3</b>: What techniques can be used to extract the features related to deception aspects from the available attributes in user data?</p></li><li><p><b>RQ4</b>: Can the deception-based fake reviews detection model improve the performance of fake reviews detection?</p></li></ul></p><p>Several important research contributions are made through this work:\n<ul style=\"list-style-type:disc\"><li><p>First, this is the first time that a fake reviews detection model is built based on synthesizing the most popular deception theories in psychology from both perspectives: the dominant perspective (cue theories) and the new perspective (non-cue theories), integrating the strengths of these two perspectives.</p></li><li><p>Second, this study provides unified terms to describe deception constructs and clear mapping between deception theories and the selected verbal and non-verbal features for fake reviews detection while considering fake reviews as a shape of deception.</p></li><li><p>Third, this study proposes a pure theory-based model for fake reviews detection that shows high performance regardless of the classification algorithm. The model incorporates the most relevant verbal and non-verbal features and avoids collecting all existing features or random feature selection from the literature.</p></li><li><p>Fourth, contrary to the literature on fake reviews detection, which focuses mainly on verbal features, our study proves that the performance of the fake reviews detection model can be improved by balancing this focus with more non-verbal features rather than focusing on one type of features only.</p></li><li><p>Fifth, our model outperformed most of the well-known state-of-the-art fake review detection models with a high degree of interpretability, low complexity, and high performance.</p></li></ul></p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION II.</div><h2>Related Works</h2></div><p>Studies on the fake reviews problem have varied in focus. Some studies have focused on determining the reasons for writing fake reviews. Some studies have focused on firms and people who have a higher possibility of posting fake reviews. Some studies have focused on techniques for writing fake reviews. Some studies have focused on the impacts on the growth of online reviews or on various stakeholders. Some studies have focused on the impacts on the market or society as a whole. Our interest lies in studies that focus on features and detection methods of fake reviews.</p><div class=\"section_2\" id=\"sec2a\"><h3>A. Ml/Dl-Based Fake Reviews Detection Methods</h3><p>Machine learning (ML) is an integral part of detecting fake reviews which has been considered as a classification problem. There are three types of machine learning: supervised, unsupervised, and semi-supervised.</p><p>The commonly used supervised learning methods include support vector machines (SVM) <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2a\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2a\">[24]</a>, <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2a\">[28]</a>, <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2a\">[29]</a>, <a ref-type=\"bibr\" anchor=\"ref37\" id=\"context_ref_37_2a\">[37]</a>, <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_2a\">[47]</a>, <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_2a\">[48]</a>, <a ref-type=\"bibr\" anchor=\"ref49\" id=\"context_ref_49_2a\">[49]</a>, <a ref-type=\"bibr\" anchor=\"ref50\" id=\"context_ref_50_2a\">[50]</a>, <a ref-type=\"bibr\" anchor=\"ref51\" id=\"context_ref_51_2a\">[51]</a>, <a ref-type=\"bibr\" anchor=\"ref52\" id=\"context_ref_52_2a\">[52]</a>, <a ref-type=\"bibr\" anchor=\"ref53\" id=\"context_ref_53_2a\">[53]</a>, logistic regression (LR) <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_2a\">[30]</a>, <a ref-type=\"bibr\" anchor=\"ref31\" id=\"context_ref_31_2a\">[31]</a>, <a ref-type=\"bibr\" anchor=\"ref32\" id=\"context_ref_32_2a\">[32]</a>, <a ref-type=\"bibr\" anchor=\"ref53\" id=\"context_ref_53_2a\">[53]</a>, Na\u00efve Bayes (NB) <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2a\">[28]</a>, <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2a\">[29]</a>, <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_2a\">[33]</a>, <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_2a\">[34]</a>, <a ref-type=\"bibr\" anchor=\"ref35\" id=\"context_ref_35_2a\">[35]</a>, <a ref-type=\"bibr\" anchor=\"ref36\" id=\"context_ref_36_2a\">[36]</a>, <a ref-type=\"bibr\" anchor=\"ref38\" id=\"context_ref_38_2a\">[38]</a>, <a ref-type=\"bibr\" anchor=\"ref51\" id=\"context_ref_51_2a\">[51]</a>, <a ref-type=\"bibr\" anchor=\"ref53\" id=\"context_ref_53_2a\">[53]</a>, k-nearest neighbor (kNN) <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2a\">[28]</a>, <a ref-type=\"bibr\" anchor=\"ref39\" id=\"context_ref_39_2a\">[39]</a>, <a ref-type=\"bibr\" anchor=\"ref51\" id=\"context_ref_51_2a\">[51]</a>, decision trees (DT) <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref40\" id=\"context_ref_40_2a\">[40]</a>, <a ref-type=\"bibr\" anchor=\"ref41\" id=\"context_ref_41_2a\">[41]</a>, random forest (RF) <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2a\">[28]</a>, <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2a\">[29]</a>, <a ref-type=\"bibr\" anchor=\"ref39\" id=\"context_ref_39_2a\">[39]</a>, <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_2a\">[42]</a>, <a ref-type=\"bibr\" anchor=\"ref43\" id=\"context_ref_43_2a\">[43]</a>, Adaptive Boosting (Adaboost) <a ref-type=\"bibr\" anchor=\"ref44\" id=\"context_ref_44_2a\">[44]</a>, <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_2a\">[45]</a>, Sparse Additive Generative Model (SAGE) <a ref-type=\"bibr\" anchor=\"ref46\" id=\"context_ref_46_2a\">[46]</a>, and multilayer perceptron (MLP) <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2a\">[29]</a>.</p><p>Because of the limited number of available labeled review datasets <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2a\">[3]</a>, some studies have used unsupervised learning methods, such as k-means clustering <a ref-type=\"bibr\" anchor=\"ref54\" id=\"context_ref_54_2a\">[54]</a>, <a ref-type=\"bibr\" anchor=\"ref55\" id=\"context_ref_55_2a\">[55]</a>, twice-clustering method <a ref-type=\"bibr\" anchor=\"ref57\" id=\"context_ref_57_2a\">[57]</a>, unsupervised similarity measurement <a ref-type=\"bibr\" anchor=\"ref58\" id=\"context_ref_58_2a\">[58]</a>, unsupervised generative Bayesian model <a ref-type=\"bibr\" anchor=\"ref59\" id=\"context_ref_59_2a\">[59]</a>, topic-sentiment joint probabilistic model <a ref-type=\"bibr\" anchor=\"ref60\" id=\"context_ref_60_2a\">[60]</a>, matrix iteration algorithm <a ref-type=\"bibr\" anchor=\"ref61\" id=\"context_ref_61_2a\">[61]</a>, multi-iterative graph-based <a ref-type=\"bibr\" anchor=\"ref62\" id=\"context_ref_62_2a\">[62]</a>, statistics-based clustering algorithm <a ref-type=\"bibr\" anchor=\"ref63\" id=\"context_ref_63_2a\">[63]</a>, unified review deviation models <a ref-type=\"bibr\" anchor=\"ref64\" id=\"context_ref_64_2a\">[64]</a>, and lexicon-based model <a ref-type=\"bibr\" anchor=\"ref56\" id=\"context_ref_56_2a\">[56]</a>.</p><p>Some studies used semi-supervised learning methods, such as the positive unlabeled (PU) learning approach <a ref-type=\"bibr\" anchor=\"ref65\" id=\"context_ref_65_2a\">[65]</a>, <a ref-type=\"bibr\" anchor=\"ref66\" id=\"context_ref_66_2a\">[66]</a>, <a ref-type=\"bibr\" anchor=\"ref67\" id=\"context_ref_67_2a\">[67]</a>, hybrid positive unlabeled (PU) learning-based approach <a ref-type=\"bibr\" anchor=\"ref68\" id=\"context_ref_68_2a\">[68]</a>, co-training approach <a ref-type=\"bibr\" anchor=\"ref69\" id=\"context_ref_69_2a\">[69]</a>, <a ref-type=\"bibr\" anchor=\"ref70\" id=\"context_ref_70_2a\">[70]</a>, threshold-based detection method <a ref-type=\"bibr\" anchor=\"ref71\" id=\"context_ref_71_2a\">[71]</a>, multi-task method <a ref-type=\"bibr\" anchor=\"ref72\" id=\"context_ref_72_2a\">[72]</a>, semi-supervised learning framework (SPR2EP) <a ref-type=\"bibr\" anchor=\"ref73\" id=\"context_ref_73_2a\">[73]</a>, and Ramp One-Class SVM <a ref-type=\"bibr\" anchor=\"ref74\" id=\"context_ref_74_2a\">[74]</a>.</p><p>Ensemble learning models have also been used in certain studies because they are more effective in detecting fake reviews than single classifiers <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_2a\">[25]</a>, <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref89\" id=\"context_ref_89_2a\">[89]</a>, <a ref-type=\"bibr\" anchor=\"ref90\" id=\"context_ref_90_2a\">[90]</a>.</p><p>Traditional machine learning algorithms are simple to implement, computationally inexpensive, and perform better than deep learning (DL) models on small datasets (see <b><a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">TABLE 1</a></b>). However, with large-scale datasets, they produce lower performance than deep learning models and are not able to capture text sequences <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2a\">[9]</a>. Deep learning models have been used to detect fake reviews, such as Convolutional Neural Networks (CNN) <a ref-type=\"bibr\" anchor=\"ref75\" id=\"context_ref_75_2a\">[75]</a>, <a ref-type=\"bibr\" anchor=\"ref81\" id=\"context_ref_81_2a\">[81]</a>, <a ref-type=\"bibr\" anchor=\"ref82\" id=\"context_ref_82_2a\">[82]</a>, <a ref-type=\"bibr\" anchor=\"ref83\" id=\"context_ref_83_2a\">[83]</a>, <a ref-type=\"bibr\" anchor=\"ref84\" id=\"context_ref_84_2a\">[84]</a>, Recurrent Convolutional Neural Networks (RCNN) <a ref-type=\"bibr\" anchor=\"ref85\" id=\"context_ref_85_2a\">[85]</a>, Long Short-Term Memory (LSTM) <a ref-type=\"bibr\" anchor=\"ref86\" id=\"context_ref_86_2a\">[86]</a>, <a ref-type=\"bibr\" anchor=\"ref87\" id=\"context_ref_87_2a\">[87]</a>, <a ref-type=\"bibr\" anchor=\"ref88\" id=\"context_ref_88_2a\">[88]</a>, Bidirectional Gated Recurrent Unit (Bi-GRU) with attention <a ref-type=\"bibr\" anchor=\"ref76\" id=\"context_ref_76_2a\">[76]</a>, Generative Adversarial Network (GAN) <a ref-type=\"bibr\" anchor=\"ref77\" id=\"context_ref_77_2a\">[77]</a>, <a ref-type=\"bibr\" anchor=\"ref78\" id=\"context_ref_78_2a\">[78]</a>, <a ref-type=\"bibr\" anchor=\"ref79\" id=\"context_ref_79_2a\">[79]</a>, and Bidirectional Encoder Representations from Transformers (BERT) <a ref-type=\"bibr\" anchor=\"ref80\" id=\"context_ref_80_2a\">[80]</a>.<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nComparison Between Detection Methods for Fake Reviews</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t1-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t1-3227631-small.gif\" alt=\"Table 1- &#10;Comparison Between Detection Methods for Fake Reviews\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>Some other deep learning models are still not used in fake reviews detection, but based on the initial experiments performed by R. Mohawesh et al. <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2a\">[9]</a>, these models are promising such as convolutional-LSTM (C-LSTM), character-level C-LSTM, Hierarchical Attention Network (HAN), convolutional HAN, distilled version of BERT (DistilBERT), and Robustly Optimized BERT approach (RoBERTa).</p><p>Despite the great results that deep learning models have achieved, they lack a conceptual understanding to provide further justifications for the results <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2a\">[9]</a>. All deep learning algorithms for detecting fake reviews are uninterpretable, and it is challenging to trust the model\u2019s performance and outcomes, whereas some deep learning models outperform other models on one dataset but underperform others on another <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2a\">[9]</a>. (See <b><a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">TABLE 1</a></b>)</p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Theory-Based Fake Reviews Detection Models</h3><p>Having a model with good accuracy for fake reviews detection is not sufficient to generalize and trust this model. The model results need sufficient theoretical justification and consistent testing results on different datasets because human deception behavior is complex <a ref-type=\"bibr\" anchor=\"ref91\" id=\"context_ref_91_2b\">[91]</a>. Few deception detection models have been built based on fundamental theories, and we do not consider studies that have features or results that are aligned with some fundamental theories. However, we only consider studies that built their models or their feature selection based on fundamental theories from natural or social sciences, such as psychology, sociology, criminology, biology, or linguistics.</p><p>S. Banerjee et al. <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_2b\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref92\" id=\"context_ref_92_2b\">[92]</a> constructed a theoretical model that detects textual cues to differentiate between truthful and fake reviews. They synthesized four deception theories: information manipulation theory (IMT) <a ref-type=\"bibr\" anchor=\"ref93\" id=\"context_ref_93_2b\">[93]</a>, leakage theory <a ref-type=\"bibr\" anchor=\"ref94\" id=\"context_ref_94_2b\">[94]</a>, self-presentational theory <a ref-type=\"bibr\" anchor=\"ref95\" id=\"context_ref_95_2b\">[95]</a>, <a ref-type=\"bibr\" anchor=\"ref96\" id=\"context_ref_96_2b\">[96]</a>, and reality monitoring theory (RM) <a ref-type=\"bibr\" anchor=\"ref97\" id=\"context_ref_97_2b\">[97]</a>, <a ref-type=\"bibr\" anchor=\"ref98\" id=\"context_ref_98_2b\">[98]</a>. The proposed model identifies four constructs in the content of the review: exaggeration, comprehensibility, specificity, and negligence. These constructs and their cues were tested using logistic regression with negative, positive, and moderate reviews. Accuracy ranged from 78% to 86%.</p><p>L. Zhou et al. <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2b\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2b\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2b\">[101]</a> concentrated on detecting cues employed by deceivers in a textual-based computer-mediated communication context. They selected linguistic-based cues that were grouped into nine linguistic constructs: quantity, complexity, non-immediacy, affect, uncertainty, diversity, specificity, expressivity, and informality. These linguistic constructs were synthesized from media richness theory <a ref-type=\"bibr\" anchor=\"ref102\" id=\"context_ref_102_2b\">[102]</a>, channel expansion theory <a ref-type=\"bibr\" anchor=\"ref103\" id=\"context_ref_103_2b\">[103]</a>, interpersonal deception theory (IDT) <a ref-type=\"bibr\" anchor=\"ref91\" id=\"context_ref_91_2b\">[91]</a>, <a ref-type=\"bibr\" anchor=\"ref104\" id=\"context_ref_104_2b\">[104]</a>, the model of deceptive communication <a ref-type=\"bibr\" anchor=\"ref105\" id=\"context_ref_105_2b\">[105]</a>, criteria-based content analysis (CBCA) <a ref-type=\"bibr\" anchor=\"ref106\" id=\"context_ref_106_2b\">[106]</a> which is the third stage of statement validity analysis (SVA), derived from the Undeutsch hypothesis <a ref-type=\"bibr\" anchor=\"ref107\" id=\"context_ref_107_2b\">[107]</a>, reality monitoring theory (RM), scientific content analysis (SCAN) <a ref-type=\"bibr\" anchor=\"ref108\" id=\"context_ref_108_2b\">[108]</a>, and verbal immediacy theory (VI) <a ref-type=\"bibr\" anchor=\"ref109\" id=\"context_ref_109_2b\">[109]</a>. After considering only the essential cues of the linguistic constructs in the model. The classification accuracy ranged from 74% to 80%, the classification precision ranged from 70% to 80%, and the classification specificity ranged from 78% to 81% using discriminant analysis, logistic regression, and neural networks.</p><p>T. Qin et al. <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2b\">[110]</a> examined linguistic cues to deceptive behavior across three methods of communication: text, audio, and face-to-face. They synthesized theories and criteria, including criteria-based content analysis (CBCA), reality monitoring theory (RM), scientific content analysis (SCAN), and interpersonal deception theory (IDT). They used linguistic cues which were grouped into seven categories: quantity, complexity, diversity, verb non-immediacy, uncertainty, specificity, and affect.</p><p>J. Li et al. <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_2b\">[33]</a> attempted to identify general linguistic differences between fake and truthful reviews; for this purpose, they used the research results of applied English linguistics and psycholinguistics with deception research and theories, including reality monitoring theory (RM) and interpersonal deception theory (IDT). They explored LIWC features (sentiment, spatial details, and first-person singular pronouns), part-of-speech (POS) features, and unigram features that distinguish informative (truthful) writing from imaginative (deceptive) writing. They experimented with these features using SAGE and SVM models, starting with intra-domain classification and extending to cross-domain classification. The classification accuracy ranged from 52% to 82%.</p><p>B. Kleinberg et al. <a ref-type=\"bibr\" anchor=\"ref111\" id=\"context_ref_111_2b\">[111]</a> used named entities to detect verbal deception by modeling and capturing three theoretical concepts: the richness of detail, contextual embedding, and verifiability of details which were derived from reality monitoring theory (RM), criteria-based content analysis (CBCA), and verifiability approach (VA) <a ref-type=\"bibr\" anchor=\"ref112\" id=\"context_ref_112_2b\">[112]</a> respectively.</p><p>C. Fuller et al. <a ref-type=\"bibr\" anchor=\"ref113\" id=\"context_ref_113_2b\">[113]</a> developed an automated text-based deception detection model by selecting cue set from deception constructs drawn from deception theories, including interpersonal deception theory (IDT), information manipulation theory (IMT), reality monitoring theory (RM), four-factor theory <a ref-type=\"bibr\" anchor=\"ref114\" id=\"context_ref_114_2b\">[114]</a>, and self-presentational theory. They used confirmatory factor analysis to validate a set of deception constructs, including uncertainty, affect, specificity, and quantity. The overall accuracy ranged from 67% to 74% using logistic regression, decision trees, and neural networks.</p><p>D. Derrick et al. <a ref-type=\"bibr\" anchor=\"ref115\" id=\"context_ref_115_2b\">[115]</a> built a theoretical model for detecting deceptive chat-based communication as a type of computer-mediated deception, which was mainly based on cognitive load theory <a ref-type=\"bibr\" anchor=\"ref116\" id=\"context_ref_116_2b\">[116]</a>, <a ref-type=\"bibr\" anchor=\"ref117\" id=\"context_ref_117_2b\">[117]</a> and psychological studies that consider the increase of cognitive load as an indication for lying <a ref-type=\"bibr\" anchor=\"ref94\" id=\"context_ref_94_2b\">[94]</a>, <a ref-type=\"bibr\" anchor=\"ref118\" id=\"context_ref_118_2b\">[118]</a>, <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2b\">[119]</a>. They hypothesized that deception in chatting affects word count, response time, lexical diversity, and the number of message edits. These four hypotheses were also supported by interpersonal deception theory (IDT), criteria-based content analysis (CBCA), and reality monitoring (RM).</p><p>X. Liu et al. <a ref-type=\"bibr\" anchor=\"ref120\" id=\"context_ref_120_2b\">[120]</a> focused on the Newman-Pennebaker (NP) model <a ref-type=\"bibr\" anchor=\"ref140\" id=\"context_ref_140_2b\">[140]</a> to explore linguistic features from the text for the purpose of detecting deception. They derived four theoretical features from the NP model: negative emotion terms, first-person singular pronouns, action verbs, and exclusive words. These theoretical features were tested using SVM and LR, and the accuracy was approximately 75%, but when these features were combined with other empirically-derived features and then optimized, the accuracy was improved to 86%.</p><p>D. Zhang et al. <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_2b\">[42]</a> found a set of non-verbal behavioral aspects of reviewers and evaluated their relevance for detecting fake reviews. They applied interpersonal deception theory (IDT) and the concept of non-verbal behavior to fake reviews detection by evaluating reviewers\u2019 posting and social behaviors. They combined non-verbal features of reviewers, such as membership, friendship, and posting with verbal features of reviews, such as review length, subjectivity, lexical validity, sentiment, lexical diversity, and self-reference diversity to improve the performance of fake reviews detection. The best accuracy of their model was 84% when using random forest.</p><p>T. Ong et al. <a ref-type=\"bibr\" anchor=\"ref121\" id=\"context_ref_121_2b\">[121]</a> used expectancy theory <a ref-type=\"bibr\" anchor=\"ref141\" id=\"context_ref_141_2b\">[141]</a> and the NP model to develop their hypotheses and show the differences between fake and truthful reviews based on information content, subjectivity, and readability.</p><p>K. Yoo et al. <a ref-type=\"bibr\" anchor=\"ref122\" id=\"context_ref_122_2b\">[122]</a> examined the linguistic structure of fake and truthful hotel reviews using interpersonal deception theory (IDT) and the NP model. They tested several aspects of reviews, including quantity, lexical complexity, lexical diversity, immediacy, presence of brand names, and sentiment.</p><p>T. Chang et al. <a ref-type=\"bibr\" anchor=\"ref124\" id=\"context_ref_124_2b\">[124]</a> used the rumor model <a ref-type=\"bibr\" anchor=\"ref142\" id=\"context_ref_142_2b\">[142]</a> and its conceptual formula to profile the importance and ambiguity in fake reviews by extracting major features of review content: important attribute word, noun-verb ratio, and a specific quantifier. Using SVM, the overall precision of the proposed model was 59.6%.</p><p>X. Zhou et al. <a ref-type=\"bibr\" anchor=\"ref123\" id=\"context_ref_123_2b\">[123]</a> built a fake news detection model focusing on news content and investigated the relationship between deception and fake news depending on the linguistic cues which were derived from four deception theories: information manipulation theory (IMT), reality monitoring theory (RM), four-factor theory, and the Undeutsch hypothesis. The deception-related attributes extracted from these theories were informality, diversity, subjectivity, sentiment, quantity, and specificity. Random forests (RF) and extreme gradient boosting (XGBoost) were utilized to experiment with these attributes and achieved accuracy from 63% to 76% and an F1-score from 65% to 76%.</p><p>Some studies <a ref-type=\"bibr\" anchor=\"ref125\" id=\"context_ref_125_2b\">[125]</a>, <a ref-type=\"bibr\" anchor=\"ref126\" id=\"context_ref_126_2b\">[126]</a>, <a ref-type=\"bibr\" anchor=\"ref127\" id=\"context_ref_127_2b\">[127]</a>, <a ref-type=\"bibr\" anchor=\"ref128\" id=\"context_ref_128_2b\">[128]</a>, <a ref-type=\"bibr\" anchor=\"ref129\" id=\"context_ref_129_2b\">[129]</a>, <a ref-type=\"bibr\" anchor=\"ref130\" id=\"context_ref_130_2b\">[130]</a>, <a ref-type=\"bibr\" anchor=\"ref131\" id=\"context_ref_131_2b\">[131]</a>, <a ref-type=\"bibr\" anchor=\"ref132\" id=\"context_ref_132_2b\">[132]</a>, <a ref-type=\"bibr\" anchor=\"ref133\" id=\"context_ref_133_2b\">[133]</a>, <a ref-type=\"bibr\" anchor=\"ref134\" id=\"context_ref_134_2b\">[134]</a> focused on dual-process theory <a ref-type=\"bibr\" anchor=\"ref143\" id=\"context_ref_143_2b\">[143]</a> or the widely used dual-process models: the heuristic-systematic model (HSM) <a ref-type=\"bibr\" anchor=\"ref144\" id=\"context_ref_144_2b\">[144]</a> and the elaboration likelihood model (ELM) <a ref-type=\"bibr\" anchor=\"ref145\" id=\"context_ref_145_2b\">[145]</a>. They developed hypotheses and conceptualized credibility analysis models for online reviews, demonstrating factors that affect the credibility of reviews, such as review sidedness, argument strength, internal consistency, reviewer credibility, information rating, review objectivity, external consistency, review framing, and structural factors.</p><p>Some studies <a ref-type=\"bibr\" anchor=\"ref135\" id=\"context_ref_135_2b\">[135]</a>, <a ref-type=\"bibr\" anchor=\"ref136\" id=\"context_ref_136_2b\">[136]</a>, <a ref-type=\"bibr\" anchor=\"ref137\" id=\"context_ref_137_2b\">[137]</a>, <a ref-type=\"bibr\" anchor=\"ref138\" id=\"context_ref_138_2b\">[138]</a>, <a ref-type=\"bibr\" anchor=\"ref139\" id=\"context_ref_139_2b\">[139]</a> employed rhetorical structure theory (RST) <a ref-type=\"bibr\" anchor=\"ref146\" id=\"context_ref_146_2b\">[146]</a> with vector space model (VSM) to detect systematic variations in coherence and structure between fake and truthful texts by analyzing the links between the component aspects of discourse. They used RST relations as features.</p><p>O. Popoola et al. <a ref-type=\"bibr\" anchor=\"ref138\" id=\"context_ref_138_2b\">[138]</a>, <a ref-type=\"bibr\" anchor=\"ref139\" id=\"context_ref_139_2b\">[139]</a> built a fake reviews detection model from the RST relations using logistic regression. After testing the model, the accuracy, precision, and recall reached 78 %, 80%, and 76 %, respectively.</p><p>G. Shan et al. <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2b\">[29]</a> built an online fake reviews detection system by adapting the truth-default theory (TDT) <a ref-type=\"bibr\" anchor=\"ref147\" id=\"context_ref_147_2b\">[147]</a>, leakage theory <a ref-type=\"bibr\" anchor=\"ref94\" id=\"context_ref_94_2b\">[94]</a>, and attitude-behavior consistency theory <a ref-type=\"bibr\" anchor=\"ref148\" id=\"context_ref_148_2b\">[148]</a>. Three types of review inconsistency were conceptualized and introduced in their study: content inconsistency, rating-sentiment inconsistency, and reviewer language inconsistency. Rating-sentiment inconsistency was derived from coherence. Content inconsistency and reviewer language inconsistency were derived from correspondence. Non-verbal features for reviewer credibility and deviation in reviewing behavior were also incorporated. They tested their hypotheses using support vector machines (SVM), Na\u00efve Bayes (NB), decision tree (DT), random forest (RF), and multilayer perceptron (MLP). After testing the system, accuracy ranged from 74% to 93%, precision ranged from 86% to 94%, recall ranged from 87% to 93%, and F1-score ranged from 87% to 93%.</p><p>From the summary in <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>, we can see that the most frequently used theories are reality monitoring theory (RM), elaboration likelihood model (ELM), interpersonal deception theory (IDT), Undeutsch hypothesis and the derived criteria-based content analysis (CBCA) respectively. We can also see that the most frequently used constructs across all theory-based models are specificity, affect, complexity, source credibility, deviation in behavior, and quantity, respectively.<div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nSummary of Theory-Based Models</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t2-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t2-3227631-small.gif\" alt=\"Table 2- &#10;Summary of Theory-Based Models\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>The deception detection models for computer-mediated texts, such as fake reviews detection models, mostly focus on verbal behavior through linguistic cues which are derived from cue theories of deception and ignore non-verbal behavior.</p><p>The literature on fake reviews detection lacks a comprehensive model that synthesizes relevant fundamental theories to analyze reviews based on their content and writers\u2019 behavior.</p></div><div class=\"section_2\" id=\"sec2c\"><h3>C. Features Used to Identify Fake Reviews</h3><div class=\"section_2\" id=\"sec2c1\"><h4>1) Reviewer Features</h4><p>These features cover the credibility and non-verbal behavior of the reviewer. The most commonly used reviewer features are:\n<ul style=\"list-style-type:disc\"><li><p><b>First review ratio:</b> This feature measures the percentage that the reviewer posts the first review for any service or item. Fake reviews are meant to be posted as early as possible to significantly affect and deceive customers <a ref-type=\"bibr\" anchor=\"ref121\" id=\"context_ref_121_2c1\">[121]</a>, <a ref-type=\"bibr\" anchor=\"ref149\" id=\"context_ref_149_2c1\">[149]</a>.</p></li><li><p><b>Reviewing burstiness:</b> This feature computes whether the reviewer posts many reviews within a short period. Posting a large number of reviews in a short period is unusual and might indicate that the reviewer is a spammer and attempts to influence the rating <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_2c1\">[150]</a>, <a ref-type=\"bibr\" anchor=\"ref151\" id=\"context_ref_151_2c1\">[151]</a>, <a ref-type=\"bibr\" anchor=\"ref152\" id=\"context_ref_152_2c1\">[152]</a>.</p></li><li><p><b>Maximum number of reviews:</b> This feature measures the largest number of reviews written by a reviewer on a certain day. Truthful reviewers should not exceed a specific threshold in one day <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_2c1\">[150]</a>, and some studies have found that the threshold is five reviews <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2c1\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref153\" id=\"context_ref_153_2c1\">[153]</a>.</p></li><li><p><b>Extreme rating:</b> This feature computes whether the reviewer always uses extreme ranking, either the highest or the lowest rank on the scale. An extreme rating may indicate an attempt by a fake reviewer to enhance or lower the overall ranking of a product <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_2c1\">[150]</a>.</p></li><li><p><b>Ratio of positive reviews:</b> This feature measures the percentage of positive reviews posted by a reviewer, which may indicate spammer behavior if the percentage of positive reviews is high <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2c1\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref154\" id=\"context_ref_154_2c1\">[154]</a>.</p></li><li><p><b>Rating deviation:</b> This feature measures the divergence between a reviewer\u2019s rating and overall rating. An honest reviewer regularly rates items within the range of the overall ratings, whereas suspicious ratings differ significantly from the overall ratings provided by honest reviewers <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_2c1\">[150]</a>, <a ref-type=\"bibr\" anchor=\"ref155\" id=\"context_ref_155_2c1\">[155]</a>.</p></li><li><p><b>Number of reviews:</b> This feature measures the reviewer involvement based on the total number of reviews posted. The number of reviews posted by a single reviewer is a crucial feature for distinguishing truthful reviewers from fake ones <a ref-type=\"bibr\" anchor=\"ref43\" id=\"context_ref_43_2c1\">[43]</a>, and the reviewer, who posted more reviews, is more credible than the one who posted fewer reviews <a ref-type=\"bibr\" anchor=\"ref156\" id=\"context_ref_156_2c1\">[156]</a>, <a ref-type=\"bibr\" anchor=\"ref157\" id=\"context_ref_157_2c1\">[157]</a>, <a ref-type=\"bibr\" anchor=\"ref158\" id=\"context_ref_158_2c1\">[158]</a>.</p></li><li><p><b>Number of friends/followers:</b> This feature measures a reviewer\u2019s sociability based on the total number of friends or followers. Sociability is an important indicator of a reviewer\u2019s credibility <a ref-type=\"bibr\" anchor=\"ref156\" id=\"context_ref_156_2c1\">[156]</a>, <a ref-type=\"bibr\" anchor=\"ref158\" id=\"context_ref_158_2c1\">[158]</a>, <a ref-type=\"bibr\" anchor=\"ref159\" id=\"context_ref_159_2c1\">[159]</a>, <a ref-type=\"bibr\" anchor=\"ref160\" id=\"context_ref_160_2c1\">[160]</a>. A reviewer\u2019s reputation can also be measured by the ratio of followers to the total number of followers and friends <a ref-type=\"bibr\" anchor=\"ref161\" id=\"context_ref_161_2c1\">[161]</a>.</p></li><li><p><b>Membership length:</b> This feature measures the age of the reviewer\u2019s account from the date of registration. The accounts with longer memberships are more reliable <a ref-type=\"bibr\" anchor=\"ref158\" id=\"context_ref_158_2c1\">[158]</a>, <a ref-type=\"bibr\" anchor=\"ref162\" id=\"context_ref_162_2c1\">[162]</a>.</p></li></ul></p></div><div class=\"section_2\" id=\"sec2c2\"><h4>2) Online Review Features</h4><p>These features describe the content of the review. The most commonly used review features are:\n<ul style=\"list-style-type:disc\"><li><p><b>Review length:</b> This feature measures the number of letters, words, phrases, or paragraphs in a review. Long reviews are considered more trustworthy than short ones for two reasons: lengthy reviews have a better probability of providing consumers with more detailed information <a ref-type=\"bibr\" anchor=\"ref129\" id=\"context_ref_129_2c2\">[129]</a>, <a ref-type=\"bibr\" anchor=\"ref156\" id=\"context_ref_156_2c2\">[156]</a>, and spammers often spend a relatively short period writing fake reviews <a ref-type=\"bibr\" anchor=\"ref163\" id=\"context_ref_163_2c2\">[163]</a>. Some studies <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2c2\">[110]</a>, <a ref-type=\"bibr\" anchor=\"ref113\" id=\"context_ref_113_2c2\">[113]</a> have mapped this feature theoretically using a quantity construct.</p></li><li><p><b>Reviews content similarity:</b> This feature measures the similarity between different reviews written by the same reviewer. The presence of similar reviews for different items may indicate that the reviewer is a spammer <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2c2\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref164\" id=\"context_ref_164_2c2\">[164]</a> because they do not want to waste time writing new reviews <a ref-type=\"bibr\" anchor=\"ref59\" id=\"context_ref_59_2c2\">[59]</a>, <a ref-type=\"bibr\" anchor=\"ref149\" id=\"context_ref_149_2c2\">[149]</a>, <a ref-type=\"bibr\" anchor=\"ref165\" id=\"context_ref_165_2c2\">[165]</a>. The cosine similarity method is primarily used to capture maximum content similarity <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_2c2\">[150]</a>.</p></li><li><p><b>Bag of Words (BoW) (n-grams):</b> These features convert a review text into a vector form using individual or small groups of words to describe the frequency of content words, and some studies <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_2c2\">[33]</a>, <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_2c2\">[48]</a> used these features to detect fake reviews. However, these features cannot capture the meaning of the text.</p></li><li><p><b>Term frequency-inverse document frequency (TF-IDF):</b> These features measure the importance and relevance of terms to a review, and are used as word evaluation schemes. R. Barbado et al. <a ref-type=\"bibr\" anchor=\"ref44\" id=\"context_ref_44_2c2\">[44]</a> used TF-IDF features with bigram features to enhance performance.</p></li><li><p><b>Language Inquiry and Word Count (LIWC):</b> LIWC is a text analysis tool that counts words into several categories. M. Ott et al. <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c2\">[24]</a> and D. Plotkina et al. <a ref-type=\"bibr\" anchor=\"ref166\" id=\"context_ref_166_2c2\">[166]</a> used the LIWC features to detect fake reviews. It consists of a dictionary with a set of categories related to psychology. Some examples of features that can be extracted using LIWC or its dictionary are as follows:\n<ol><li><p><i>Personal pronouns</i>: This feature measures the usage of first-person pronouns and third-person pronouns in a review. When first-person pronouns (e.g.: \u201cI\u201d, \u201cmy\u201d, \u201cwe\u201d, \u201cour\u201d\u2026etc.) are used less and third-person pronouns (e.g.: \u201che\u201d, \u201chim\u201d, \u201cthey\u201d, \u201cthem\u201d\u2026etc.) are used more, this may indicate that the review is fake because liars try to disengage themselves from their false information, and because they do not have real experience <a ref-type=\"bibr\" anchor=\"ref91\" id=\"context_ref_91_2c2\">[91]</a>, <a ref-type=\"bibr\" anchor=\"ref167\" id=\"context_ref_167_2c2\">[167]</a>. Some studies <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2c2\">[110]</a> have mapped this feature theoretically using a non-immediacy construct.</p></li><li><p><i>Temporal and spatial information</i>: This feature measures the usage of locations and times in a review. Legitimate messages are expected to include more information about places and times than deceptive ones <a ref-type=\"bibr\" anchor=\"ref97\" id=\"context_ref_97_2c2\">[97]</a>, <a ref-type=\"bibr\" anchor=\"ref106\" id=\"context_ref_106_2c2\">[106]</a>. Some studies <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2c2\">[110]</a> have theoretically mapped this feature using a specificity construct.</p></li><li><p><i>Positive/negative affect:</i> These features measure the usage of terms with positive/negative meanings. Deceivers are expected to show more negative affect <a ref-type=\"bibr\" anchor=\"ref91\" id=\"context_ref_91_2c2\">[91]</a>. Some studies <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2c2\">[110]</a> have theoretically mapped these features using an affect construct.</p></li></ol></p></li><li><p><b>Coh-Matrix features:</b> Coh-Matrix is a tool used for cohesion and coherence measures for texts <a ref-type=\"bibr\" anchor=\"ref168\" id=\"context_ref_168_2c2\">[168]</a>. It has many features for texts, such as cohesion and narrativity. D. Plotkina et al. <a ref-type=\"bibr\" anchor=\"ref166\" id=\"context_ref_166_2c2\">[166]</a> have used Coh-Matrix features to detect fake online reviews.</p></li><li><p><b>Semantic features:</b>These features capture the meanings of words in a review so that switching between synonyms does not impact the results. Word embedding is one of the distributional semantic methods that represents words in vectors of fixed lengths <a ref-type=\"bibr\" anchor=\"ref169\" id=\"context_ref_169_2c2\">[169]</a>. Some studies <a ref-type=\"bibr\" anchor=\"ref170\" id=\"context_ref_170_2c2\">[170]</a>, <a ref-type=\"bibr\" anchor=\"ref171\" id=\"context_ref_171_2c2\">[171]</a> have used word embedding with deep learning to detect fake reviews.</p></li><li><p><b>Stylometric features:</b> These features measure the writing style in a review. These features include both syntactic and lexical features. Syntactic features include the presence, frequency, and diversity of specific parts of speech (POS) patterns. Lexical features include lexical diversity, which was mapped theoretically with a diversity construct <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2c2\">[110]</a>, and lexical validity (ratio of misspellings), which was mapped theoretically with an informality construct <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_2c2\">[42]</a>, <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_2c2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_2c2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_2c2\">[101]</a>. S. Shojaee et al. <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_2c2\">[47]</a> have used a large number of syntactic and lexical features to identify fake reviews.</p></li><li><p><b>Discourse/rhetorical relations:</b> These features capture the coherence of a review text. These relations have different patterns <a ref-type=\"bibr\" anchor=\"ref135\" id=\"context_ref_135_2c2\">[135]</a>, <a ref-type=\"bibr\" anchor=\"ref136\" id=\"context_ref_136_2c2\">[136]</a>. O. Popoola et al. <a ref-type=\"bibr\" anchor=\"ref138\" id=\"context_ref_138_2c2\">[138]</a>, <a ref-type=\"bibr\" anchor=\"ref139\" id=\"context_ref_139_2c2\">[139]</a> used RST relations to build a fake reviews detection model.</p></li></ul></p></div></div><div class=\"section_2\" id=\"sec2d\"><h3>D. Deception Theories</h3><p>Fake reviews are a form of deception <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_2d\">[42]</a>, and deception is defined as a message purposely sent by a sender to form a false belief or conclusion by the receiver <a ref-type=\"bibr\" anchor=\"ref167\" id=\"context_ref_167_2d\">[167]</a>, <a ref-type=\"bibr\" anchor=\"ref172\" id=\"context_ref_172_2d\">[172]</a>. Deception theories in psychology that study human cognition and behavior, discovered across disciplines, provide essential clues to deception. These theories have the potential to open new areas for research on large amounts of fake reviews data and can also support the development of fake reviews detection models. In this section, we consider and summarize deception theories that are highly cited, well-founded with a clear methodology, and tested in the context of deception detection in computer-mediated text.</p><div class=\"section_2\" id=\"sec2d1\"><h4>1) Leakage Theory</h4><p>Leakage theory <a ref-type=\"bibr\" anchor=\"ref94\" id=\"context_ref_94_2d1\">[94]</a> is the first and possibly most prominent deception theory. This theory has dominated deception research, while most of the theories that follow can be considered modifications of the principles of leakage and deception cues <a ref-type=\"bibr\" anchor=\"ref173\" id=\"context_ref_173_2d1\">[173]</a>. The theory highlights the differentiation between two types of non-verbal behaviors: deception and leakage cues. Deception cues indicate that deception occurs, but they do not reveal what information is hidden. Leakage cues, on the other hand, expose hidden information, which can be considered a leakage of the truth. Both types of cues are mostly clear on the legs and feet as well as micro expressions on the face.</p><p>The theory primarily considers high-stakes lies, not insignificant or white lies. According to this idea, deceit must induce emotional reactions in the deceiver, which can only apply to high-stake lies. Negative emotions (guilt, fear, and delight) are deception-related. The consequences of a lie\u2019s acceptance or rejection are called stakes. Leakage and deception cues are more likely to occur when stakes are higher.</p><p>The theory has evolved over time <a ref-type=\"bibr\" anchor=\"ref174\" id=\"context_ref_174_2d1\">[174]</a>, <a ref-type=\"bibr\" anchor=\"ref175\" id=\"context_ref_175_2d1\">[175]</a>, but it actually kept the same concepts with limited changes, such as considering the verbal content and voice, such as inconsistent content and voice pitch. It considered pauses, indirect speech, long response latency, and speech errors. The only textual content cue that showed a difference was the number of self-references, which was lower in deception. This theory focuses on emotions and facial expressions that can only be clear in face-to-face communication with high-stake lies.</p><p>The main criticism of this theory is the lack of evidence that specific physiological states that are thought to be caused by telling a lie cannot be caused by many other emotional states, such as anxiety or fear <a ref-type=\"bibr\" anchor=\"ref176\" id=\"context_ref_176_2d1\">[176]</a>.</p></div><div class=\"section_2\" id=\"sec2d2\"><h4>2) Four-Factor Theory</h4><p>Four-factor theory <a ref-type=\"bibr\" anchor=\"ref114\" id=\"context_ref_114_2d2\">[114]</a> suggests that investigating four specific factors could lead to the discovery of deception cues. The four psychological factors are arousal, emotional reactions, cognitive effort, and attempted behavioral control. Arousal and emotional reactions appear to have the same meaning, as mentioned by the authors of the theory, which led other researchers to consider them as three factors <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2d2\">[119]</a>.</p><p>The emotional reactions of deceivers depend on their personalities; they may feel guilty, fearful, or excited, which may cause non-immediacy, anxiety, speech mistakes (stuttering, omission of words, and repetition of words), speech hesitation, or an increased pitch. This theory posits that more cognitive effort is required when telling a lie than when telling the truth. Deceivers try to control their behavior to avoid detection and appear truthful.</p><p>The problem with using this theory in the context of online reviews is that it focuses on face-to-face non-verbal behavior.</p></div><div class=\"section_2\" id=\"sec2d3\"><h4>3) Interpersonal Deception Theory (IDT)</h4><p>Interpersonal deception theory (IDT) <a ref-type=\"bibr\" anchor=\"ref91\" id=\"context_ref_91_2d3\">[91]</a>, <a ref-type=\"bibr\" anchor=\"ref104\" id=\"context_ref_104_2d3\">[104]</a> aims to describe deception from the viewpoint of interpersonal communication in the presence of dynamic interaction between the sender and receiver. According to this theory, the deceiver will participate in strategic behavior changes in response to the receiver\u2019s doubts and show nonstrategic leakage signs. On the strategic side, the deceiver tries to manage information in his message, image, and behavior.</p><p>Source credibility is one of the attributes considered critical by this theory. Credibility measures the believability of a sender in terms of character, competence, composure, sociability, and dynamism. The IDT posits that as the sender\u2019s behavior deviates from normalcy, natural, reciprocity, ideal, and moderate involvement, it should be suspected.</p><p>The theory posits that deceivers have less specificity, immediacy, vocal relaxation, vocal pleasantness, and expressivity but show more negative affect, nervousness, arousal, uncertainty, noninvolvement, cognitive load, pauses, response latencies, and non-fluencies.</p><p>The theory posits that the behavior of deceivers is reflected in their language in terms of quantity, immediacy, specificity, uncertainty, and vagueness. The deceivers\u2019 deceptive messages are brief and reflect less quantity. They may employ leveling terms such as: \u201calways\u201d or \u201ceveryone\u201d which minimize specificity. They may employ indirect forms of expression to modify or objectify their replies. They may use group/others references such as: \u201cthey\u201d or \u201cwe\u201d more than self-references such as: \u201cme\u201d or \u201cI\u201d which reflects non-immediacy. They are more likely to use past-tense verbs than present-tense verbs, reflecting non-immediacy in time.</p><p>The problem with using this theory in the context of online reviews is that it considers the interpersonal interactive form of communication, and posits that skilled deceivers are different from unskilled ones, making it very difficult to differentiate between skilled deceivers and truthful senders.</p></div><div class=\"section_2\" id=\"sec2d4\"><h4>4) Self-Presentational Theory</h4><p>The self-presentational theory <a ref-type=\"bibr\" anchor=\"ref95\" id=\"context_ref_95_2d4\">[95]</a>, <a ref-type=\"bibr\" anchor=\"ref96\" id=\"context_ref_96_2d4\">[96]</a> first highlights that lying is a regular phenomenon in everyday situations. They disagreed with the concept that lying is usually a complex and guilt-inducing procedure with obvious and powerful cues. Instead, they argued that most false presentations are well-practiced and well-executed and that only little behavioral leakage remains. The theory claims that the behavior of both truth-tellers and deceivers is affected by emotions, cognitive load, and behavioral control. The theory posits that deceivers may appear less convincing, forthcoming, spontaneous, and pleasant, but tenser than truth-tellers.</p><p>Deceivers are less convincing than truth-tellers which means they have less plausibility, certainty, involvement, immediacy, and fluency. Deceivers are less forthcoming than truth-tellers which means they have shorter messages with fewer details, less complexity, and less quantity of information. Deceivers are less spontaneous than truth-tellers which means their deceptive messages are less influenced by narrative mistakes than truthful ones. Deceivers are less pleasant than truth tellers, which means that their deceptive messages are less positive, less cooperative, and more negative. Deceivers are tenser than truth tellers, which means they are more anxious and nervous.</p><p>This theory took advantage of former theories such as reality monitoring theory (RM), verbal immediacy theory (VI), and criteria-based content analysis (CBCA). They used the cues mentioned in verbal immediacy theory (VI) <a ref-type=\"bibr\" anchor=\"ref109\" id=\"context_ref_109_2d4\">[109]</a> to measure immediacy, including the use of passive voice in deceptive messages instead of active voice and negations instead of assertions. Regarding fluency, they found that deceivers repeatedly used the same words and phrases. Regarding plausibility, they found that deceptive messages were more likely to be internally inconsistent or to reflect ambiguity.</p><p>The theory was criticized for focusing on similarities instead of the differences between deceivers and truth-tellers, which did not significantly improve deception detection <a ref-type=\"bibr\" anchor=\"ref177\" id=\"context_ref_177_2d4\">[177]</a>.</p></div><div class=\"section_2\" id=\"sec2d5\"><h4>5) Reality Monitoring Theory (RM)</h4><p>Reality monitoring theory (RM) <a ref-type=\"bibr\" anchor=\"ref97\" id=\"context_ref_97_2d5\">[97]</a>, <a ref-type=\"bibr\" anchor=\"ref98\" id=\"context_ref_98_2d5\">[98]</a> was originally used to examine the characteristics of memory, and it was not used for deception. This theory was used as a verbal deception detection method because the basis of reality monitoring is the fact that the quality of memories of actually experienced events is different from that of imagined events. The differentiation between memories of experience and imagination is derived from the Undeutsch hypothesis <a ref-type=\"bibr\" anchor=\"ref107\" id=\"context_ref_107_2d5\">[107]</a>. Researchers have argued that experienced events show truthfulness, whereas imagined events indicate deception.</p><p>Perceptual, contextual, and affective information are present in the memories of experienced events. Perceptual (sensory) information refers to sounds, smells, tastes, touches, or visual details that can be memorized from real experiences. Contextual information refers to temporal details (time of occurrence, time order, and duration) and spatial details (places of occurrence and positions of objects or people). Affective information refers to emotions and feelings.</p><p>According to reality monitoring, truthful statements exhibit clarity, re-constructability, and realism. Clarity refers to the sharpness and vividness of a statement. Re-constructability refers to the possibility of reconstructing a scenario. Realism refers to the plausibility and feasibility of a scenario.</p><p>Cognitive operations are present in the memories of imagined events. Cognitive operations refer to inferences and opinions during the description of a scenario, such as reasoning or thoughts.</p><p>In summary, clarity, re-constructability, realism, perceptual information, contextual information, and affective information are the attributes and content of truthful statements. Cognitive operations are present in the deceptive statements.</p><p>J. Masip et al. <a ref-type=\"bibr\" anchor=\"ref178\" id=\"context_ref_178_2d5\">[178]</a> showed that in comparison to deceptive statements, truthful statements contain more evidence of cognitive operations, which contrasts with RM theory.</p></div><div class=\"section_2\" id=\"sec2d6\"><h4>6) Criteria-Based Content Analysis (CBCA)</h4><p>Statement validity analysis (SVA) is a verbal deception detection technique used in sexual offense cases to judge the validity of statements of child witnesses <a ref-type=\"bibr\" anchor=\"ref179\" id=\"context_ref_179_2d6\">[179]</a> and is based on the Undeutsch hypothesis <a ref-type=\"bibr\" anchor=\"ref107\" id=\"context_ref_107_2d6\">[107]</a>. This technique was also applied to older witnesses in different types of cases and has four stages <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2d6\">[119]</a>. The core stage of this technique is the third one which is criteria-based content analysis (CBCA) <a ref-type=\"bibr\" anchor=\"ref106\" id=\"context_ref_106_2d6\">[106]</a> in which nineteen different criteria are evaluated by qualified evaluators in the written interview. Each of these criteria is believed to appear more repeatedly in truthful statements than in deceptive ones because it is very complicated to fake them <a ref-type=\"bibr\" anchor=\"ref179\" id=\"context_ref_179_2d6\">[179]</a>. These criteria are judged using a scale of 0 to 2, where \u201c0\u201d indicates the absence of criterion, \u201c1\u201d indicates the presence of criterion, and \u201c2\u201d indicates the strong presence of criterion. It was found that using a scale of 0 to 4 (five points) is preferable to a scale of 0 to 2 (three points) because it is more sensitive to minor variations between deceptive and truthful statements <a ref-type=\"bibr\" anchor=\"ref179\" id=\"context_ref_179_2d6\">[179]</a>. The nineteen criteria were divided into four categories: general characteristics, specific contents, motivation-related contents, and offense-specific elements.</p><p>The general characteristics category contains criteria 1 to 3: logical structure, unstructured production, and quantity of details. Logical structure (criterion 1) refers to the coherence and logical consistency of a statement, but it does not refer to plausibility. Unstructured production (criterion 2) refers to presenting information without considering the order in the time sequence. Quantity of details (criterion 3) refers to the richness of details such as locations, times, people, things, and events.</p><p>The specific contents category contains the criteria 4 to 13: contextual embedding, descriptions of interactions, reproduction of conversation, unexpected complications during the incident, unusual details, superfluous details, accurately reported details misunderstood, related external associations, accounts of subjective mental state, and attribution of perpetrator\u2019s mental state. Contextual embedding (criterion 4) is present when events are timed and located in a specific place. Descriptions of interactions (criterion 5) include the presence of information that connects the witness with the perpetrator. Reproduction of conversation (criterion 6) refers to the presence of direct dialogue using actual quotations of exact words used by someone. Unexpected complications during the incident (criterion 7) refer to the presence of unexpected elements. Unusual details (criterion 8) refer to the presence of unique, unforeseen, or surprising details regarding individuals, things, or events. Superfluous details (criterion 9) refer to unnecessary details of the event. Accurately reported details misunderstood (criterion 10) refer to giving details that are beyond the understanding of the person. Related external associations (criterion 11) refer to the presence of events that are related to the incident but not part of it. Accounts of subjective mental state (criterion 12) refer to describing how feelings change and thoughts are mentioned during the incident. Attribution of perpetrator\u2019s mental state (criterion 13) refers to describing motives, feelings, or thoughts of the perpetrator during the incident.</p><p>The motivation-related contents category contains criteria 14 to 18: spontaneous corrections, admitting lack of memory, raising doubts about one\u2019s own testimony, self-deprecation, and pardoning the perpetrator. Spontaneous corrections (criterion 14) refer to adding or correcting information of a previous statement. Admitting lack of memory (criterion 15) refers to forgetting, not remembering, or not knowing. Raising doubts about one\u2019s own testimony (criterion 16) refers to indicating the oddness and implausibility of a person\u2019s own statement. Self-deprecation (criterion 17) refers to revealing details that are negative or incriminating oneself. Pardoning the perpetrator (criterion 18) refers to excusing or failing to blame the perpetrator.</p><p>The offense-specific elements category contains only the details characteristic of the offense. Details characteristic of the offense (criterion 19) refer to describing parts that are considered typical for such a sort of offense by experts.</p><p>It is challenging to capture highly subjective criteria automatically; therefore, not all CBCA criteria are applicable for automatic deception detection <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_2d6\">[110]</a>.</p></div><div class=\"section_2\" id=\"sec2d7\"><h4>7) Scientific Content Analysis (Scan)</h4><p>Scientific content analysis (SCAN) <a ref-type=\"bibr\" anchor=\"ref108\" id=\"context_ref_108_2d7\">[108]</a> is a verbal deception detection technique. The SCAN procedure involves asking the person in question to write a detailed report of all the person\u2019s activities during a specific timeframe so that a reader with no prior knowledge of the situation can figure out what happened. Subsequently, a SCAN expert examines the handwritten statements using a set of criteria. Some SCAN criteria are assumed to be more probable to take place in truthful statements than in deceptive statements, while others are assumed to be more probable to take place in deceptive statements. SCAN has no fixed criteria list, but only twelve criteria were the focus of the research <a ref-type=\"bibr\" anchor=\"ref107\" id=\"context_ref_107_2d7\">[107]</a>, <a ref-type=\"bibr\" anchor=\"ref180\" id=\"context_ref_180_2d7\">[180]</a>, <a ref-type=\"bibr\" anchor=\"ref181\" id=\"context_ref_181_2d7\">[181]</a>.</p><p>The twelve SCAN criteria: denial of allegations, social introduction, spontaneous corrections, lack of conviction and memory, structure of statement, emotions, objective and subjective time, out-of-sequence and extraneous information, missing information, change in language, first person singular past tense, and pronouns.</p><p>Denial of allegations (criterion 1) refers to immediately denying the allegations that indicate truthfulness. Social introduction (criterion 2) refers to the clarity of introducing another person when the writer shows ambiguity and failure, such as avoiding mentioning their names or relationships, which indicates deception. Spontaneous corrections (criterion 3) are equivalent to criterion 14 in the CBCA; however, they are considered an indication of deception in the SCAN. Lack of conviction and memory (criterion 4) is equivalent to criterion 15 in CBCA; however, they are considered an indication of deception in SCAN. Structure of statement (criterion 5) refers to the statement\u2019s overall balance between describing activities prior to the event, describing the event itself, and describing what happened immediately after the event, while unbalanced statements may indicate deception. Emotions (criterion 6) are equivalent to criterion 12 in CBCA, but in SCAN, the position of emotions in the statement for truth-tellers is considered throughout the story and for deceivers before the story\u2019s climax. Objective and subjective time (criterion 7) refer to the coverage of time periods in a statement, where objective time is the actual period of the event, and subjective time is the number of words used to describe it. The correspondence between objective and subjective times indicates truthfulness. Out-of-sequence and extraneous information (criterion 8) is equivalent to criteria 2 and 9 in CBCA; however, they are considered an indication of deception in SCAN. Missing information (criterion 9) refers to omitting some information using words such as: \u201cfinally\u201d, \u201cshortly thereafter\u201d, \u201csometime after\u201d, and \u201clater on\u201d. First-person singular past tense (criterion 10) refers to using \u201cI\u201d and past tense while describing the event, which indicates truthfulness. Pronouns (criterion 11) refer to using pronouns in the statement such as: \u201cI\u201d, \u201cthey\u201d, \u201che\u201d, \u201cshe\u201d, \u201cmy\u201d, or \u201chis\u201d. The presence of pronouns reflects responsibility, possession, and commitment since the absence of pronouns indicates deception. Change in language (criterion 12) refers to using different terms to describe one thing without sufficient justification, which indicates deception.</p><p>The SCAN method had limited attempts from research to validate it and lacks theoretical underpinning and standardization, and there is no theoretical justification for why these criteria can differentiate between truthful and deceptive statements <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2d7\">[119]</a>, which is the main problem of this method. Another problem is that the common criteria between SCAN and CBCA conflict in the way of interpreting; SCAN experts consider them as indications of deception, but CBCA experts consider them as indications of truthfulness, although CBCA has more support from research <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2d7\">[119]</a>.</p></div><div class=\"section_2\" id=\"sec2d8\"><h4>8) Verifiability Approach (VA)</h4><p>The verifiability approach (VA) <a ref-type=\"bibr\" anchor=\"ref112\" id=\"context_ref_112_2d8\">[112]</a> is a verbal deception detection technique. This method is based on two assumptions that put liars in a dilemma. In the first assumption, research has repeatedly shown that providing more details indicates truthfulness <a ref-type=\"bibr\" anchor=\"ref119\" id=\"context_ref_119_2d8\">[119]</a>; therefore, liars want to provide as many details as possible to make a truthful impression <a ref-type=\"bibr\" anchor=\"ref182\" id=\"context_ref_182_2d8\">[182]</a>. The second assumption is that liars prefer to avoid providing a large number of details because they fear that these details can be checked and that their lies will be discovered <a ref-type=\"bibr\" anchor=\"ref182\" id=\"context_ref_182_2d8\">[182]</a>. To balance these two opposing targets, liars utilize a strategy that focuses on providing unverifiable details <a ref-type=\"bibr\" anchor=\"ref183\" id=\"context_ref_183_2d8\">[183]</a>.</p><p>The verifiability approach posits that information verifiability, or the possibility of verifying information without actually verifying it, can be used to distinguish between truthfulness and deception. Truth-tellers provide more verifiable perceptual, spatial, and temporal details than liars. The quantity of perceptual and contextual details reflects the richness in details only; however, for this approach, the quality of details is of interest.</p><p>An interesting part of their experiments is that telling the participants that they need verifiable details to be checked enlarges the difference between truth-tellers and liars, which improves their ability to detect lies. The difference is enlarged because truth-tellers try to provide more verifiable details. For RM, CBCA, and SCAN, telling participants about the detection method will make it less effective because these methods focus on the number of details and do not distinguish between verifiable and unverifiable details <a ref-type=\"bibr\" anchor=\"ref184\" id=\"context_ref_184_2d8\">[184]</a>. Looking for verifiable details makes the verifiability approach more effective when dealing with the strategic behavior of deceivers <a ref-type=\"bibr\" anchor=\"ref185\" id=\"context_ref_185_2d8\">[185]</a>. This approach is not affected by deceivers who have good imaginations or deceivers who describe actual experiences that occurred at other times, similar to CBCA and RM <a ref-type=\"bibr\" anchor=\"ref185\" id=\"context_ref_185_2d8\">[185]</a>.</p><p>The number of verifiable details can be assessed in relation to the total number of details. In particular, the quantity of verifiable perceptual and contextual details is divided by the overall quantity of verifiable and unverifiable perceptual and contextual details <a ref-type=\"bibr\" anchor=\"ref186\" id=\"context_ref_186_2d8\">[186]</a>.</p></div><div class=\"section_2\" id=\"sec2d9\"><h4>9) Truth-Default Theory (TDT)</h4><p>As the name of the theory suggests, the basic assumption of truth-default theory (TDT) <a ref-type=\"bibr\" anchor=\"ref147\" id=\"context_ref_147_2d9\">[147]</a> is that people trust and believe each other by default, which is called \u201ctruth bias\u201d or \u201ctruth default\u201d <a ref-type=\"bibr\" anchor=\"ref114\" id=\"context_ref_114_2d9\">[114]</a>, <a ref-type=\"bibr\" anchor=\"ref187\" id=\"context_ref_187_2d9\">[187]</a>. This theory posits that most people communicate honestly most of the time; therefore, truth bias is beneficial for efficient communication and for improving the accuracy of deception detection, even if this bias causes people to be deceived sometimes. The people\u2019s inability to detect lies has been proven to be incorrect. This theory emphasizes the accuracy of deception detection and credibility assessment.</p><p>TDT presents a new perspective in deception research that differs from the previous dominant perspective that can be classified as cue theories. It focuses on contextualized communication content (content in the context) rather than on non-verbal cues. Understanding context requires having background information. Context information contains basic data, such as the description of an event, location, or tools. The existence of context information improves the accuracy of detecting deceptive statements <a ref-type=\"bibr\" anchor=\"ref188\" id=\"context_ref_188_2d9\">[188]</a>. The TDT disagrees with previous studies that posit emotional leakage, cognitive effort, arousal, or self-presentation as indications of deception. The theory states that focusing on non-verbal behavior increases the noise around the deception signal, which decreases the accuracy of deception detection because most lies can be detected by checking correspondence or confession.</p><p>This theory does not try to define a new set of deception cues; it criticizes the idea of observing deception cues. Communication content refers to what is said, whereas deception cues refer to how the message is said and how people behave when saying it.</p><p>A lack of correspondence and coherence in content triggers suspicion and may indicate deception. Checking correspondence is related to comparing contextualized communication content with known facts and evidence. When evidence is not available, assessing the plausibility of the content should take place, while typical and usual scenarios are known. Logical consistency is also referred to as coherence. Messages from the same person that are truthful and consistent do not conflict with each other. In general, correspondence is more effective in detecting deception than coherence. Coherence was not found to be useful in differentiating between liars and truthful people <a ref-type=\"bibr\" anchor=\"ref189\" id=\"context_ref_189_2d9\">[189]</a>.</p><p>This theory posits that strategic questioning and active judgment increase the accuracy, which is not applicable in the case of online reviews. In general, because of the theoretical framework of the dominant perspective, it has been remarkably more useful than this new perspective in detecting computer-mediated deception <a ref-type=\"bibr\" anchor=\"ref190\" id=\"context_ref_190_2d9\">[190]</a>. The new perspective is still weak in terms of linguistics <a ref-type=\"bibr\" anchor=\"ref191\" id=\"context_ref_191_2d9\">[191]</a>, and the unavailability of evidence or prior knowledge to fact-check the content in some contexts makes the usage of cues more useful <a ref-type=\"bibr\" anchor=\"ref188\" id=\"context_ref_188_2d9\">[188]</a>, which is the case in the context of online reviews. This new perspective is helpful in interrogative contexts <a ref-type=\"bibr\" anchor=\"ref192\" id=\"context_ref_192_2d9\">[192]</a>.</p></div><div class=\"section_2\" id=\"sec2d10\"><h4>10) Information Manipulation Theory (IMT)</h4><p>Information manipulation theory (IMT) <a ref-type=\"bibr\" anchor=\"ref93\" id=\"context_ref_93_2d10\">[93]</a> is one of the most important theories from the new perspective. IMT shifts the focus from non-verbal cues to deceptive message design. It also suggested a method that can categorize deceptive messages, while previous studies were limited to only three types: distortion, omission, and falsification.</p><p>According to IMT, deceptive messages work by violating the principles that govern conversational exchanges in a covert manner. These principles are called Grice\u2019s maxims <a ref-type=\"bibr\" anchor=\"ref193\" id=\"context_ref_193_2d10\">[193]</a>: quantity, quality, manner, and relevance of information. Quantity refers to the expected amount of relevant information provided that makes a message informative. Quality refers to the expected information veracity. Manner refers to the expected avoidance of ambiguity. Relevance refers to expected relevant information based on a prior argument.</p><p>Deceptive messages are produced by manipulating the information. Information manipulation refers to violating one or more of Grice\u2019s four maxims. Quantity violations (omission) refer to changing the amount of sensitive information revealed in a message; therefore, it will be less informative. Quality violations (falsification) refer to information distortion, either by distorting sensitive information or fabricating the entire message. Manner violations (equivocation) refer to the use of traditionally ambiguous phrases and indirect expressions rather than clarity of expression in attempting to hide the truth. Relevance violations (evasion) refer to providing irrelevant information or failing to provide any contextually relevant information to divert attention.</p><p>IMT was extended to information manipulation theory 2 (IMT2) <a ref-type=\"bibr\" anchor=\"ref194\" id=\"context_ref_194_2d10\">[194]</a>. The IMT2 is a message-production theory for deception. It consists of three proposition groups: intentional states, cognitive load, and information manipulation. This theory disagrees with the dominant perspective that cognitive load is higher in deception than in truthfulness. IMT2 shows that the most frequent type of deceptive message is quantity violations (omission), followed by quality violations (falsification), manner violations (equivocation), and relevance violations (evasion). IMT2 posits that people with high integrity have almost no motive to lie because they have nothing to hide.</p><p>The limitation of our work here is that we are unable to cover all existing deception theories, which may have different directions for interpreting the deception phenomena. We focus only on the most popular and influential deception theories.</p></div></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION III.</div><h2>Our Research Methodology</h2></div><p>The proposed method can be summarized as follows: First, ten deception theories were synthesized: leakage theory, four-factor theory, self-presentational theory, IDT, RM, CBCA, SCAN, VA, TDT, and IMT / IMT2. Second, the constructs of deception were collected from the synthesized deception theories. Third, important constructs were selected based on specific criteria. Fourth, a theoretical model was formulated based on the important constructs. Fifth, the theoretical model was empirically validated using online reviews datasets by preprocessing the data, extracting features, applying classification methods, and evaluating the model. (See <b><a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">FIGURE 1</a></b>)\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul1-3227631-large.gif\" data-fig-id=\"fig1\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul1-3227631-small.gif\" alt=\"FIGURE 1. - Our five-phase research methodology.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>Our five-phase research methodology.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p><div class=\"section_2\" id=\"sec3a\"><h3>A. Selecting Constructs of Deception</h3><p>From the synthesized deception theories and theory-based models, it can be observed that there was a great variety in the use of terms expressing the same constructs. Some studies, such as L. Zhou et al. <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a\">[101]</a>, have determined the constructs that were derived from theories and used them as categories for features. Therefore, before selecting constructs, we put the factors, cues, or criteria derived from deception theories and share the same focus under the same construct. This facilitates understanding of the focus and usage frequency in deception theories (see <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>). We determined a group of constructs from the synthesized deception theories and then selected or excluded from them based on a set of criteria, where each construct must satisfy all criteria to be selected (see <b><a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">TABLE 3</a></b>).<div class=\"figure figure-full table\" id=\"table3\"><div class=\"figcaption\"><b class=\"title\">TABLE 3 </b>\nSummary of Criteria-Based Constructs Selection</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t3-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t3-3227631-small.gif\" alt=\"Table 3- &#10;Summary of Criteria-Based Constructs Selection\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table4\"><div class=\"figcaption\"><b class=\"title\">TABLE 4 </b>\nUsage Summary of Selected Constructs in Deception Theories</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t4-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t4-3227631-small.gif\" alt=\"Table 4- &#10;Usage Summary of Selected Constructs in Deception Theories\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>The constructs from synthesized deception theories are specificity, quantity, non-immediacy, affect, uncertainty, informality, consistency, source credibility, deviation in behavior, diversity, complexity, spontaneous corrections, response time, body constructs, voice constructs, eye constructs, and face constructs.</p><p>The criteria used for construct selection were as follows:\n<ul style=\"list-style-type:disc\"><li><p><b>Criterion 1 (C1):</b> \u201cused in theory-based models\u201d. This refers to whether the construct was used by previous theory-based models of deception detection in computer-mediated texts (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>).</p></li><li><p><b>Criterion 2 (C2):</b> \u201chad consistent validation results\u201d. This refers to whether the construct had consistent results and received support across previous theory-based models of deception detection in computer-mediated texts.</p></li><li><p><b>Criterion 3 (C3):</b> \u201ccomputationally measurable\u201d. This refers to the ability to measure a construct computationally in the context of the computer-mediated texts.</p></li><li><p><b>Criterion 4 (C4):</b> \u201cavailable related data attributes\u201d. This refers to whether the public online reviews datasets have attributes for data points that enable us to measure the construct empirically.</p></li></ul></p><p>The selected constructs that satisfied all four criteria (from no. 1 to 9 in <b><a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">TABLE 3</a></b>) were specificity, quantity, non-immediacy, affect, uncertainty, informality, consistency, source credibility, and deviation in behavior. The excluded constructs that did not satisfy one or more criteria (from no. 10 to 17 in <b><a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">TABLE 3</a></b>) were diversity, complexity, spontaneous corrections, response time, body constructs, voice constructs, eye constructs, and face constructs. The details of selection and exclusion are provided in the following two subsections.</p><div class=\"section_2\" id=\"sec3a1\"><h4>1) Selected Constructs and Theoretical Model</h4><p>Verbal constructs:\n<ul style=\"list-style-type:disc\"><li><p>Specificity</p></li><li><p>Quantity</p></li><li><p>Non-immediacy</p></li><li><p>Affect</p></li><li><p>Uncertainty</p></li><li><p>Informality</p></li><li><p>Consistency</p></li></ul> Non-verbal constructs:\n<ul style=\"list-style-type:disc\"><li><p>Source Credibility</p></li><li><p>Deviation in behavior</p></li></ul> The above-selected constructs, the reasons for selection, and the formulation of the theoretical model are explained as follows:</p><p>Deception theories use specificity in the language to assess whether the statement is clear, precise, unique, exact, related to the subject, and the number of details included. In the IDT, lack of specificity was used to indicate deception. According to self-presentational theory, deceptive messages are less detailed. In RM, clarity, the existence of perceptual information, and contextual information (temporal and spatial) are used to indicate truthfulness. In CBCA, most of the criteria were only for specificity, criteria 3 to 11: contextual embedding, descriptions of interactions, reproduction of conversation, unexpected complications during the incident, unusual details, superfluous details, accurately reported details misunderstood, and related external associations. In addition to criterion 19: details characteristic of the offense. In SCAN, social introduction (criterion 2) is related to specificity. For VA, since it focuses on verifiable perceptual, spatial, and temporal details and all of them reflect specificity as an indication of truthfulness. In TDT, contextual content requires contextual information. In IMT and IMT2, quality and relevance are two maxims related to specificity to assess the message content. Specificity is the most frequently used construct in theory-based models and deception theories (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>, <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>). This was supported by theory-based models as a construct that discriminates between deception and truthfulness <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_3a1\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref92\" id=\"context_ref_92_3a1\">[92]</a>, <a ref-type=\"bibr\" anchor=\"ref111\" id=\"context_ref_111_3a1\">[111]</a>, <a ref-type=\"bibr\" anchor=\"ref113\" id=\"context_ref_113_3a1\">[113]</a>, <a ref-type=\"bibr\" anchor=\"ref123\" id=\"context_ref_123_3a1\">[123]</a>. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 1 (H1):</i> Incorporating \u2018specificity\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use quantity in the language to assess the amount of information in the statement. IDT and self-presentational theory posit that deceptive messages are short and brief, reflecting less quantity while trying to hide and omit information. In SCAN, missing information (criterion 9) is related to quantity. In IMT and IMT2, quantity is one maxim to assess the message content. Quantity is one of the most frequently used constructs in theory-based models (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>). It was supported by some theory-based models <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a1\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a1\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a1\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref113\" id=\"context_ref_113_3a1\">[113]</a>, <a ref-type=\"bibr\" anchor=\"ref115\" id=\"context_ref_115_3a1\">[115]</a>, <a ref-type=\"bibr\" anchor=\"ref123\" id=\"context_ref_123_3a1\">[123]</a> as a construct that discriminates between deception and truthfulness. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 2 (H2):</i> Incorporating \u2018quantity\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use non-immediacy in the language to assess warmth, closeness, and involvement. The four-factor theory posits that deceivers are less immediate than truth-tellers. Leakage theory points out that indirect speech is an indication of deception. The IDT and self-presentational theory focus on non-immediacy and non-involvement with clear verbal cues. In SCAN, immediacy is measured verbally from pronoun usage and verb tenses. Non-immediacy is one of the most frequently used constructs in deception theories (see <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>). This was supported by some theory-based models <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a1\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a1\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a1\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_3a1\">[110]</a>, <a ref-type=\"bibr\" anchor=\"ref122\" id=\"context_ref_122_3a1\">[122]</a> as a construct that discriminates between deception and truthfulness. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 3 (H3):</i> Incorporating \u2018non-immediacy\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use affect in the language to assess emotions and feelings. Leakage theory, four-factor theory, interpersonal deception theory, and self-presentational theory posit that negative emotions indicate deception such as guilt, fear, anxiety, and nervousness. In RM, affective information and cognitive operations are used to assess emotions, thoughts, and opinions. CBCA has two criteria related to affect, criterion 12 and criterion 13: accounts of subjective mental state, and attribution of perpetrator\u2019s mental state. In SCAN, emotions (criterion 6) are related to affect. Affect is the second most frequently used construct in both deception theories and theory-based models (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>, <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>). The affect construct was supported by some theory-based models <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a1\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a1\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a1\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref122\" id=\"context_ref_122_3a1\">[122]</a>, <a ref-type=\"bibr\" anchor=\"ref123\" id=\"context_ref_123_3a1\">[123]</a> as a construct that discriminates between deception and truthfulness. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 4 (H4):</i> Incorporating \u2018affect\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use uncertainty in the language to assess sureness, doubtfulness, ambiguity, or vagueness. The IDT and self-presentational theory posit that deceptive messages are vague, reflecting less certainty. The CBCA has two criteria for certainty: admitting lack of memory (criterion 15) and raising doubts about one\u2019s own testimony (criterion 16). In SCAN, lack of conviction and memory (criterion 4) is related to uncertainty. In IMT and IMT2, manner is one maxim related to uncertainty to assess the message content. Uncertainty is one of the most frequently used constructs in deception theories (see <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>). This was supported by some theory-based models <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a1\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a1\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a1\">[101]</a> as a construct that discriminates between deception and truthfulness. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 5 (H5):</i> Incorporating \u2018uncertainty\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use informality in the language to assess whether a person uses a non-fluent or unofficial language. Leakage theory, four-factor theory, IDT, and self-presentational theory posit that deceptive messages have more speech mistakes and non-fluencies than truthful ones. This was supported by some theory-based models <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a1\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a1\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a1\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref123\" id=\"context_ref_123_3a1\">[123]</a> as a construct that discriminates between deception and truthfulness. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 6 (H6):</i> Incorporating \u2018informality\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Deception theories use consistency in the language to assess logic, plausibility, coherence, or correspondence. Leakage and self-presentational theories posit that deceptive content is less plausible and internally inconsistent. In RM, realism is considered an indication of truthful statements. In CBCA, logical structure (criterion 1) refers to logical consistency and coherence as indications for truthful statements. In TDT, correspondence and coherence are used to assess message credibility. This was supported by strong empirical evidence from G. Shan et al. <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_3a1\">[29]</a>, who investigated three types of inconsistency and their ability to distinguish between fake and truthful reviews. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 7 (H7):</i> Incorporating \u2018consistency\u2019 improves the prediction performance of the fake reviews detection model.</p><p>The IDT uses source credibility to assess the sender as a source of information if it is reliable, reputable, believable, and trustworthy. In IDT, source credibility is considered by the theory as a critical attribute to measure the believability of the sender in terms of character, competence, composure, sociability, and dynamism. Source credibility is one of the most frequently used constructs in theory-based models (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>). Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 8 (H8):</i> Incorporating \u2018source credibility\u2019 improves the prediction performance of the fake reviews detection model.</p><p>The IDT uses deviation in behavior to assess the extent to which a person\u2019s behavior departs from normal, average, usual, common, and expected behavior. The IDT posits that as the sender\u2019s behavior deviates from normalcy, natural, reciprocity, ideal, or moderate involvement, it should be suspected. Deviation in behavior is one of the most frequently used constructs in theory-based models (see <b><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">TABLE 2</a></b>). Some studies <a ref-type=\"bibr\" anchor=\"ref125\" id=\"context_ref_125_3a1\">[125]</a>, <a ref-type=\"bibr\" anchor=\"ref126\" id=\"context_ref_126_3a1\">[126]</a>, <a ref-type=\"bibr\" anchor=\"ref128\" id=\"context_ref_128_3a1\">[128]</a>, <a ref-type=\"bibr\" anchor=\"ref132\" id=\"context_ref_132_3a1\">[132]</a>, <a ref-type=\"bibr\" anchor=\"ref133\" id=\"context_ref_133_3a1\">[133]</a>, <a ref-type=\"bibr\" anchor=\"ref134\" id=\"context_ref_134_3a1\">[134]</a> have called this construct external consistency or review consistency. This was supported by strong empirical evidence from D. Zhang et al. <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_3a1\">[42]</a> and G. Shan et al. <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_3a1\">[29]</a>, who investigated a set of non-verbal behavioral aspects of reviewers and evaluated their relevance for detecting fake reviews. Therefore, the following hypothesis is proposed:</p><p><i>Hypothesis 9 (H9):</i> Incorporating \u2018Deviation in behavior\u2019 improves the prediction performance of the fake reviews detection model.</p><p>Based on the above hypotheses, the theoretical model of fake reviews detection was formulated (see <b><a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">FIGURE 2</a></b>). By synthesizing and selecting deception constructs from deception theories and then formulating the theoretical model of fake reviews detection in this section, we achieved our first research objective (RO1).\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul2-3227631-large.gif\" data-fig-id=\"fig2\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul2-3227631-small.gif\" alt=\"FIGURE 2. - Theoretical model of fake reviews detection.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>Theoretical model of fake reviews detection.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p><p>From <b><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">TABLE 4</a></b>, we can see that the most frequently used constructs in deception theories are specificity, affect, non-immediacy, uncertainty, and consistency.</p></div><div class=\"section_2\" id=\"sec3a2\"><h4>2) Excluded Constructs</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Body Constructs</p></li><li><p>Voice Constructs</p></li><li><p>Eye Constructs</p></li><li><p>Face Constructs</p></li><li><p>Spontaneous Corrections</p></li><li><p>Response Time</p></li><li><p>Diversity</p></li><li><p>Complexity</p></li></ul> The above-excluded constructs and the reasons for exclusion are explained as follows:</p><p>The constructs of deception include constructs related to body movements, voice pitch, eye gaze, and facial expressions. These constructs are applicable to face-to-face interactive communication, videotaped interviews, or audiotaped interviews and are not applicable in the context of online reviews or any computer-mediated text. Therefore, based on the four criteria, all these constructs and their related factors, cues, or criteria are neglected.</p><p>Some constructs are computationally measurable, but no attributes in the available online reviews datasets can support their measurement. Spontaneous corrections and response time are examples of these constructs. Spontaneous corrections in language are used by deception theories to assess whether the person edits, revises, or rewrites his statements. According to self-presentational theory, deceivers are less spontaneous than truth-tellers, which means that their deceptive messages are less influenced by narrative mistakes than truthful ones. Spontaneous corrections are used as a criterion in CBCA and SCAN; however, they are considered an indication of truthfulness in CBCA and an indication of deception in SCAN. The response time is used by deception theories to assess the latency of responses and unfilled pauses due to cognitive effort. According to the leakage theory and IDT, deceivers may take more time to respond, especially when they are subjected to suspicion. Spontaneous corrections and response time were used in the theory-based model, but in a chat-based communication context using a self-implemented tool <a ref-type=\"bibr\" anchor=\"ref115\" id=\"context_ref_115_3a2\">[115]</a>. R. Banerjee et al. <a ref-type=\"bibr\" anchor=\"ref195\" id=\"context_ref_195_3a2\">[195]</a> empirically investigated both spontaneous corrections and response time as indications for deception using keystroke patterns, and the results were promising for both constructs. They did not use an off-the-shelf dataset but instead used a self-implemented key logger and crowd-sourcing approach. Therefore, spontaneous corrections and response time were neglected.</p><p>Some studies <a ref-type=\"bibr\" anchor=\"ref99\" id=\"context_ref_99_3a2\">[99]</a>, <a ref-type=\"bibr\" anchor=\"ref100\" id=\"context_ref_100_3a2\">[100]</a>, <a ref-type=\"bibr\" anchor=\"ref101\" id=\"context_ref_101_3a2\">[101]</a>, <a ref-type=\"bibr\" anchor=\"ref110\" id=\"context_ref_110_3a2\">[110]</a>, <a ref-type=\"bibr\" anchor=\"ref121\" id=\"context_ref_121_3a2\">[121]</a>, <a ref-type=\"bibr\" anchor=\"ref122\" id=\"context_ref_122_3a2\">[122]</a> have considered lexical complexity and lexical diversity in language as constructs derived from deception theories or other psychological studies to differentiate between fake and truthful reviews. These two constructs showed conflicting results from one study to another. Therefore, lexical complexity and diversity were neglected.</p></div></div><div class=\"section_2\" id=\"sec3b\"><h3>B. Textual Data Preprocessing</h3><div class=\"section_2\" id=\"sec3b1\"><h4>1) Lower Casing</h4><p>The lower casing is the process of transforming all letters of text into lowercase. The main purpose of this process is to prepare words for the case-sensitive tools. In our case, the LIWC analysis library is case-sensitive, whereas all words in its main dictionary are lowercase words. If there is only one letter in a word written in the upper case (capital letter), the category of the word will be missed by the LIWC analysis.</p></div><div class=\"section_2\" id=\"sec3b2\"><h4>2) Tokenization</h4><p>Tokenization is the process of dividing a review text into smaller units, called tokens, which can be either words or sentences. Word tokenization was used before the LIWC analysis, spell checker, and review length calculation. Whitespace tokenization was used only before LIWC analysis because of its sensitivity in detecting the categories of each word. For spell checker and review length calculation, the NLTK toolkit library was used for this purpose. Sentence tokenization was used for two purposes: before the passive-voice detector (PassivePy) to calculate the percentage of passive-voice sentences and before the location of maximum affect calculation.</p></div><div class=\"section_2\" id=\"sec3b3\"><h4>3) Punctuation Removal</h4><p>Punctuation removal is the process of removing all punctuations in a text. This process cleans text before calculating the length of the review to avoid counting the punctuations as words in a review text.</p></div></div><div class=\"section_2\" id=\"sec3c\"><h3>C. Feature Selection and Extraction</h3><p>To validate the theoretical model after selecting the verbal and the non-verbal constructs from deception theories, it is required to select features that can characterize these constructs on the one hand, and that can be measured from the review texts and the reviewer\u2019s behavior on the other hand. (For the symbols used in the equations below, see <b><a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">TABLE 5</a></b>).<div class=\"figure figure-full table\" id=\"table5\"><div class=\"figcaption\"><b class=\"title\">TABLE 5 </b>\nList of Symbols for the Feature Extraction Methods</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t5-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t5-3227631-small.gif\" alt=\"Table 5- &#10;List of Symbols for the Feature Extraction Methods\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><div class=\"section_2\" id=\"sec3c1\"><h4>1) Specificity Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Generalization terms usage (F1)</p></li><li><p>Richness of details (F2)</p></li><li><p>Richness of verifiable details (F3)</p></li></ul> According to IDT, deceivers may employ generalization terms to avoid specificity. These terms are also called leveling terms, all-ness terms, over-generalization terms, words of absoluteness, or absolutist words. Examples of these terms include: \u201call\u201d, \u201ceverything\u201d, \u201ctotally\u201d, \u201ceveryone\u201d\u2026etc. We used the validated list of nineteen absolutist words which was provided by M. Al-Mosaiwi et al. <a ref-type=\"bibr\" anchor=\"ref196\" id=\"context_ref_196_3c1\">[196]</a> to calculate the ratio of using these terms in a review text. Consider the following examples using generalization terms:\n<ol><li><p>\u201c<u><b>Everything</b></u> in this place is amazing\u201d</p></li><li><p>\u201cIt\u2019s a <u><b>totally</b></u> bad restaurant. <u><b>Nothing</b></u> good\u201d</p></li></ol></p><p>Suppose that G is a set of generalization terms and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$R_{t}$\n</tex-math></inline-formula> is the text of a review. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{1}$\n</tex-math></inline-formula> is the ratio of generalization words to the total number of words in a review text. The generalization terms usage in the text can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{1}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in G }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{1}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in G }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$w$\n</tex-math></inline-formula> is a word in the text of review.</p><p>The RM theory posits that perceptual and contextual information are present in memories of real experiences. Perceptual information refers to sounds, smells, tastes, touches, or visual details. Contextual information refers to temporal details (time of occurrence, time order, and duration) and spatial details (places of occurrence and positions of objects or people). CBCA posits that the quantity of details and contextual embedding are two signs of truthfulness. Quantity of details refers to the richness of details such as locations, times, people, things, and events. Contextual embedding is present when events are timed and located in a specific place. We used the LIWC category \u201cperceptual processes\u201d to capture the perceptual information from the review text. We also used the LIWC categories \u201ctime\u201d and \u201cspace\u201d to capture the temporal and spatial information from the review text. Therefore, these three categories were used to calculate the richness of the details in the review. Consider the following example of perceptual and contextual details:\n<ol><li><p>\u201cI visited this <u><b>place</b></u> in the <u><b>morning</b></u>. It is <u><b>near</b></u> home. The food was <u><b>spicy</b></u> and <u><b>delicious</b></u>\u201d</p></li></ol></p><p>Suppose that TS is a set of words in the \u201ctime\u201d and \u201cspace\u201d categories and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> is a set of words in the \u201cperceptual processes\u201d category inside the LIWC dictionary. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{2}$\n</tex-math></inline-formula> is the ratio of perceptual and contextual words to the total number of words in a review text. The richness of details can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{2}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in P\\cup \\mathrm {TS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{2}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in P\\cup \\mathrm {TS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>SCAN has \u201csocial introduction\u201d as a criterion which means that the clearness of introducing other persons is an indication of truthfulness, and avoiding mentioning their names or their relationship indicates deception. For VA, truth-tellers provide more verifiable details than liars. The existence of named entities almost meets the real verifiability standards <a ref-type=\"bibr\" anchor=\"ref111\" id=\"context_ref_111_3c1\">[111]</a>, <a ref-type=\"bibr\" anchor=\"ref197\" id=\"context_ref_197_3c1\">[197]</a>. Therefore, we used NER in the spaCy library to extract eighteen categories of named entities: persons, facilities, money, organizations, geo-political entities, locations, dates, nationalities or religious groups, times, products, events, works of art, law documents, languages, percentages, quantities, ordinals, and cardinals. We then calculated the quantity of these named entities in the review text to represent the quantity of verifiable details. Assessing the quantity of verifiable details can be done in relation to the total quantity of details. In particular, the quantity of verifiable details is divided by the overall quantity of verifiable and unverifiable details <a ref-type=\"bibr\" anchor=\"ref186\" id=\"context_ref_186_3c1\">[186]</a>. In example (3), there are no verifiable details. Consider the following example for verifiable details:\n<ol><li><p>\u201cWhen I visited <u><b>San Francisco</b></u> on <u><b>August 12th this year</b></u>, I went to this restaurant and at <u><b>9 AM</b></u>. <u><b>One</b></u> of them called <u><b>Omar</b></u> served me the food and he was very cheerful.\u201d</p></li></ol></p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$V$\n</tex-math></inline-formula> is a set of named entities in the review text. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{3}$\n</tex-math></inline-formula> is the ratio of words that provide verifiable details to the total number of words that provide verifiable or unverifiable details in a review text. The richness of verifiable details can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{3}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in V }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in P\\cup \\mathrm {TS} }\\right \\} }\\right |\\!+\\!\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in V }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{3}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in V }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in P\\cup \\mathrm {TS} }\\right \\} }\\right |\\!+\\!\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in V }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c2\"><h4>2) Quantity Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Length of the review (F4)</p></li></ul> Self-presentational theory and IDT posit that the deceptive messages are short and brief which reflects less quantity of information.</p><p>We used the number of words to calculate the quantity of the review. The length of the review can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{4}=\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{4}=\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c3\"><h4>3) Non-Immediacy Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>First-person singular pronouns usage (F5)</p></li><li><p>First-person plural pronouns usage (F6)</p></li><li><p>Third-person pronouns usage (F7)</p></li><li><p>Present-tense verbs usage (F8)</p></li><li><p>Past-tense verbs usage (F9)</p></li><li><p>Passive voice usage (F10)</p></li><li><p>Negations usage (F11)</p></li></ul> IDT, SCAN, and leakage theory posit that deceivers may use group or other references (first-person plural pronouns or third-person pronouns) such as: \u201cthey\u201d or \u201cwe\u201d more than self-references (first-person singular pronouns) such as: \u201cme\u201d or \u201cI\u201d which reflects non-immediacy. SCAN has a criterion for \u201cpronouns\u201d which considers using personal pronouns in the statement such as: \u201cI\u201d, \u201cthey\u201d, \u201che\u201d, \u201cshe\u201d, \u201cmy\u201d, or \u201chis\u201d. The presence of pronouns reflects responsibility, possession, and commitment since the absence of pronouns indicates deception. POS tagging provides one tag type for all levels of personal pronouns. Therefore, we used the LIWC category \u201cpersonal pronouns\u201d and its subcategories \u201c1st personal singular\u201d, \u201c1st personal plural\u201d, \u201c3rd personal singular\u201d, and \u201c3rd personal plural\u201d to capture the usage of pronouns in the review text. Consider the following examples for first-person singular pronouns usage, first-person plural pronouns usage, and third-person pronouns usage, respectively:\n<ol><li><p>\u201cFor <u><b>me</b></u> it was a great meal. <u><b>I</b></u> sat for a few minutes until <u><b>my</b></u> order was prepared.\u201d</p></li><li><p>\u201c<u><b>We</b></u> went to that place in the morning, and everyone served <u><b>us</b></u> perfectly.\u201d</p></li><li><p>\u201c<u><b>They</b></u> delayed my order for no reason, but <u><b>their</b></u> meals are very tasty.\u201d</p></li></ol></p><p>Suppose that FS is a set of words in the \u201c1st personal singular\u201d category and PP is a set of words in the \u201cpersonal pronouns\u201d category inside the LIWC dictionary. Where FS <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\subset $\n</tex-math></inline-formula> PP. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{5}$\n</tex-math></inline-formula> is the ratio of first-person singular pronouns to the total number of pronouns in a review text. The first-person singular pronouns usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{5}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {FS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{5}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {FS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that FP is a set of words in the \u201c1st personal plural\u201d category inside the LIWC dictionary. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {FP} \\subset \\mathrm {PP}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{6}$\n</tex-math></inline-formula> is the ratio of first-person plural pronouns to the total number of pronouns in a review text. The first-person plural pronouns usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{6}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {FP} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{6}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {FP} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that TP is a set of words in the \u201c3rd personal singular\u201d and \u201c3rd personal plural\u201d categories inside LIWC dictionary. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {TP}\\subset \\mathrm {PP}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{7}$\n</tex-math></inline-formula> is the ratio of third-person pronouns to the total number of pronouns in a review text. The third-person pronouns usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{7}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {TP} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{7}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {TP} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PP} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>For IDT, deceivers are more likely to use past-tense verbs than present-tense verbs, reflecting non-immediacy in time. However, for SCAN, using the past tense when describing an event indicates truthfulness. We used POS tagging in the spaCy library to identify verbs and their sub-categories, including past and present tenses in a review text. Consider the following examples for using present tense and past tense, respectively:\n<ol><li><p>\u201cWe <u><b>go</b></u> there almost every evening.\u201d</p></li><li><p>\u201cI <u><b>visited</b></u> this coffee once. The latt\u00e9 <u><b>was</b></u> tasty.\u201d</p></li></ol></p><p>Suppose that PR is a set of present verbs and VR is a set of all verbs. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {PR}\\subset \\mathrm {VR}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{8}$\n</tex-math></inline-formula> is the ratio of present verbs to the total number of verbs in a review text. The present-tense verbs usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{8}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PR} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {VR} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{8}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PR} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {VR} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that PS is a set of past verbs. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {PS}\\subset \\mathrm {VR}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{9}$\n</tex-math></inline-formula> is the ratio of past verbs to the total number of verbs in a review text. The past-tense verbs usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{9}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {VR} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{9}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {VR} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>The self-presentational theory posits that the usage of passive voice in the deceptive message is more than the usage of active voice to reduce immediacy. We used the PassivePy tool <a ref-type=\"bibr\" anchor=\"ref198\" id=\"context_ref_198_3c3\">[198]</a> to identify sentences in passive voice from the review text. Consider the following examples of passive voice:\n<ol><li><p>\u201cThe place <u><b>is wonderfully arranged</b></u> to provide privacy to everyone. All meals <u><b>are professionally served</b></u>.\u201d</p></li></ol></p><p>Suppose that PV is a set of passive-voice sentences. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{10}$\n</tex-math></inline-formula> is the ratio of passive voice sentences to the total number of sentences in a review\u2019s text. The passive voice usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{10}=\\frac {\\left |{ \\left \\{{S:S\\in R_{t}\\wedge S\\in \\mathrm {PV} }\\right \\} }\\right |}{\\left |{ \\left \\{{S:S\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{10}=\\frac {\\left |{ \\left \\{{S:S\\in R_{t}\\wedge S\\in \\mathrm {PV} }\\right \\} }\\right |}{\\left |{ \\left \\{{S:S\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S$\n</tex-math></inline-formula> is a sentence in a review\u2019s text.</p><p>The self-presentational theory posits that the usage of negations in the deceptive message is more than the usage of assertions to reduce immediacy. We used the LIWC category \u201cnegations\u201d to capture the negations usage in the review text. Consider the following example of negations usage:\n<ol><li><p>\u201cIt <u><b>wasn\u2019t</b></u> as expected, I <u><b>couldn\u2019t</b></u> have imagined this level of irresponsibility.\u201d</p></li></ol></p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> is a set of words in the \u201cnegations\u201d category inside the LIWC dictionary. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{11}$\n</tex-math></inline-formula> is the ratio of negations to the total number of words in a review text. The negations usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{11}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in N }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{11}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in N }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c4\"><h4>4) Affect Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Sentiment polarity (F12)</p></li><li><p>Sentiment subjectivity (F13)</p></li><li><p>Positive emotion words usage (F14)</p></li><li><p>Negative emotion words usage (F15)</p></li><li><p>Location of maximum affect (F16)</p></li></ul> The leakage and four-factor theories posit that emotional reactions are related to deception. Deceivers may feel guilty, fearful, or excited. The self-presentational theory posits that deceptive messages are less positive and more negative. Deceivers are more anxious and nervous. CBCA has a criterion for the subjective mental state which refers to describing how feelings change and mentioning the thoughts, and another criterion for the perpetrator\u2019s mental state which refers to describing the motives, feelings, or thoughts of the perpetrator during the incident. We used the TextBlob sentiment analyzer to extract two dimensions of sentiment from a review: polarity and subjectivity. Polarity indicates whether a sentence is positive or negative. Subjectivity indicates whether the judgment is based on personal opinion or factual information. We also used the LIWC category \u201caffective processes\u201d including its subcategories \u201cnegative emotion\u201d and \u201cpositive emotion\u201d to capture the usage of positive and negative emotion words in the review text. Consider the following examples for positive emotion usage, negative emotion usage, and subjective sentence, respectively:\n<ol><li><p>\u201cI am <u><b>very happy</b></u> with this experience. It was <u><b>amazing</b></u>.\u201d</p></li><li><p>\u201cIt was a <u><b>bad</b></u> experience. Everything is <u><b>disgusting</b></u>.\u201d</p></li><li><p>\u201cIt\u2019s a <u><b>wonderful</b></u> place.\u201d</p></li></ol></p><p>The sentiment polarity can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{12}=polarity\\left ({R_{t} }\\right),\\quad [-1,1]\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{12}=polarity\\left ({R_{t} }\\right),\\quad [-1,1]\\end{equation*}\n</span></span></disp-formula></p><p>The sentiment subjectivity can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{13}=subject\\left ({R_{t} }\\right),\\quad [{0,1}]\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{13}=subject\\left ({R_{t} }\\right),\\quad [{0,1}]\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that PE is a set of words in the \u201cpositive emotion\u201d category and AF is a set of words in the \u201caffective processes\u201d category inside the LIWC dictionary. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {PE}\\subset \\mathrm {AF}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{14}$\n</tex-math></inline-formula> is the ratio of positive emotion words to the total number of affect words in a review text. The positive emotion words usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{14}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PE} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{14}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {PE} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that NE is a set of words in the \u201cnegative emotion\u201d category inside the LIWC dictionary. Where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {NE}\\subset \\mathrm {AF}$\n</tex-math></inline-formula>. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{15}$\n</tex-math></inline-formula> is the ratio of negative emotion words to the total number of affect words in a review text. The negative emotion words usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{15}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {NE} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{15}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {NE} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>SCAN has one criterion for emotions but it does not only consider the existence of emotions, it rather considers the position of emotions in a statement. For truth-tellers, the emotions are expected to be present throughout the story, while deceivers are expected to show emotions before the story\u2019s climax. A. Sepehri et al. <a ref-type=\"bibr\" anchor=\"ref199\" id=\"context_ref_199_3c4\">[199]</a> conducted analyses at the sentence level to investigate the location of maximum emotion in deception and truth using two datasets, one for news and the other for reviews. Their findings were consistent with the SCAN criterion, and they found that the maximum emotion location for deceptive texts was at the beginning. They suggested a method to measure the location of the maximum affect: (a) tokenize each text at the sentence level, (b) score each sentence using the LIWC category \u201caffective processes\u201d to calculate the emotion ratio, (c) determine the sentence number with the maximum score of affect, and (d) divide the sentence number by the number of sentences in the text. A smaller result indicates that the location of maximum affect is at the beginning. They found no difference in patterns between using sentiment analysis and LIWC-based affect scores. Therefore, we used the LIWC-based method to calculate the location of the maximum affect. Consider the following example of maximum affect located at the beginning of the statement:\n<ol><li><p>\u201cI am <u><b>frustrated</b></u>, <u><b>angry</b></u>, and very <u><b>upset</b></u>. I thought the <u><b>worst</b></u> thing about this place was the long waiting time. It will be the last time I visit this place.\u201d</p></li></ol></p><p>For each sentence in a review text, it is required to calculate the ratio of affect words to the total number of words, so it will be possible to get the index of the sentence that has the maximum score and determine its location. The location of maximum affect can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\forall S\\in R_{t},\\quad f_{16}(S)=&amp;\\frac {\\left |{ \\left \\{{ w:w\\in S\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in S }\\right \\} }\\right |}\\\\ F_{16}=&amp;\\frac {index(\\mathrm {max}(f_{16}(S)))}{\\left |{ \\left \\{{S:S\\in R_{t} }\\right \\} }\\right |}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\forall S\\in R_{t},\\quad f_{16}(S)=&amp;\\frac {\\left |{ \\left \\{{ w:w\\in S\\wedge w\\in \\mathrm {AF} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in S }\\right \\} }\\right |}\\\\ F_{16}=&amp;\\frac {index(\\mathrm {max}(f_{16}(S)))}{\\left |{ \\left \\{{S:S\\in R_{t} }\\right \\} }\\right |}\\end{align*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c5\"><h4>5) Uncertainty Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Certainty words usage (F17)</p></li><li><p>Uncertainty words usage (F18)</p></li></ul> IMT posits that one of the information manipulation methods used by deceivers is manner violations which refer to the use of traditionally ambiguous phrases and indirect expressions rather than clarity of expression in attempting to hide the truth. We used the LIWC categories \u201ccertainty\u201d and \u201ctentative\u201d to capture the usage of certainty and uncertainty words in the review text. Consider the following examples of certainty words usage and uncertainty words usage respectively:\n<ol><li><p>\u201cThis is <u><b>exactly</b></u> what I need. I\u2019m <u><b>sure</b></u> this is the best Chinese restaurant in my area\u201d</p></li><li><p>\u201cI was <u><b>wondering</b></u> why this place <u><b>seems almost</b></u> perfect to me.\u201d</p></li></ol></p><p>Suppose that CR is a set of words in the \u201ccertainty\u201d category inside the LIWC dictionary. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{17}$\n</tex-math></inline-formula> is the ratio of certainty words to the total number of words in a review text. The certainty words usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{17}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {CR} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{17}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {CR} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Suppose that UC is a set of words in the \u201ctentative\u201d category inside the LIWC dictionary. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{18}$\n</tex-math></inline-formula> is the ratio of uncertainty words to the total number of words in a review text. The uncertainty words usage can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{18}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {UC} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{18}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {UC} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c6\"><h4>6) Informality Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Misspelled words ratio (F19)</p></li></ul> Leakage theory, four-factor theory, IDT, and self-</p><p>presentational theory posit that deceptive messages have more speech mistakes and non-fluencies than truthful ones. We used Pyspellchecker, spell checking tool, to detect misspelled words in a review text. Consider the following example of misspelled words:\n<ol><li><p>\u201c<u><b>typcially</b></u> what I need from any <u><b>restrant</b></u>.\u201d</p></li></ol></p><p>Suppose that MS is a set of words detected as misspelled in the review\u2019s text. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{19}$\n</tex-math></inline-formula> is the ratio of misspelled words to the total number of words in a review text. The misspelled words ratio can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{19}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {MS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{19}=\\frac {\\left |{ \\left \\{{w:w\\in R_{t}\\wedge w\\in \\mathrm {MS} }\\right \\} }\\right |}{\\left |{ \\left \\{{w:w\\in R_{t} }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c7\"><h4>7) Consistency Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Rating-sentiment inconsistency (F20)</p></li></ul> The self-presentational theory posits that deceptive messages are more likely to be internally inconsistent. We used the TextBlob sentiment analyzer to extract the polarity of a review text. As the polarity lies in the range of [\u22121, 1] and the star rating lies in the range of [1, 5], we normalized both of them to lie in the range of [0, 1]. Consider the following examples of inconsistency between sentiment and rating:\n<ol><li><p>\u201cI <u><b>love</b></u> to eat breakfast here every morning.\u201d \u2736\u2730\u2730\u2730\u2730</p></li></ol></p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${max}_{p}$\n</tex-math></inline-formula> is the maximum sentiment polarity <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_3c7\">[1]</a>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$min_{p}$\n</tex-math></inline-formula> is the minimum sentiment polarity [\u22121], <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${max}_{\\ast }$\n</tex-math></inline-formula> is the maximum star rating <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_3c7\">[5]</a>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$min_{\\ast }$\n</tex-math></inline-formula> is the minimum star rating <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_3c7\">[1]</a>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$R_{\\ast }$\n</tex-math></inline-formula> is the review\u2019s star rating. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{20}$\n</tex-math></inline-formula> is the absolute difference between the normalized sentiment polarity of the text and the normalized star rating of a review. The rating-sentiment inconsistency can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{20}=\\left |{ \\frac {polarity\\left ({R_{t} }\\right)-min_{p}}{max_{p}-min_{p}}-\\frac {R_{\\ast }-{min}_{\\ast }}{max_{\\ast }-{min}_{\\ast }} }\\right |\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{20}=\\left |{ \\frac {polarity\\left ({R_{t} }\\right)-min_{p}}{max_{p}-min_{p}}-\\frac {R_{\\ast }-{min}_{\\ast }}{max_{\\ast }-{min}_{\\ast }} }\\right |\\end{equation*}\n</span></span></disp-formula></p><p>The above verbal features from F1 to F20, the textual pre-processing methods for review text, and the programming tools that were used to extract these features were summarized in <b><a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">FIGURE 3</a></b>.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul3-3227631-large.gif\" data-fig-id=\"fig3\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul3-3227631-small.gif\" alt=\"FIGURE 3. - Verbal features extraction for our model.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>Verbal features extraction for our model.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec3c8\"><h4>8) Source-Credibility Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Number of reviews (F21)</p></li></ul> IDT focuses on source credibility as a measure of the source\u2019s believability in terms of different aspects including dynamism and sociability. We used the number of reviews posted by the reviewer to measure dynamism and sociability.</p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$U$\n</tex-math></inline-formula> is a set of all reviews posted by a user in a dataset. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{21}$\n</tex-math></inline-formula> is the number of reviews posted by the user and it can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{21}=\\left |{ U }\\right |\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{21}=\\left |{ U }\\right |\\end{equation*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3c9\"><h4>9) Deviation-in-Behavior Features</h4><p>\n<ul style=\"list-style-type:disc\"><li><p>Rating deviation (F22)</p></li><li><p>Extreme rating ratio (F23)</p></li><li><p>Maximum reviewing frequency (F24)</p></li></ul> IDT posits that the deceiver\u2019s behavior deviates from the normal and ideal behavior. Therefore, the reviewer\u2019s rating behavior is important to be captured and compared with the average rating behavior for one product to measure how much it deviates from the normal behavior.</p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{\\ast }$\n</tex-math></inline-formula> is the average star rating of a reviewed product. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{22}$\n</tex-math></inline-formula> is the normalized absolute difference between the user\u2019s rating on a product and the average rating of the reviewed product. The rating deviation can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{22}=\\frac {\\left |{ R_{\\ast }-P_{\\ast } }\\right |}{max_{\\ast }-{min}_{\\ast }}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{22}=\\frac {\\left |{ R_{\\ast }-P_{\\ast } }\\right |}{max_{\\ast }-{min}_{\\ast }}\\end{equation*}\n</span></span></disp-formula></p><p>Fake reviewers tend to rate the products either with the highest rate (5 stars) or with the lowest rate (1 star) to enhance or damage reputation <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_3c9\">[150]</a>, which is deviated from truthful reviewers\u2019 rating behavior. Therefore, the extreme rating ratio is important to be measured.</p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$U_{\\ast }$\n</tex-math></inline-formula> is a set of reviews ratings for a user in a dataset. Feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{23}$\n</tex-math></inline-formula> is the ratio of reviews with extreme star ratings <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left \\{{1,5 }\\right \\}$\n</tex-math></inline-formula> to the total number of reviews posted by the user. The extreme rating ratio can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{23}=\\frac {\\left |{ \\left \\{{R_{\\ast }:R_{\\ast }\\in U_{\\ast }\\wedge R_{\\ast }\\in \\left \\{{1,5 }\\right \\} }\\right \\} }\\right |}{\\left |{ \\left \\{{R_{\\ast }:R_{\\ast }\\in U_{\\ast } }\\right \\} }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{23}=\\frac {\\left |{ \\left \\{{R_{\\ast }:R_{\\ast }\\in U_{\\ast }\\wedge R_{\\ast }\\in \\left \\{{1,5 }\\right \\} }\\right \\} }\\right |}{\\left |{ \\left \\{{R_{\\ast }:R_{\\ast }\\in U_{\\ast } }\\right \\} }\\right |}\\end{equation*}\n</span></span></disp-formula></p><p>Truthful reviewers are not expected to post more than two reviews per day while fake reviewers are expected to write down about seven reviews in one day <a ref-type=\"bibr\" anchor=\"ref150\" id=\"context_ref_150_3c9\">[150]</a> which is deviated from truthful posting reviewers\u2019 behavior. Therefore, the maximum reviewing frequency is important to be measured.</p><p>Suppose that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${R}_{d}$\n</tex-math></inline-formula> is a set of all reviews posted on a specific date <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$U$\n</tex-math></inline-formula> is a set of all reviews posted by the user in a dataset. The feature <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{24}$\n</tex-math></inline-formula> is the maximum number of reviews posted by a user in one day. The maximum reviewing frequency can be calculated as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\forall d,\\quad f_{24}(d)=&amp;\\left |{ R_{d}\\cap U }\\right |\\\\ F_{24}=&amp;\\max (f_{24}(d))\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\forall d,\\quad f_{24}(d)=&amp;\\left |{ R_{d}\\cap U }\\right |\\\\ F_{24}=&amp;\\max (f_{24}(d))\\end{align*}\n</span></span></disp-formula></p><p>By specifying twenty-four features from the deception constructs and their extraction methods, we achieved the second and fourth research objectives (RO2 and RO4).</p></div></div></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION IV.</div><h2>Experimental Validation</h2></div><div class=\"section_2\" id=\"sec4a\"><h3>A. Proposed Fake Reviews Detection Model</h3><p>To validate the theoretical model empirically, we proposed a fake reviews detection model that can be implemented and validated.</p><p>The first stage of the proposed model uses the review text data attribute and pre-processes the text based on the procedures mentioned in the above section (TEXTUAL DATA PREPROCESSING). Non-verbal attributes do not require any pre-processing; these attributes include date, rating, user ID, and product ID.</p><p>The next stage uses the pre-processed text data with non-verbal attributes and extracts the verbal and non-verbal features based on the extraction methods mentioned in the above section (FEATURE SELECTION AND EXTRACTION). In general, verbal features are more complicated to extract and computationally costly than non-verbal features (see <b><a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">FIGURE 3</a></b>).</p><p>The last stage of the proposed model is the classification stage, in which the extracted features are passed to a trained machine-learning model to classify the review as either fake or truthful.</p><p>The model stages are summarized in <b><a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">FIGURE 4</a></b>. By developing a fake reviews detection model based on the selected verbal and non-verbal features, we achieved the third research objective (RO3).\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul4-3227631-large.gif\" data-fig-id=\"fig4\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul4-3227631-small.gif\" alt=\"FIGURE 4. - Fake reviews detection steps.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>Fake reviews detection steps.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec4b\"><h3>B. Online Reviews Datasets</h3><p>Finding a ground-truth dataset for the problem of fake reviews is difficult; however, the ground-truth data are not guaranteed. The most popular and near-ground truth datasets are YelpChi, YelpNYC, and YelpZip <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_4b\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref163\" id=\"context_ref_163_4b\">[163]</a>, <a ref-type=\"bibr\" anchor=\"ref200\" id=\"context_ref_200_4b\">[200]</a> (see <b><a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">TABLE 7</a></b>), which were crawled from the Yelp website and used widely to benchmark the models for spam detection. YelpChi contains reviews from the Chicago area of a group of hotels and restaurants. YelpNYC contains reviews from New York City of a group of restaurants. YelpZip contains reviews from New York City, New Jersey, Vermont, Connecticut, and Pennsylvania of a group of restaurants. The data attributes include product ID, user ID, date, rating, review text, and label for each review. Yelp filters suspicious reviews but keeps them public. Therefore, the filtered reviews were considered fake, whereas the recommended reviews were considered truthful in the three datasets. These datasets do not offer adequate behavioral details because of the high proportion of reviewers with a single review and products with a single review <a ref-type=\"bibr\" anchor=\"ref201\" id=\"context_ref_201_4b\">[201]</a>, which makes it important to extract verbal and non-verbal features when using these datasets.<div class=\"figure figure-full table\" id=\"table6\"><div class=\"figcaption\"><b class=\"title\">TABLE 6 </b>\nSummary of Selected Features for Our Unified Model</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t6-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t6-3227631-small.gif\" alt=\"Table 6- &#10;Summary of Selected Features for Our Unified Model\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table7\"><div class=\"figcaption\"><b class=\"title\">TABLE 7 </b>\nDescriptive Statistics of Yelp Datasets</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t7-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t7-3227631-small.gif\" alt=\"Table 7- &#10;Descriptive Statistics of Yelp Datasets\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div><div class=\"section_2\" id=\"sec4c\"><h3>C. Classification Methods</h3><p>Four classification algorithms, logistic regression (LR), Na\u00efve Bayes (NB), decision tree (DT), and random forest (RF), were chosen for this research. They were our first choice because they are frequently used in the literature and their performance results are promising. We used the Scikit-learn library <a ref-type=\"bibr\" anchor=\"ref202\" id=\"context_ref_202_4c\">[202]</a> to implement these methods.</p><div class=\"section_2\" id=\"sec4c1\"><h4>1) Logistic Regression (LR)</h4><p>Logistic regression (LR) is a linear model used for classification. It utilizes an additional logistic function (sigmoid) and converts linear probabilities into logistic ones, in contrast to linear regression, which assumes linear correlations between the output and features. The estimated probabilities that fall between zero and one are constrained by the logit distribution.</p></div><div class=\"section_2\" id=\"sec4c2\"><h4>2) Naive Bayes (NB)</h4><p>Na\u00efve Bayes (NB) classifiers <a ref-type=\"bibr\" anchor=\"ref203\" id=\"context_ref_203_4c2\">[203]</a> use Bayes\u2019 theorem and are probabilistic classifiers. NB is one of the earliest classification methods and is simple to build without the use of iterative parameter estimation schemes. As a result, they are extremely scalable and easily trainable, especially when the input dimensions are high, the NB classification method is well suited.</p></div><div class=\"section_2\" id=\"sec4c3\"><h4>3) Decision Tree (DT)</h4><p>A decision tree (DT) models the process of converting input features into one of the defined class labels using a treelike graph. Each leaf node in the decision tree indicates a class label for a given item. It is simple to interpret because it can be seen as a set of if-then rules. In this study, we used the classification and regression tree (CART) algorithm <a ref-type=\"bibr\" anchor=\"ref204\" id=\"context_ref_204_4c3\">[204]</a>. By continuously separating a node into two child nodes, starting with the root node that includes the entire learning sample, CART creates a binary decision tree.</p></div><div class=\"section_2\" id=\"sec4c4\"><h4>4) Random Forest (RF)</h4><p>Random forest (RF) <a ref-type=\"bibr\" anchor=\"ref205\" id=\"context_ref_205_4c4\">[205]</a> is an ensemble learning method for classification that creates several decision trees during training and outputs the class, representing the average of the classes produced by the individual trees.</p></div></div><div class=\"section_2\" id=\"sec4d\"><h3>D. Model Evaluation</h3><p>To validate the fake reviews detection model in our experiment, we performed 10-fold cross-validation with five evaluation metrics and the average values of the scores were reported for each of the four classification methods on the three datasets. We used the Scikit-learn library <a ref-type=\"bibr\" anchor=\"ref202\" id=\"context_ref_202_4d\">[202]</a> to measure these metrics.</p><p>The area under the receiver operating characteristic curve (ROC AUC), F1-score (F1), accuracy (A), recall (R), and precision (P) were used as evaluation metrics with the YelpChi, YelpNYC, and YelpZip datasets using all twenty-four selected features (see <b><a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">TABLE 6</a></b>).</p><p>The receiver operating characteristic (ROC) curve is the true positive rate vs. false positive rate curve, where the model is evaluated using different thresholds and the area under this curve (AUC) is used as an evaluation metric. The ROC AUC shows the ability of the model to discriminate between classes <a ref-type=\"bibr\" anchor=\"ref206\" id=\"context_ref_206_4d\">[206]</a> regardless of the threshold or class distribution. A valuable feature of ROC curves is their insensitivity to class distribution because they are based on the true positive rate and false positive rate <a ref-type=\"bibr\" anchor=\"ref207\" id=\"context_ref_207_4d\">[207]</a>. The three Yelp datasets are highly imbalanced, and fake reviews account for only 10-13% (see <b><a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">TABLE 7</a></b>). Therefore, we used the ROC AUC for model evaluation and comparison with other models.</p><p>The F1-score (F1), accuracy (A), recall (R), and precision (P) are commonly used to evaluate machine-learning classifiers. Precision (P) is the ratio of fake reviews that are correctly classified as fake reviews. This metric evaluates the ability of the classifier not to classify a truthful review as fake. Recall (R) is the ratio of the total fake reviews in the dataset that are correctly classified, which evaluates the ability of the classifier to find all fake reviews in the dataset. F1-score (F1) is the harmonic mean of the recall and precision. Accuracy (A) is the ratio of correctly classified reviews to whether they are truthful or fake from all tested reviews. These four metrics are calculated as follows.<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\boldsymbol {P}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {p}}} \\\\ \\boldsymbol {R}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {n}}} \\\\ \\boldsymbol {F1}=&amp;\\frac { \\boldsymbol {2} \\boldsymbol {P}\\ast \\boldsymbol {R}}{ \\boldsymbol {P}+ \\boldsymbol {R}} \\\\ \\boldsymbol {A}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {t}_{ \\boldsymbol {n}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {t}_{ \\boldsymbol {n}}+ \\boldsymbol {f}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {n}}}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\boldsymbol {P}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {p}}} \\\\ \\boldsymbol {R}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {n}}} \\\\ \\boldsymbol {F1}=&amp;\\frac { \\boldsymbol {2} \\boldsymbol {P}\\ast \\boldsymbol {R}}{ \\boldsymbol {P}+ \\boldsymbol {R}} \\\\ \\boldsymbol {A}=&amp;\\frac { \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {t}_{ \\boldsymbol {n}}}{ \\boldsymbol {t}_{ \\boldsymbol {p}}+ \\boldsymbol {t}_{ \\boldsymbol {n}}+ \\boldsymbol {f}_{ \\boldsymbol {p}}+ \\boldsymbol {f}_{ \\boldsymbol {n}}}\\end{align*}\n</span></span></disp-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t_{p}$\n</tex-math></inline-formula> is the true positive which indicates the number of fake reviews that were correctly classified as fake reviews. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{p}$\n</tex-math></inline-formula> is the false positive which indicates the number of truthful reviews that were falsely classified as fake ones. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{n}$\n</tex-math></inline-formula> is the false negative which indicates the number of fake reviews that were falsely classified as truthful reviews. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t_{n}$\n</tex-math></inline-formula> is the true negative which indicates the number of truthful reviews that were correctly classified as truthful reviews.</p><p>According to the high imbalance of labels in the datasets, we calculated the average weighted by support (the number of true instances for each label) for F1-score, precision, and recall.</p></div><div class=\"section_2\" id=\"sec4e\"><h3>E. Analyses of Results</h3><p>To evaluate the impact of incorporating deception-based constructs on the prediction performance of the fake reviews detection model, we evaluated the selected features (see <b><a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">TABLE 6</a></b>) that characterize these constructs in the reviews data.</p><p>First, we extracted the features from the three Yelp datasets. Second, we performed 10-fold cross-validation for each of the four classification methods on the three datasets without hyperparameter optimization. Third, we evaluated the impact and contribution of the selected features using the permutation feature importance technique. Fourth, we optimized the hyperparameters for the AUC scores of all classifiers using the exhaustive grid search with cross-validation. Fifth, we performed 10-fold cross-validation for each of the four classification methods on the three datasets using four feature sets.</p><p>The experimental results of the performance of the classification models using all selected features with 10-fold cross-validation are listed in <b><a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">TABLE 8</a></b>. Logistic regression (LR) showed an AUC in the range of 0.75 to 0.79, F1-score in the range of 0.80 to 0.85, accuracy in the range of 0.86 to 0.89, precision in the range of 0.81 to 0.83, and recall in the range of 0.86 to 0.89.<div class=\"figure figure-full table\" id=\"table8\"><div class=\"figcaption\"><b class=\"title\">TABLE 8 </b>\nExperimental Results of Performance on Yelp Datasets (Without Hyperparameter Optimization)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t8-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t8-3227631-small.gif\" alt=\"Table 8- &#10;Experimental Results of Performance on Yelp Datasets (Without Hyperparameter Optimization)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>Na\u00efve Bayes (NB) showed an AUC in the range of 0.71 to 0.75, F1-score in the range of 0.78 to 0.81, accuracy in the range of 0.75 to 0.79, precision in the range of 0.82 to 0.84, and recall in the range of 0.75 to 0.79. The decision tree (DT) showed an AUC in the range of 0.57 to 0.59, F1-score in the range of 0.80 to 0.83, accuracy in the range of 0.79 to 0.83, precision in the range of 0.80 to 0.84, and recall in the range of 0.79 to 0.83. Random forest (RF) showed an AUC in the range of 0.72 to 0.75, F1-score in the range of 0.81 to 0.85, accuracy in the range of 0.86 to 0.89, precision in the range of 0.80 to 0.84, and recall in the range of 0.86 to 0.89.</p><p>We selected the permutation feature importance technique <a ref-type=\"bibr\" anchor=\"ref208\" id=\"context_ref_208_4e\">[208]</a> rather than the biased impurity-based importance to evaluate the contribution of each feature and its related construct in the model prediction performance. The permutation feature importance is calculated by shuffling the features randomly one by one and then checking the decrement in the evaluation score. The experimental importance scores of the permutation feature importance for all selected features are shown in <b><a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">TABLE 9</a></b> and <b><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">FIGURE 5</a></b>.<div class=\"figure figure-full table\" id=\"table9\"><div class=\"figcaption\"><b class=\"title\">TABLE 9 </b>\nExperimental Results of Importance Scores</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t9-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t9-3227631-small.gif\" alt=\"Table 9- &#10;Experimental Results of Importance Scores\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div>\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul5-3227631-large.gif\" data-fig-id=\"fig5\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul5-3227631-small.gif\" alt=\"FIGURE 5. - Fake reviews feature importance ranking.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>Fake reviews feature importance ranking.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p><p>The top ten features that had sufficient importance scores (greater than 0.03): number of reviews, extreme rating ratio, rating deviation, length of the review, past-tense verbs usage, sentiment polarity, rating-sentiment inconsistency, maximum reviewing frequency, present-tense verbs usage, and misspelled words ratio, respectively. These features are related to the constructs of source credibility, deviation in behavior, quantity, non-immediacy, affect, consistency, and informality.</p><p>We optimized the hyperparameters of all classifiers using the exhaustive grid search with 10-fold cross-validation to improve the AUC score. We then performed 10-fold cross-validation using four feature sets: all selected features, important features (see the top ten in <b><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">FIGURE 5</a></b>), verbal features (see F1 to F20 in <b><a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">TABLE 6</a></b>), and non-verbal features (see F21 to F24 in <b><a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">TABLE 6</a></b>).</p><p>The experimental results of the performance of the ML classification methods using each feature set with 10-fold cross-validation are presented in <b><a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">TABLE 10</a></b> and <b><a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">FIGURE 6</a></b>. The performance results are similar among different classification methods on different datasets, proving that the model is consistent and its strength depends on the selected features, regardless of the dataset or the method used for the purpose of classification. By testing the performance of the proposed model, the fifth research objective was achieved (RO5).<div class=\"figure figure-full table\" id=\"table10\"><div class=\"figcaption\"><b class=\"title\">TABLE 10 </b>\nExperimental Results of AUC Scores Using Different Feature Sets (With Hyperparameter Optimization)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t10-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t10-3227631-small.gif\" alt=\"Table 10- &#10;Experimental Results of AUC Scores Using Different Feature Sets (With Hyperparameter Optimization)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div>\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul6-3227631-large.gif\" data-fig-id=\"fig6\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul6-3227631-small.gif\" alt=\"FIGURE 6. - ROC curves using all classification methods with different feature sets.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p>ROC curves using all classification methods with different feature sets.</p></fig></div><p class=\"links\"><a href=\"/document/9975326/all-figures\" class=\"all\">Show All</a></p></div></p></div></div>\n<div class=\"section\" id=\"sec5\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION V.</div><h2>Discussion</h2></div><p>This study examined how deception constructs from deception theories can be used to build a fake reviews detection model and improve its performance. Incorporating verbal and non-verbal deception-related features was theory-driven. The main purpose was to improve the performance of the fake reviews detection model and to avoid the incorporation of irrelevant features. We evaluated how deception-related features differentiate fake and truthful reviews.</p><p>If we return to deception theories, we can see that reality monitoring theory (RM), criteria-based content analysis (CBCA), scientific content analysis (SCAN), verifiability approach (VA), truth-default theory (TDT), and information manipulation theory (IMT) focus only on the verbal behavior and the content of the deceptive message. Leakage theory, four-factor theory, interpersonal deception theory (IDT), and self-presentational theory consider non-verbal behavior. The only theory that had computationally measurable non-verbal constructs in the context of the computer-mediated text is the interpersonal deception theory (IDT). Therefore, the bias found in deception theories towards verbal deception was clearly reflected in the selection of constructs and, thus, the selection of features.</p><p>To test the nine hypotheses, we empirically evaluated the permutation importance for each feature using the three Yelp datasets. If a construct has at least one related feature with a sufficient importance score (greater than 0.03), then incorporating this construct improves the prediction performance of the fake reviews detection model, thereby supporting the hypothesis that considers this construct.</p><p>Although the number of selected non-verbal features is five times less than the number of selected verbal features, and the computational cost of extraction for non-verbal features is less than that for verbal features, non-verbal features are still more important than verbal features in terms of their ability to differentiate between fake and truthful reviews (see <b><a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">TABLE 9</a></b> and <b><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">FIGURE 5</a></b>). The top three features\u2013number of reviews, extreme rating ratio, and rating deviation\u2013 are related to non-verbal constructs, source credibility, and deviation in behavior, respectively. The last non-verbal feature is the maximum reviewing frequency, which also has a sufficient importance score (see <b><a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">TABLE 9</a></b> and <b><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">FIGURE 5</a></b>). Therefore, these results support Hypotheses H8 and H9.</p><p>The results (see <b><a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">TABLE 10</a></b> and <b><a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">FIGURE 6</a></b>) generally show a performance improvement using combined verbal and non-verbal important features over using all features. The highest performance for all datasets was achieved using the RF model with important features. A performance decrement is shown between using non-verbal features and the use of all or important features. These results support the use of a combination of verbal and non-verbal features to improve the performance of the fake reviews detection model. On the other hand, using non-verbal features alone still shows good performance, which is another strong piece of evidence that supports Hypotheses H8 and H9.</p><p>The length of the review, past-tense verbs usage, sentiment polarity, rating-sentiment inconsistency, present-tense verbs usage, and misspelled words ratio are the six verbal features with sufficient importance scores that represent the importance and impact of the verbal constructs: quantity, non-immediacy, affect, consistency, and informality. Therefore, these results support Hypotheses H2, H3, H4, H6, and H7.</p><p>The remaining features are related to specificity and uncertainty. Although these constructs have received more attention in deception theories than non-verbal constructs, they were not able to show enough importance as features in the fake reviews detection model. Therefore, these results do not support Hypotheses H1 and H5. Based on these results, fake reviews are sufficiently certain and can be rich in details whether they are verifiable or unverifiable, and cannot be distinguished from truthful reviews by specificity or certainty.</p><p>Using verbal features (<b><a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">TABLE 10</a></b> and <b><a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">FIGURE 6</a></b>) shows the worst results, with a decrement between 6% in the best case and 14% in the worst case, which proves the importance of non-verbal features over verbal features. In general, the results show the difficulty for fake reviewers to imitate the non-verbal behavior of truthful reviewers, while verbal behavior is easier to imitate because the review content can be manipulated and prepared to look truthful.</p><p>According to the results, the supported deception constructs that can improve the fake reviews detection are quantity, non-immediacy, affect, consistency, informality, source credibility, and deviation in behavior. These results can answer the first research question (RQ1) \u201cwhat deception aspects from deception theories should be considered to capture the behavior of fraudulent online customers?\u201d</p><p>According to the results, the crucial features that can improve fake reviews detection are the number of reviews, extreme rating ratio, rating deviation, length of the review, past-tense verbs usage, sentiment polarity, rating-sentiment inconsistency, maximum reviewing frequency, present-tense verbs usage, and misspelled words ratio. These results can answer the second research question (RQ2) \u201cWhat are the possible features that can be extracted from the available attributes in open-source customer reviews to reflect the relevant aspects of deceptive behavior?\u201d</p><p>To extract the selected features from the online reviews data, we used programming tools and methods, summarized in <b><a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">TABLE 6</a></b> and <b><a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">FIGURE 3</a></b>. This answers the third research question (RQ3) \u201cWhat techniques can be used to extract the features related to deception aspects from the available attributes in user data?\u201d</p><p>T. Vantan et al. <a ref-type=\"bibr\" anchor=\"ref209\" id=\"context_ref_209_5\">[209]</a> combined verbal features with a bag of words. They proposed four classification methods with their combined verbal features. Although they chose CNN+LSTM as one of their proposed methods, they could not achieve an accuracy of more than 0.78 using only a balanced subset of the YelpNYC dataset.</p><p>M. Ferreira Uchoa <a ref-type=\"bibr\" anchor=\"ref210\" id=\"context_ref_210_5\">[210]</a> used n-grams (verbal features) with SVM and NN. They used the YelpChi, YelpNYC, and YelpZIP datasets for the testing. Although their proposed neural networks reached 1500 hidden layers, they could only reach an accuracy in a range of 0.54 to 0.65.</p><p>A. Rastogi et al. <a ref-type=\"bibr\" anchor=\"ref201\" id=\"context_ref_201_5\">[201]</a>, <a ref-type=\"bibr\" anchor=\"ref211\" id=\"context_ref_211_5\">[211]</a> used behavioral and textual features with LR, SVM, and MLP. They filtered YelpNYC and YelpZip to consider products and reviewers that had at least three reviews, which means that they filtered out approximately 75% from YelpNYC and 42% from YelpZip. The filtered-out data contain 80% of fake reviews in each dataset. Though they filtered out most of the fake reviews from both datasets before validation, they could only reach an AUC in a range of 0.73 to 0.88 for YelpNYC and 0.70 to 0.84 for YelpZIP using behavioral features.</p><p>C. Yuan et al. <a ref-type=\"bibr\" anchor=\"ref212\" id=\"context_ref_212_5\">[212]</a> tested a group of well-known fake reviews detection models as a baseline to compare the results with those of their proposed model (HFAN). They used the YelpChi, YelpNYC, and YelpZIP datasets for benchmarking. The models tested were RSD <a ref-type=\"bibr\" anchor=\"ref213\" id=\"context_ref_213_5\">[213]</a>, SpEagle <a ref-type=\"bibr\" anchor=\"ref163\" id=\"context_ref_163_5\">[163]</a>, TDSD <a ref-type=\"bibr\" anchor=\"ref214\" id=\"context_ref_214_5\">[214]</a>, CHMM <a ref-type=\"bibr\" anchor=\"ref215\" id=\"context_ref_215_5\">[215]</a>, Spam2Vec <a ref-type=\"bibr\" anchor=\"ref216\" id=\"context_ref_216_5\">[216]</a>, CNN-GRNN <a ref-type=\"bibr\" anchor=\"ref76\" id=\"context_ref_76_5\">[76]</a>, SWNN <a ref-type=\"bibr\" anchor=\"ref217\" id=\"context_ref_217_5\">[217]</a>, ABNN <a ref-type=\"bibr\" anchor=\"ref218\" id=\"context_ref_218_5\">[218]</a>, and AEDA <a ref-type=\"bibr\" anchor=\"ref78\" id=\"context_ref_78_5\">[78]</a> (see their results in <b><a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\">TABLE 11</a></b>). They considered the text at the user and product levels. Although their proposed model (HFAN) has a highly complex architecture, they could only reach AUC scores of 0.83, 0.85, and 0.87 for YelpChi, YelpNYC, and YelpZIP, respectively.<div class=\"figure figure-full table\" id=\"table11\"><div class=\"figcaption\"><b class=\"title\">TABLE 11 </b>\nComparing AUC Scores of Prominent Fake Reviews Detection Models Using the Yelp Datasets</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t11-3227631-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975326/abdul.t11-3227631-small.gif\" alt=\"Table 11- &#10;Comparing AUC Scores of Prominent Fake Reviews Detection Models Using the Yelp Datasets\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>Our unified model outperformed most of the well-known fake review detection models (see <b><a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\">TABLE 11</a></b>). Although A. Rastogi et al. <a ref-type=\"bibr\" anchor=\"ref201\" id=\"context_ref_201_5\">[201]</a>, <a ref-type=\"bibr\" anchor=\"ref211\" id=\"context_ref_211_5\">[211]</a> obtained high AUC scores, their model was validated after filtering out 80% of the fake reviews from YelpNYC and YelpZip datasets, making the results unreliable for comparison. For HFAN <a ref-type=\"bibr\" anchor=\"ref212\" id=\"context_ref_212_5\">[212]</a>, their model obtained high AUC scores (only 3-5% higher than our model), but it suffers from high complexity and low interpretability of the results. Our model is interpretable, with favorable theory-based features and mapping to deception theories. In addition, our model has low complexity and high performance.</p><p>After implementing and validating the proposed fake reviews detection model and then comparing it with state-of-the-art models, the improvement in performance, complexity, and interpretability was proved by results which, in turn, answered the fourth research question (RQ4) \u201cCan the deception-based fake reviews detection model improve the performance of fake reviews detection?\u201d.</p></div>\n<div class=\"section\" id=\"sec6\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VI.</div><h2>Conclusion and Future Directions</h2></div><p>In this study, we developed a pure theory-based model for fake reviews detection. To achieve the objectives of the research and answer the research questions, we began by synthesizing ten popular deception theories and analyzing them thoroughly. Next, we derived important constructs of deception from the deception theories to build a unified theoretical model. We selected features that could characterize the derived constructs and could be measured from the review texts and the reviewer\u2019s behavior. Finally, our fake reviews detection model was empirically validated using three famous Yelp reviews datasets after extracting the selected features.</p><p>Some limitations of this work present ample opportunities for future research as suggested below.\n<ul style=\"list-style-type:disc\"><li><p>First, the synthesized deception theories in this study are limited by those that are the most influential and popular in computer-mediated text contexts. More deception theories can be synthesized and merged with other well-founded fundamental theories from sociology, criminology, biology, or linguistics.</p></li><li><p>Second, our selected constructs from deception theories were limited to computer-mediated text. Therefore, we encourage other researchers to select constructs from the same deception theories that are applicable to deception detection for other types of media such as voice and video.</p></li><li><p>Third, more features can be added to our feature set to characterize the derived constructs more widely in the context of online reviews.</p></li><li><p>Fourth, more complex semantic features using deep learning methods (e.g., <a ref-type=\"bibr\" anchor=\"ref219\" id=\"context_ref_219_6\">[219]</a>, <a ref-type=\"bibr\" anchor=\"ref220\" id=\"context_ref_220_6\">[220]</a>, <a ref-type=\"bibr\" anchor=\"ref221\" id=\"context_ref_221_6\">[221]</a>) and other empirically-derived features can be combined with theory-based features to enhance the prediction performance.</p></li><li><p>Fifth, the benchmarking Yelp datasets used for model validation include reviews of hotels and restaurants only, which raises questions regarding the generalizability of our model and the study\u2019s conclusions. Therefore, it would be worthwhile to investigate whether the results of this study can be reproduced for online reviews of other business categories.</p></li><li><p>Sixth, we used only four classical machine-learning algorithms for model validation. Therefore, we encourage other researchers to validate the model using different algorithms, particularly neural networks, which are expected to achieve better predictions.</p></li></ul></p></div>\n</div></div></response>\n"
}