{
    "abstract": "Machine learning (ML)-based approaches are desirable for discriminating targets from clutter signals to enhance the performance of active sonar systems. However, a small dataset and imbalanced data samples between the target and clutter hinder ML applications in active sonar classification. Anomaly detection (AD), which effectively exploits the imbalance, is adopted to enhance the generalization o...",
    "articleNumber": "9976054",
    "articleTitle": "Bi-Sphere Anomaly Detection With Learnable Centroid for Active Sonar Classification",
    "authors": [
        {
            "preferredName": "Geunhwan Kim",
            "normalizedName": "G. Kim",
            "firstName": "Geunhwan",
            "lastName": "Kim",
            "searchablePreferredName": "Geunhwan Kim"
        },
        {
            "preferredName": "Youngmin Choo",
            "normalizedName": "Y. Choo",
            "firstName": "Youngmin",
            "lastName": "Choo",
            "searchablePreferredName": "Youngmin Choo"
        }
    ],
    "doi": "10.1109/ACCESS.2022.3227646",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9976054/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION I.</div><h2>Introduction</h2></div><p>Modern active sonar systems for anti-submarine warfare transmit sound waves and analyze received signals to estimate the information of the underwater target. However, in addition to the target echo reflected from the artificial objects, the received signal consists of the signal reflected from various geological and biological scattering objects, such as the sea surface, sea bottom, and fish school, which is called clutter. Because a clutter has physical experiences similar to those of the target echo (sound propagation and scattering in the ocean), it generates a false alarm when a matched filter is applied. Therefore, such false alarms make it difficult to detect the targets. Consequently, the performance of active sonar systems will be degraded. To overcome this problem, an active sonar-classification algorithm that distinguishes targets from clutter is desired in active sonar systems <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\">[1]</a>, <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a>, <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>, <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\">[4]</a>.</p><p>In the past few decades, research on machine learning (ML)-based algorithms have been conducted for active sonar classification. Early studies related to active sonar classification can be found in literature from the late 1980s. Gorman et al. <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>, <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a> performed an experiment to distinguish between a metal cylinder and a cylindrical rock located on a sandy seabed using a shallow neural network with a normalized spectral envelope as the input. Shin et al. <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a> and Andrea Trucco <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a> conducted active sonar classification using a classify-before-detection strategy based on a pattern-recognition paradigm. Murphy et al. performed active sonar classification using a Gaussian-based classifier with aural features that mimicked the human auditory system <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a>. Seo et al. performed active sonar classification using a support vector machine with multilayer features from the range-bearing domain <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\">[10]</a>. Tongjing Sun et al. proposed Fisher discriminant dictionary learning combining Fisher\u2019s discriminant criterion and a dictionary learning-based sparse representation classification algorithm <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>.</p><p>Recently, with the rapid development of deep learning technology, there have been increasing attempts to adopt it to active sonar classification. Several studies have been conducted on active sonar classifiers based on convolutional neural networks (CNN) trained with a supervised learning approach <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_1\">[12]</a>, <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_1\">[13]</a>. Yule Chen et al. conducted data augmentation using a generative adversarial network to overcome the problem of a supervised learning approach in the small number of samples <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_1\">[14]</a>. Research on unsupervised approaches has also been conducted <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\">[15]</a>. Wang et al. proposed a multidomain network comprising a shared network and attention modules using images from different signal processing as inputs <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_1\">[16]</a>.</p><p>However, the generalization performance of active sonar classifiers remains low and limited, primarily because the active sonar dataset suffers from a small number of data samples owing to the difficulty of sea trials and the confidentiality of data samples. A small number of data samples has an adverse effect on the performance of conventional ML-based algorithms, which are guaranteed to be performed when large amounts of data samples are used. Additionally, the active sonar dataset also suffers from severely imbalanced data samples between the target and clutter because the received signal contains an abundance of clutter and few target signals. Therefore, it is necessary to understand the characteristics of the active sonar dataset and adopt an appropriate approach to solve the active sonar classification problem.</p><p>Deep anomaly detection (AD) can effectively exploit the imbalanced dataset, making it suitable to enhance the generalization performance of the active sonar classifier <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\">[17]</a>. Conventional deep AD focuses on learning a representation of normal data samples (here, clutter data samples in the active sonar dataset) and attempts to fit normal data samples in a compact sphere manifold in latent space <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a>. After learning, deep AD distinguishes abnormal data samples (here, target data samples in the active sonar dataset) by measuring the distance between the centroid of the sphere and the data samples in the latent space. However, abnormal target data samples from artificial objects have similar physical experiences as normal clutter data samples from geological and biological objects. Therefore, the abnormal target data samples and the normal clutter data samples have similar characteristics, such that the abnormal target data sample may be included within the decision boundary of the normality. Consequently, it is difficult to discriminate between the target and clutter using only normal data samples.</p><p>A deep AD using anomaly data samples has also been proposed <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a>; however, the generalization performance of active sonar classification remains low because prior knowledge of active sonar data samples are not fully considered.</p><p>To overcome the problem of active sonar classification and advance generalization performance, we propose semi-supervised learning-based bi-sphere anomaly detection (BiSAD), which finds two spheres, including target and clutter samples, respectively, by modifying the conventional deep AD. Simultaneously, BiSAD searches for the latent space, where the centroids of spheres are at a long distance, to increase the generalization performance.</p><p>The remainder of this paper is organized as follows. <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Sec. II</a> describes the problem of active sonar targets and clutter classification. <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Sec. III</a> summarizes the ML-based training and testing strategies and <a ref-type=\"sec\" anchor=\"sec4\" class=\"fulltext-link\">Sec. IV</a> presents BiSAD for active sonar classification. <a ref-type=\"sec\" anchor=\"sec5\" class=\"fulltext-link\">Sec. V</a> describes the preliminaries of ML-based active sonar classification. <a ref-type=\"sec\" anchor=\"sec6\" class=\"fulltext-link\">Sec. VI</a> describes the results of the ML-based classifiers using sea experimental data that include scattered signals from underwater artificial objects. Finally, we conclude this paper in <a ref-type=\"sec\" anchor=\"sec7\" class=\"fulltext-link\">Sec. VII</a>.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION II.</div><h2>Problem Description</h2></div><div class=\"section_2\" id=\"sec2a\"><h3>A. Overview of the Scheme of the Active Sonar Detection and Classification</h3><p><a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1</a> shows a scheme for active sonar detection and classification. There are two strategies: classify-after-detection and classify-before-detect.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo1ab-3227646-large.gif\" data-fig-id=\"fig1\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo1ab-3227646-small.gif\" alt=\"FIGURE 1. - Scheme for the active sonar detection and classification. (a) Classify-after-detect strategy: matched filter, normalization, and clustering are sequentially performed on the received beam signal. The results obtained in this process are called contacts. As the contacts contain many nontargets, a classification process is required to remove them. (b) Classify-before-detect strategy: detection and classification are simultaneously performed on raw beam signal, which removes the pre-processing in the classify-after-detect.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>Scheme for the active sonar detection and classification. (a) Classify-after-detect strategy: matched filter, normalization, and clustering are sequentially performed on the received beam signal. The results obtained in this process are called contacts. As the contacts contain many nontargets, a classification process is required to remove them. (b) Classify-before-detect strategy: detection and classification are simultaneously performed on raw beam signal, which removes the pre-processing in the classify-after-detect.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p><a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1(a)</a> depicts the classify-after-detect strategy <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2a\">[9]</a>. The received beam signal is filtered using a matched filter with a replica of the transmitted pulse. A threshold was applied to detect the target signal. However, it is inappropriate to use a fixed threshold because the clutter level fluctuates according to changes in the oceanic environment, which causes the problem of detecting the target with a different false alarm rate. Therefore, a normalization algorithm that adapts the threshold to obtain a fixed false alarm rate should be applied to the matched filter output <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_2a\">[20]</a>. Since modern active sonar systems have a high range-bearing resolution, multiple signals can be detected for a single object. A clustering algorithm was employed to group multiple detected signals from the same object <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_2a\">[21]</a>. The output of clustering is called a contact.</p><p>Meanwhile, <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1(b)</a> depicts the classification-before-detect strategy <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_2a\">[7]</a>, <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_2a\">[8]</a>, <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_2a\">[22]</a>. Unlike the classify-after-detect strategy requiring pre-processing, classifiers are directly applied to the received beam signal in classify-before-detect. Therefore, the classify-before-detect strategy can utilize redundant information by extracting proper acoustic features from raw beam signals. Recent developments in ML-based algorithms have enabled the adoption of the classify-before-detection strategy in active sonar systems.</p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Active Sonar Target and Clutter Classification</h3><p><a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figs. 2(a), (b), and (c)</a> display examples of the results of the beamforming process, matched filter (MF), and contacts, respectively. These results are generated by sea experimental data with a single underwater target and shallow water (the specification of the sea trial data will be described in <a ref-type=\"sec\" anchor=\"sec5a\" class=\"fulltext-link\">Sec.V-A</a> in detail).</p><p>In the beamforming output of <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Fig. 2(a)</a>, the target signal is identified using prior information on the target location and is marked with the red arrow. Reverberation appeared in the earlier part of the time, making multiple clutter. Furthermore, strong signals (orange arrows) were observed randomly, which also resulted in clutter.\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo2abc-3227646-large.gif\" data-fig-id=\"fig2\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo2abc-3227646-small.gif\" alt=\"FIGURE 2. - Results of the classify-after-detect strategy. (a) Beamforming output, (b) matched filter output, and (c) contacts. The beam and time domain in (a) and (b) are converted to range (X-axis) and cross-range (Y-axis) domain. In the beamforming output, it is evident that target signal (red arrow) and clutter signals (orange arrows) appeared. Clutter signals originated from reverberation and randomly located strong reflection. In the matched filter output, the target signal is emphasized owing to the effect of correlation; however, multiple clutter signals still remain. Following normalization and clustering, many contacts appear.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>Results of the classify-after-detect strategy. (a) Beamforming output, (b) matched filter output, and (c) contacts. The beam and time domain in (a) and (b) are converted to range (X-axis) and cross-range (Y-axis) domain. In the beamforming output, it is evident that target signal (red arrow) and clutter signals (orange arrows) appeared. Clutter signals originated from reverberation and randomly located strong reflection. In the matched filter output, the target signal is emphasized owing to the effect of correlation; however, multiple clutter signals still remain. Following normalization and clustering, many contacts appear.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>In the MF output of <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Fig. 2(b)</a>, it can be observed that the target signal is emphasized and the noise level is suppressed. However, multiple clutter signals remained along the target signal, primarily because many of the scattered signals have a similar experience to the target; therefore, the clutter signal is also highly correlated with the replica of MF.</p><p>In <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Fig. 2(c)</a> shows the clustering results. Although MF, normalization, and clustering were applied, many contacts were observed. Classification is required because these contacts do not guarantee that they are certain targets.</p><p>Generally, classification is performed by sonar operators because they are known to be capable of distinguishing the target from a clutter <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2b\">[9]</a>, <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_2b\">[23]</a>. More specifically, the sonar operator can distinguish subtle differences between the target and clutter from a raw audio signal extracted from the selected beam signal data. This means that the human auditory system can extract aural and perceptual information from a raw audio signal. However, leaving the sonar operator solely responsible for the classification of numerous contacts is risky for human error, besides, it is slow to process and unavailable for around-the-clock surveillance. Therefore, an automatic active sonar classifier that can effectively distinguish the target from clutter using a raw audio signal is required.</p></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION III.</div><h2>Various Ml-Based Training and Testing Strategies</h2></div><div class=\"section_2\" id=\"sec3a\"><h3>A. Supervised Learning</h3><p>ML-based approaches are commonly used to solve classification problems for various research fields <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_3a\">[24]</a>. Many ML-based approaches are supervised learning approaches that require a large number of labeled samples, and the class of each data sample is known. <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Fig. 3</a> illustrates the architecture of the supervised learning approach. For the labeled dataset <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\chi = \\{\\mathbf {x}_{i}, y_{i} \\}_{i=1}^{N} = \\chi _{0} \\cup \\chi _{1}$\n</tex-math></inline-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\chi _{0}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\chi _{1}$\n</tex-math></inline-formula> are the normal and abnormal dataset, respectively, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> is the number of total data samples, the supervised learning approach can be represented as:<disp-formula id=\"deqn1-deqn2\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mathbf {z}=&amp;\\phi (\\mathbf {x};\\mathbf {W}_{\\phi }) \\tag{1}\\\\ \\mathbf {p}=&amp;a \\left ({f(\\mathbf {z}) }\\right)\\tag{2}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mathbf {z}=&amp;\\phi (\\mathbf {x};\\mathbf {W}_{\\phi }) \\tag{1}\\\\ \\mathbf {p}=&amp;a \\left ({f(\\mathbf {z}) }\\right)\\tag{2}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi: \\mathbf {x} \\rightarrow \\mathbf {z}$\n</tex-math></inline-formula> represents an encoder function for feature learning with weight parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\phi }$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {z}$\n</tex-math></inline-formula> indicates a latent vector which encodes feature of input vector, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f$\n</tex-math></inline-formula> denotes a fully-connected layer which connects latent vector and output, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$a$\n</tex-math></inline-formula> represents softmax activation function, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {p}$\n</tex-math></inline-formula> corresponds to the output that indicates the probability of each classes. Typically, the architecture of supervised learning is trained by minimizing cross-entropy loss using the gradient-descent method <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_3a\">[24]</a>. The anomaly score of supervised learning <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$s_{sup}(\\mathbf {x})$\n</tex-math></inline-formula> is calculated as follows:<disp-formula id=\"deqn3\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} s_{sup}(\\mathbf {x}) = \\frac {p_{1}}{p_{0}}\\tag{3}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} s_{sup}(\\mathbf {x}) = \\frac {p_{1}}{p_{0}}\\tag{3}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$p_{0}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$p_{1}$\n</tex-math></inline-formula> denote the element of output vector <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {p}$\n</tex-math></inline-formula> which indicate normal and abnormal probabilities, respectively.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo3-3227646-large.gif\" data-fig-id=\"fig3\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo3-3227646-small.gif\" alt=\"FIGURE 3. - Scheme of supervised learning. Input data sample &#10;$\\mathbf {x}$&#10; were encoded to latent vector &#10;$\\mathbf {z}$&#10; using the encoder function. Output &#10;$\\mathbf {y}$&#10; was composed of a fully-connected layer and softmax activation function, where its index indicates the probability of each class. The cross-entropy loss function is typically used and the gradient descent method is applied to train entire networks.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>Scheme of supervised learning. Input data sample <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {x}$\n</tex-math></inline-formula> were encoded to latent vector <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {z}$\n</tex-math></inline-formula> using the encoder function. Output <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {y}$\n</tex-math></inline-formula> was composed of a fully-connected layer and softmax activation function, where its index indicates the probability of each class. The cross-entropy loss function is typically used and the gradient descent method is applied to train entire networks.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>Recent networks of supervised learning approaches become deeper and more complex because the complexity of the networks has a better ability to fit dataset than shallow networks <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_3a\">[25]</a>, <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_3a\">[26]</a>, <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_3a\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_3a\">[28]</a>. However, the deeper and more complex networks require more memory size and have risk of overfitting, leading to decreased and unstable generalization performance. In general tasks of supervised learning approaches, a large size of the dataset that contains the overall data distribution is used to prevent the problem of supervised learning approaches <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_3a\">[24]</a>. In the active sonar classification, however, obtaining a large labeled dataset is difficult due to the cost and confidentiality of underwater defense systems. Furthermore, it is difficult to implement bulk networks in active sonar systems. Consequently, the large complexity of the networks makes it hard to apply to practical applications <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_3a\">[29]</a>.</p><p>To overcome the limitations of supervised learning with the bulk networks, we use prior information that the sonar dataset is imbalanced as explained in the previous section. The AD approaches are suitable for the imbalanced dataset consisting of a large number of normal class and a small number of abnormal class. Therefore, we are now considering the AD approaches, which may enable shallow networks to have a similar or better performance, compared to the supervised learning approaches and we will explain it next subsection.</p></div><div class=\"section_2\" id=\"sec3b\"><h3>B. Anomaly Detection: Unsupervised Learning</h3><p>Deep support vector data description (SVDD) is a form of well-known deep AD based on an unsupervised learning approach <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_3b\">[18]</a>. It finds a sphere embracing the normal data samples in latent space. <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Fig. 4(a)</a> shows the architecture of deep SVDD. Deep SVDD was performed in two steps. First, the autoencoder (AE) is used to pre-train the weights of the encoder function to form the latent space of the normal data samples and calculate the centroid; the weights are adjusted to make outputs sames as inputs and it is well-known strategies in the deep AD approach <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_3b\">[18]</a>. The pre-training can be conducted to minimize the following loss:<disp-formula id=\"deqn4-deqn5\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mathbf {z}=&amp;\\phi \\left ({\\mathbf {x};\\mathbf {W}_{\\phi } }\\right), \\tag{4}\\\\ \\{\\mathbf {W}_{\\phi }^{AE},\\mathbf {W}_{\\psi }^{AE} \\}=&amp;\\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi },\\mathbf {W}_{\\psi }} l \\left ({\\psi \\left ({\\mathbf {z};\\mathbf {W}_{\\psi } }\\right) }\\right),\\tag{5}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mathbf {z}=&amp;\\phi \\left ({\\mathbf {x};\\mathbf {W}_{\\phi } }\\right), \\tag{4}\\\\ \\{\\mathbf {W}_{\\phi }^{AE},\\mathbf {W}_{\\psi }^{AE} \\}=&amp;\\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi },\\mathbf {W}_{\\psi }} l \\left ({\\psi \\left ({\\mathbf {z};\\mathbf {W}_{\\psi } }\\right) }\\right),\\tag{5}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi: \\mathbf {x} \\rightarrow \\mathbf {z}$\n</tex-math></inline-formula> represents an encoder function for feature learning with weight parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\phi }$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\psi: \\mathbf {z} \\rightarrow \\hat {\\mathbf {x}}$\n</tex-math></inline-formula> represents a decoder function for decoding the latent vector to reconstructed vector <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\hat {\\mathbf {x}}$\n</tex-math></inline-formula> with weight parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\psi }$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> represents a loss function for AE, which is typically mean square error. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\phi }^{AE}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\psi }^{AE}$\n</tex-math></inline-formula> represent pre-trained weights of the encoder and decoder functions, respectively. The centroid of the normal data samples <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> in the latent space can be calculated as:<disp-formula id=\"deqn6-deqn7\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mathbf {c}_{0}=&amp;\\frac {1}{N_{0}} \\sum _{i = 1}^{N_{0}}{\\mathbf {z}^{AE}_{i}}, \\tag{6}\\\\ \\mathbf {z}^{AE}_{i}=&amp;\\phi \\left ({\\mathbf {x}_{i};\\mathbf {W}_{\\phi }^{AE} }\\right),\\tag{7}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mathbf {c}_{0}=&amp;\\frac {1}{N_{0}} \\sum _{i = 1}^{N_{0}}{\\mathbf {z}^{AE}_{i}}, \\tag{6}\\\\ \\mathbf {z}^{AE}_{i}=&amp;\\phi \\left ({\\mathbf {x}_{i};\\mathbf {W}_{\\phi }^{AE} }\\right),\\tag{7}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {x}_{i}$\n</tex-math></inline-formula> is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> normal data sample, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{0}$\n</tex-math></inline-formula> denotes the number of normal data samples.\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo4ab-3227646-large.gif\" data-fig-id=\"fig4\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo4ab-3227646-small.gif\" alt=\"FIGURE 4. - Description of the deep SVDD. (a) Network architecture of the deep SVDD. First, AE is pre-trained using only normal data samples to form the latent space. Following pre-training, centroid of the sphere of normal data samples is calculated. The weights of pre-trained encoders are used to initialize the training encoder. In the main training process, Deep SVDD attempts to concentrate the normal data samples to the centroid of the sphere using only normal data samples. After training, the anomaly score can be calculated. (b) The manifold learning concept of the deep SVDD. Normal clutter data samples (blue dots) are concentrated on the centroid &#10;$\\mathbf {c}_{0}$&#10; of a normal sphere (blue sphere).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>Description of the deep SVDD. (a) Network architecture of the deep SVDD. First, AE is pre-trained using only normal data samples to form the latent space. Following pre-training, centroid of the sphere of normal data samples is calculated. The weights of pre-trained encoders are used to initialize the training encoder. In the main training process, Deep SVDD attempts to concentrate the normal data samples to the centroid of the sphere using only normal data samples. After training, the anomaly score can be calculated. (b) The manifold learning concept of the deep SVDD. Normal clutter data samples (blue dots) are concentrated on the centroid <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> of a normal sphere (blue sphere).</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>In the following step, to embrace the normal data samples using the sphere in latent space, deep SVDD minimizes the following loss:<disp-formula id=\"deqn8\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\{\\mathbf {W}^{\\ast}_{\\phi } \\} = \\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi }} \\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} ||\\phi (\\mathbf {x}_{i};\\mathbf {W}_{\\phi }) - \\mathbf {c}_{0} ||^{2}.\\tag{8}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\{\\mathbf {W}^{\\ast}_{\\phi } \\} = \\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi }} \\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} ||\\phi (\\mathbf {x}_{i};\\mathbf {W}_{\\phi }) - \\mathbf {c}_{0} ||^{2}.\\tag{8}\\end{equation*}\n</span></span></disp-formula> The encoder <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi $\n</tex-math></inline-formula> whose weights are initialized from AE pre-training, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}_{\\phi }^{AE}$\n</tex-math></inline-formula>, is adjusted to derive the sphere. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {W}^{\\ast}_{\\phi }$\n</tex-math></inline-formula> denote the trained weights of the encoder function.</p><p>Following training, the anomaly score of deep AD approach <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$s_{AD}(\\mathbf {x})$\n</tex-math></inline-formula> can be calculated by measuring a distance of encoded latent vector for the input data sample from the sphere centroid <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> and it is denoted as:<disp-formula id=\"deqn9\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} s_{AD}(\\mathbf {x}) = ||\\phi (\\mathbf {x};\\mathbf {W}^{\\ast}_{\\phi }) - \\mathbf {c}_{0} ||^{2}.\\tag{9}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} s_{AD}(\\mathbf {x}) = ||\\phi (\\mathbf {x};\\mathbf {W}^{\\ast}_{\\phi }) - \\mathbf {c}_{0} ||^{2}.\\tag{9}\\end{equation*}\n</span></span></disp-formula> <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Fig. 4(b)</a> illustrates the concept of the manifold of SVDD. A manifold is formed, such that the normal data samples are concentrated at the centroid of the sphere. However, the abnormal data samples are far from the centroid of the sphere. Therefore, distance from the centroid of the normal sphere can measure the anomaly of the data samples.</p></div><div class=\"section_2\" id=\"sec3c\"><h3>C. Anomaly Detection: Semi-Supervised Learning</h3><p>Although deep SVDD shows promising results in various fields <a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_3c\">[30]</a>, <a ref-type=\"bibr\" anchor=\"ref31\" id=\"context_ref_31_3c\">[31]</a>, <a ref-type=\"bibr\" anchor=\"ref32\" id=\"context_ref_32_3c\">[32]</a>, it has limited classification (or detection) performance because only normal data samples are used during training.</p><p>Recently, a semi-supervised approach to deep AD that utilizes labeled abnormal data samples was proposed, which is called deep semi-supervised anomaly detection (SAD) <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_3c\">[19]</a>. <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Fig. 5(a)</a> displays the architecture of deep SAD. As in deep SVDD, deep SAD comprises two steps: pre-training the AE and learning the manifold. In the first step, pre-training was performed using normal data samples, which was the same as that in the deep SVDD. However, in the second step, deep SAD uses a loss function that is different from that in deep SVDD. The loss function searches for the sphere embracing the dominant normal samples in the latent space, while it penalizes (penalizing means pushing the samples from the centroid; as in <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_3c\">[19]</a>) a small number of abnormal samples from the sphere centroid. The loss function in a deep SAD is expressed as <disp-formula id=\"deqn10-deqn11\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\{\\mathbf {W}^{\\ast}_{\\phi } \\}=&amp;\\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi }} \\frac {1}{N} \\sum _{i=1}^{N} \\left ({||\\phi (\\mathbf {x}_{i};\\mathbf {W}_{\\phi }) - \\mathbf {c}_{0} ||^{2} }\\right)^{y_{i}}. \\tag{10}\\\\ y_{i}=&amp;\\begin{cases} 1 &amp; if~\\mathbf {x}_{i} \\in \\chi _{0}\\\\ -1 &amp;~if \\mathbf {x}_{i} \\in \\chi _{1}\\end{cases}.\\tag{11}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\{\\mathbf {W}^{\\ast}_{\\phi } \\}=&amp;\\mathop {\\mathrm {argmin}}_{\\mathbf {W}_{\\phi }} \\frac {1}{N} \\sum _{i=1}^{N} \\left ({||\\phi (\\mathbf {x}_{i};\\mathbf {W}_{\\phi }) - \\mathbf {c}_{0} ||^{2} }\\right)^{y_{i}}. \\tag{10}\\\\ y_{i}=&amp;\\begin{cases} 1 &amp; if~\\mathbf {x}_{i} \\in \\chi _{0}\\\\ -1 &amp;~if \\mathbf {x}_{i} \\in \\chi _{1}\\end{cases}.\\tag{11}\\end{align*}\n</span></span></disp-formula>\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo5ab-3227646-large.gif\" data-fig-id=\"fig5\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo5ab-3227646-small.gif\" alt=\"FIGURE 5. - Description of the deep SAD. (a) Network architecture of the deep SAD. Pre-training of AE using normal data samples is identical to deep SVDD. However, in the main training process, deep SAD concentrates the normal clutter samples on the centroid of the sphere while penalizing the abnormal target data samples. Following the training, the anomaly score can be calculated the same as deep SVDD. (b) The concept of manifold learning of the deep SAD. Normal clutter data samples (blue dots) are concentrated on the centroid &#10;$\\mathbf {c}_{0}$&#10; of a normal sphere (blue sphere) while abnormal target data samples (red dots) move away from the centroid.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>Description of the deep SAD. (a) Network architecture of the deep SAD. Pre-training of AE using normal data samples is identical to deep SVDD. However, in the main training process, deep SAD concentrates the normal clutter samples on the centroid of the sphere while penalizing the abnormal target data samples. Following the training, the anomaly score can be calculated the same as deep SVDD. (b) The concept of manifold learning of the deep SAD. Normal clutter data samples (blue dots) are concentrated on the centroid <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> of a normal sphere (blue sphere) while abnormal target data samples (red dots) move away from the centroid.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>Following the training, anomaly score <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$s(\\mathbf {x})$\n</tex-math></inline-formula> can be calculated using <a ref-type=\"disp-formula\" anchor=\"deqn9\" href=\"#deqn9\" class=\"fulltext-link\">(9)</a> as in the deep SVDD. <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Fig. 5(b)</a> illustrates the concept of the manifold of deep SAD. A manifold is formed such that the normal and abnormal samples are located near and far from the centroid of the sphere, respectively. The distances of the abnormal data samples from the sphere centroid are greater than those in the deep SVDD owing to the loss function that repels them from the sphere centroid. Therefore, a deep SAD has an enhanced generalization performance.</p></div></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION IV.</div><h2>Bi-Sphere Anomaly Detection for Active Sonar Classification</h2></div><p>In the conventional deep AD approaches, such as deep SVDD and SAD, it learns to make a single compact sphere manifold by considering the majority of the normal data samples. In particular, in deep SAD, minor abnormal data samples assist in forming the sphere, including the normal data samples, resulting in better generalization.</p><p>However, it is noteworthy that the abnormal target samples have similar experiences of propagation and scattering from the artificial objects in active sonar systems. Therefore, the corresponding latent vectors should be in close proximity. The similarity between abnormal target samples can be exploited to enhance the generalization of deep AD. Accordingly, we propose bi-sphere anomaly detection (BiSAD) in which an additional sphere embracing abnormal data samples is added to the latent space based on the properties of active sonar data. BiSAD has two spheres to embrace respectively normal and abnormal samples to improve generalization performance and finds the latent space where the distance between the centroids of the two spheres is maximized. Because the bi-sphere concept of BiSAD is motivated by the characteristics of the active sonar dataset, it can be expected that the generalization performance will be improved.</p><p><a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Fig. 6(a)</a> shows the architecture of BiSAD. BiSAD comprises two steps, similar to conventional deep AD approaches. However, the details of each step were different. First, AE was pre-trained to form a latent space using both normal and abnormal data samples. It is because BiSAD attempts to form individual spheres for both the normal and abnormal data samples. In the following step, BiSAD uses two encoders, unlike conventional AD approaches that use a fixed single centroid of a normal data sphere calculated by a pre-trained AE encoder (conventional AD approaches, therefore, require a single encoder function to learn manifold). In contrast, in BiSAD, one of the encoders learns the variable centroids of two spheres <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({\\phi _{A} }\\right)$\n</tex-math></inline-formula>, and the other encoder learns the manifold <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({\\phi _{B} }\\right)$\n</tex-math></inline-formula>.\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo6ab-3227646-large.gif\" data-fig-id=\"fig6\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo6ab-3227646-small.gif\" alt=\"FIGURE 6. - Description of the BiSAD. (a) Network architecture of BiSAD. AE is pre-trained using normal and abnormal data samples both. In the main training process, BiSAD uses two encoders: Encoder &#10;$\\phi _{A}$&#10; which learns the centroids of two spheres and encoder &#10;$\\phi _{B}$&#10; which learns the manifold. Following the training, the anomaly score can be calculated the same as conventional deep AD approaches. (b) The concept of manifold learning of the BiSAD. Normal clutter data samples (blue dots) are concentrated on the centroid &#10;$\\mathbf {c}_{0}$&#10; of a normal sphere (blue sphere) while moving away from the centroid &#10;$\\mathbf {c}_{1}$&#10; of an abnormal sphere (red sphere). Abnormal target data samples are used to train BiSAD in the opposite direction to normal clutter data samples. Simultaneously, BiSAD is trained so that the centroids of the two spheres move away from each other.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p>Description of the BiSAD. (a) Network architecture of BiSAD. AE is pre-trained using normal and abnormal data samples both. In the main training process, BiSAD uses two encoders: Encoder <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi _{A}$\n</tex-math></inline-formula> which learns the centroids of two spheres and encoder <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi _{B}$\n</tex-math></inline-formula> which learns the manifold. Following the training, the anomaly score can be calculated the same as conventional deep AD approaches. (b) The concept of manifold learning of the BiSAD. Normal clutter data samples (blue dots) are concentrated on the centroid <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> of a normal sphere (blue sphere) while moving away from the centroid <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{1}$\n</tex-math></inline-formula> of an abnormal sphere (red sphere). Abnormal target data samples are used to train BiSAD in the opposite direction to normal clutter data samples. Simultaneously, BiSAD is trained so that the centroids of the two spheres move away from each other.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>Using the first encoder <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi _{A}$\n</tex-math></inline-formula>, the centroids of normal data samples <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> and abnormal data samples <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{1}$\n</tex-math></inline-formula> in latent space can be calculated as follows:<disp-formula id=\"deqn12-deqn13\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}})=&amp;\\frac {1}{N_{0}} \\sum _{i = 1}^{N_{0}}{\\phi _{A} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{A}})}, \\mathbf {x}_{i} \\in \\chi _{0} \\tag{12}\\\\ \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}})=&amp;\\frac {1}{N_{1}} \\sum _{i = 1}^{N_{1}}{\\phi _{A} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{A}})}, \\mathbf {x}_{i} \\in \\chi _{1}\\tag{13}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}})=&amp;\\frac {1}{N_{0}} \\sum _{i = 1}^{N_{0}}{\\phi _{A} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{A}})}, \\mathbf {x}_{i} \\in \\chi _{0} \\tag{12}\\\\ \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}})=&amp;\\frac {1}{N_{1}} \\sum _{i = 1}^{N_{1}}{\\phi _{A} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{A}})}, \\mathbf {x}_{i} \\in \\chi _{1}\\tag{13}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{0}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{1}$\n</tex-math></inline-formula> represent the numbers of normal and abnormal data samples, respectively.</p><p>Using the second encoder <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\phi _{B}$\n</tex-math></inline-formula>, BiSAD tries to find the manifold. BiSAD concentrates the normal and abnormal data samples near the corresponding sphere centroids of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{1}$\n</tex-math></inline-formula> (relevant to the first and last terms in <a ref-type=\"disp-formula\" anchor=\"deqn14\" href=\"#deqn14\" class=\"fulltext-link\">(14)</a>). Simultaneously, BiSAD penalizes normal (or abnormal) data samples from <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{1}$\n</tex-math></inline-formula> (or <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{0}$\n</tex-math></inline-formula>) (relevant to the second and third terms in <a ref-type=\"disp-formula\" anchor=\"deqn14\" href=\"#deqn14\" class=\"fulltext-link\">(14)</a>). BiSAD finds the manifold of two spheres and attempts to increase the distance <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$r$\n</tex-math></inline-formula> between the centroids, simultaneously. Thus, the loss function in BiSAD is defined as follows:<disp-formula id=\"deqn14\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*}&amp;\\hspace {-2pc}\\{\\mathbf {W}^{\\ast}_{\\phi _{A}},\\mathbf {W}^{\\ast}_{\\phi _{B}} \\} \\\\=&amp;\\underset {\\mathbf {W}^{\\ast}_{\\phi _{A}},\\mathbf {W}^{\\ast}_{\\phi _{B}}}{ \\mathop {\\mathrm {argmin}}} \\frac {\\kappa _{00}d_{00}+\\kappa _{01}d_{01}+\\kappa _{10}d_{10}+\\kappa _{11}d_{11}}{r^{2}}.\\tag{14}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*}&amp;\\hspace {-2pc}\\{\\mathbf {W}^{\\ast}_{\\phi _{A}},\\mathbf {W}^{\\ast}_{\\phi _{B}} \\} \\\\=&amp;\\underset {\\mathbf {W}^{\\ast}_{\\phi _{A}},\\mathbf {W}^{\\ast}_{\\phi _{B}}}{ \\mathop {\\mathrm {argmin}}} \\frac {\\kappa _{00}d_{00}+\\kappa _{01}d_{01}+\\kappa _{10}d_{10}+\\kappa _{11}d_{11}}{r^{2}}.\\tag{14}\\end{align*}\n</span></span></disp-formula> where <disp-formula id=\"deqn15-deqn16\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} d_{00}=&amp;\\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{+1}, \\mathbf {x}_{i} \\in \\chi _{0} \\\\ d_{01}=&amp;\\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{-1}, \\mathbf {x}_{i} \\in \\chi _{0} \\\\ d_{10}=&amp;\\frac {1}{N_{1}} \\sum _{i=1}^{N_{1}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{-1}, \\mathbf {x}_{i} \\in \\chi _{1} \\\\ d_{11}=&amp;\\frac {1}{N_{1}} \\sum _{i=1}^{N_{1}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{+1}, \\mathbf {x}_{i} \\in \\chi _{1},\\tag{15}\\\\ r=&amp;||\\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||,\\tag{16}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} d_{00}=&amp;\\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{+1}, \\mathbf {x}_{i} \\in \\chi _{0} \\\\ d_{01}=&amp;\\frac {1}{N_{0}} \\sum _{i=1}^{N_{0}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{-1}, \\mathbf {x}_{i} \\in \\chi _{0} \\\\ d_{10}=&amp;\\frac {1}{N_{1}} \\sum _{i=1}^{N_{1}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{-1}, \\mathbf {x}_{i} \\in \\chi _{1} \\\\ d_{11}=&amp;\\frac {1}{N_{1}} \\sum _{i=1}^{N_{1}} \\left ({||\\phi _{B} (\\mathbf {x}_{i};\\mathbf {W}_{\\phi _{B}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||^{2} }\\right)^{+1}, \\mathbf {x}_{i} \\in \\chi _{1},\\tag{15}\\\\ r=&amp;||\\mathbf {c}_{0} (\\mathbf {W}_{\\phi _{A}}) - \\mathbf {c}_{1} (\\mathbf {W}_{\\phi _{A}}) ||,\\tag{16}\\end{align*}\n</span></span></disp-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}=[\\kappa _{00},\\kappa _{01},\\kappa _{10},\\kappa _{11}]$\n</tex-math></inline-formula> represents the weighting parameter for determining the strategy in manifold learning (the effects of these parameters will be discussed in the <a ref-type=\"sec\" anchor=\"sec6b\" class=\"fulltext-link\">Sec. VI-B</a>).</p><p>Following training, anomaly score <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$s(\\mathbf {x})$\n</tex-math></inline-formula> can be calculated using <a ref-type=\"disp-formula\" anchor=\"deqn9\" href=\"#deqn9\" class=\"fulltext-link\">(9)</a> as in conventional deep AD approaches. <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Fig. 6(b)</a> shows the manifold concept of the BiSAD. The manifolds are formed such that the normal and abnormal data samples are concentrated on the corresponding sphere centroids and repelled from the opposite sphere centroids. Concurrently, the centroids of the spheres were trained to be distant from each other.</p></div>\n<div class=\"section\" id=\"sec5\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION V.</div><h2>Preliminaries for Ml-Based Active Sonar Classification</h2></div><div class=\"section_2\" id=\"sec5a\"><h3>A. Active Sonar Dataset</h3><p>To verify the BiSAD, we use sea experimental data with one artificial underwater target which is collected by an active sonar system. In these experiments, a linear chirped pulse was transmitted multiple times with a pause and received through a linear sensor array. In conclusion, we acquired raw beam signal data measured along azimuth angles (beam angles) and time (ping numbers).</p><p>To generate the active sonar dataset for the training and testing, we use the classify-after-detect strategy (MF, normalization, and clustering are sequentially performed to generate contacts) in Sec II-A. In total, we achieved contacts (whose number was in the order of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{3}$\n</tex-math></inline-formula>) and extracted the contact signals from the raw audio signals. The length of the contact signal was set to twice the length of the pulse by considering the multipath propagation effect, which elongates the transmitted signal.</p><p>Each contact signal was annotated with target or nontarget by three experienced sonar experts. The number of target and nontarget data samples was in the order of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{1}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{3}$\n</tex-math></inline-formula>, respectively. As expected, the target is a minor class which is abnormal when using the AD approaches. Note that the signal-to-noise ratio (SNR) of the target echo differed from ping to ping owing to the varying transmitter-target-receiver geometry and ocean environments.</p><p>To complete the active sonar dataset, we need to divide it into a training dataset and a test dataset. Unlike ordinary ML data split, which is randomly divided into training and test datasets <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_5a\">[24]</a>, the active sonar dataset should be split by considering physical characteristics for meaningful experiments. Based on the observation of target echo variation from ping to ping, we divide the dataset by temporal change with the ping. More specifically, we define the data samples from the ten first pings (early ten pings) as the training dataset and data samples from the remaining pings as the test dataset. It is noteworthy that the number of targets in the training dataset was less than ten whereas the number of the clutter appeared about five hundred.</p></div><div class=\"section_2\" id=\"sec5b\"><h3>B. Preprocessing of Active Sonar Dataset for Classification</h3><p>In general, it is hard to extract the aural and perceptual information directly from raw audio signals because of their complexity due to high dimensions <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_5b\">[33]</a>. Therefore, in conventional audio signal processing, it is natural to transform raw audio signals into time-frequency (TF) data using short-time Fourier transform (STFT) for further processing <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_5b\">[34]</a>. Likewise, it is natural to transform the raw beam signal into TF data before applying ML-based active sonar classifiers. <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig. 7</a> illustrates the transformation process. First, the raw audio signal is extracted and STFT is applied. Following STFT, frequency constraining (considering the bandwidth of the transmitted pulse) and resizing are applied sequentially. The pre-processed data are called TF images. In conclusion, ML-based active sonar classifiers attempt to discriminate the target from clutter using TF images as inputs.\n<div class=\"figure figure-full\" id=\"fig7\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo7-3227646-large.gif\" data-fig-id=\"fig7\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo7-3227646-small.gif\" alt=\"FIGURE 7. - The pre-processing of active sonar dataset for classification. The raw audio beam signal is transformed into time-frequency (TF) data through short-time Fourier transform (STFT). Following STFT, bandwidth constraining and resizing were applied. The TF image presents the input of active sonar classifier.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 7. </b><fig><p>The pre-processing of active sonar dataset for classification. The raw audio beam signal is transformed into time-frequency (TF) data through short-time Fourier transform (STFT). Following STFT, bandwidth constraining and resizing were applied. The TF image presents the input of active sonar classifier.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p><a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Fig. 8</a> shows examples of the TF images. <a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Figs. 8(a) and (b)</a> show three different TF images of the target and clutter, respectively. It is difficult to distinguish visually because the target and clutter signals arise from scattering by the same transmitted signal (they have a similar frequency band with the transmitted signal).\n<div class=\"figure figure-full\" id=\"fig8\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo8ab-3227646-large.gif\" data-fig-id=\"fig8\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo8ab-3227646-small.gif\" alt=\"FIGURE 8. - The examples of time-frequency (TF) image of (a) TF images of target and (b) are TF images of nontarget in the active sonar dataset. Because target and nontarget TF images are generated from similar physical experiences, it is hard to discriminate. The purpose of this study is to develop an active sonar classifier that can classify these TF images.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 8. </b><fig><p>The examples of time-frequency (TF) image of (a) TF images of target and (b) are TF images of nontarget in the active sonar dataset. Because target and nontarget TF images are generated from similar physical experiences, it is hard to discriminate. The purpose of this study is to develop an active sonar classifier that can classify these TF images.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec5c\"><h3>C. Setup for Training and Testing</h3><p>The encoder networks for feature learning are composed of two CNN layers followed by two fully connected (FC) layers after flattening. The decoder networks for AE have a symmetrical structure to that of the encoder networks. The network architecture is summarized in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>. The size of the input TF image was set to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$64 \\times 64$\n</tex-math></inline-formula>.<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nNetworks Architecture</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo.t1-3227646-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo.t1-3227646-small.gif\" alt=\"Table 1- &#10;Networks Architecture\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>All supervised learning and deep AD approaches are initialized using pre-trained AE weights. For training (including pre-training), the Adam optimizer was used with an epoch of 100, batch size of 64, and learning rate of 0.001. Five-fold cross-validation was conducted <a ref-type=\"bibr\" anchor=\"ref35\" id=\"context_ref_35_5c\">[35]</a> and an early stopping technique was employed using the validation loss in each fold to prevent overfitting. The final output was calculated using the average of five model outputs trained in the five-fold cross-validation. For supervised learning, the softmax output, which is the mean probability of each class, is averaged, and for deep AD approaches, the anomaly scores are averaged <a ref-type=\"bibr\" anchor=\"ref36\" id=\"context_ref_36_5c\">[36]</a>, <a ref-type=\"bibr\" anchor=\"ref37\" id=\"context_ref_37_5c\">[37]</a>.</p><p>Owing to small amount of the imbalanced active sonar dataset, ordinary supervised learning makes decision with a bias toward to dominant normal class, which results in excessive false alarms and missing targets. To overcome this problem, data argumentation can be used to complement abnormal data samples by modifying the existing abnormal data samples <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_5c\">[24]</a>. However, general data argumentation schemes such as rotating, shifting, and shearing are unsuitable for active sonar dataset because it does not consider the physical characteristics of underwater sound propagation and scattering.</p><p>Inevitably, down-sampling is used, which reduces the number of dominant normal data samples to the number of abnormal data samples when the network is trained <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_5c\">[24]</a>.</p></div></div>\n<div class=\"section\" id=\"sec6\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VI.</div><h2>Ml-Based Active Sonar Classification</h2></div><p>We performed a generalization test using active sonar dataset for the BiSAD along with the supervised learning, deep SVDD, and deep SAD. For a qualitative analysis, the receiver operating characteristic (ROC) curve is used and is calculated using the anomaly score according to ranging thresholds in the probability of detection <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> and probability of false alarm <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula>. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula> are defined as:<disp-formula id=\"deqn17-deqn18\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} P_{D}=&amp;\\frac {\\mathrm {TP}}{\\mathrm {TP} + \\mathrm {FN}}, \\tag{17}\\\\ P_{fa}=&amp;\\frac {\\mathrm {FP}}{\\mathrm {FP} + \\mathrm {TN}},\\tag{18}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} P_{D}=&amp;\\frac {\\mathrm {TP}}{\\mathrm {TP} + \\mathrm {FN}}, \\tag{17}\\\\ P_{fa}=&amp;\\frac {\\mathrm {FP}}{\\mathrm {FP} + \\mathrm {TN}},\\tag{18}\\end{align*}\n</span></span></disp-formula> where TP, TN, FP, and FN indicate true positive (predict actually abnormal target as abnormal target), true negative (predict actually normal clutter as normal clutter), false positive (predict actually normal clutter as abnormal target), and false negative (predict actually abnormal target as normal clutter), respectively.</p><p>For quantitative analysis, we calculated <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> at the specific <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula> of 0.01, and the area under the curve (AUC) of the average ROC curve according to the considered ML-based approaches.</p><div class=\"section_2\" id=\"sec6a\"><h3>A. Comparative Analysis</h3><p><a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Fig. 9(a)</a> to (d) illustrate the ROC curves of supervised learning, deep SVDD, deep SAD, and BiSAD, in the test dataset after training using the training dataset (i.e., the ten first pings). Because the number of data samples is limited in the active sonar dataset, we cannot guarantee performance using the results obtained from a single trial. Therefore, in our analysis, we conducted 30 trials and analyze 30 ROC curves to ensure the reliability of the results. <a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Fig. 9</a> shows the average, minimum, and maximum ROC curves, which represent the average, minimum, and maximum values at a specific <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula> among the 30 ROC curves. <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig. 10</a> presents a close-up view of the average ROC curve plotted on a logarithmic scale of the lower <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula> part for a distinct comparison of performance.\n<div class=\"figure figure-full\" id=\"fig9\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo9abcd-3227646-large.gif\" data-fig-id=\"fig9\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo9abcd-3227646-small.gif\" alt=\"FIGURE 9. - Comparison of the ROC curves of (a) supervised learning, (b) deep SVDD, (c) deep SAD, and (d) BiSAD, respectively. The performance variability of supervised learning is high. BiSAD exhibits superior performance and stable ROC curves.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 9. </b><fig><p>Comparison of the ROC curves of (a) supervised learning, (b) deep SVDD, (c) deep SAD, and (d) BiSAD, respectively. The performance variability of supervised learning is high. BiSAD exhibits superior performance and stable ROC curves.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig10\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo10-3227646-large.gif\" data-fig-id=\"fig10\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo10-3227646-small.gif\" alt=\"FIGURE 10. - Comparison of the average ROC curves. The BiSAD exhibits superior performance than other approaches.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 10. </b><fig><p>Comparison of the average ROC curves. The BiSAD exhibits superior performance than other approaches.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>The supervised learning exhibits the lowest performance and largest variability than AD approaches, owing to the small training dataset whose size is in the order of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{1}$\n</tex-math></inline-formula> after the down-sampling. The BiSAD shows high <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> than the other ML-based approaches at low <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula>. Among the ML-based classifiers, the BiSAD exhibits the best performance. The calculated quantitative values are presented in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>. The <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> and AUC of BiSAD were both higher than those of the others. Compared to supervised learning, BiSAD exhibited superior <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> and AUC values of 0.150 and 0.089, respectively.<div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nPerformance analysis of average ROC curves</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo.t2-3227646-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo.t2-3227646-small.gif\" alt=\"Table 2- &#10;Performance analysis of average ROC curves\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div><div class=\"section_2\" id=\"sec6b\"><h3>B. ANALYSIS ON THE <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\kappa$\n</tex-math></inline-formula> IN THE LOSS FUNCTION</h3><p>In the BiSAD loss function of <a ref-type=\"disp-formula\" anchor=\"deqn14\" href=\"#deqn14\" class=\"fulltext-link\">(14)</a>, we adopted four weights <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\kappa _{00}$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\kappa _{01}$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\kappa _{10}$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\kappa _{11}$\n</tex-math></inline-formula> to control the manifold learning of BiSAD. In this subsection, we analyze the generalization test performance according to the weight vector <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> was set to [1, 0, 0, 1], [0, 1, 1, 0], and [1, 1, 1, 1]..</p><p>The <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 0, 0, 1] attempts to concentrate normal and abnormal data samples on the individual spheres with less penalization; the penalization is solely considered by <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$r$\n</tex-math></inline-formula> in the denominator of <a ref-type=\"disp-formula\" anchor=\"deqn14\" href=\"#deqn14\" class=\"fulltext-link\">(14)</a>. Meanwhile, the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [0, 1, 1, 0] emphasize the penalizing without considering the concentration. When we set <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> as [1, 1, 1, 1], BiSAD uses both concentration and penalization; therefore, it finds compact spheres while considering penalization.</p><p><a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Fig. 11(a), (b), and (c)</a> show a comparison of the average, maximum, and minimum ROC curves, and <a ref-type=\"fig\" anchor=\"fig12\" class=\"fulltext-link\">Fig. 12</a> shows a comparison of average ROC curves at <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{fa}$\n</tex-math></inline-formula> less than 0.1. The maximum ROC curves of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 0, 0, 1] and [0, 1, 1, 0] are superior than that of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 1, 1, 1],, and the average ROC curve is good in the order of [0, 1, 1, 0], [1, 1, 1, 1], and [1, 0, 0, 1]. However, the variability of the classification performance of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 0, 0, 1] and [0,1,1 0] is significant whereas that of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 1, 1, 1] is moderately consistent.\n<div class=\"figure figure-full\" id=\"fig11\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo11abc-3227646-large.gif\" data-fig-id=\"fig11\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo11abc-3227646-small.gif\" alt=\"FIGURE 11. - Comparison of the ROC curves according to &#10;$\\mathbf {k}$&#10; of (a) [1, 0, 0, 1], (b) [0, 1, 1, 0], and (c) [1, 1, 1, 1]. The case of &#10;$\\mathbf {k}$&#10; of [1, 1, 1, 1] shows stable results than others.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 11. </b><fig><p>Comparison of the ROC curves according to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of (a) [1, 0, 0, 1], (b) [0, 1, 1, 0], and (c) [1, 1, 1, 1]. The case of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 1, 1, 1] shows stable results than others.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig12\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo12-3227646-large.gif\" data-fig-id=\"fig12\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo12-3227646-small.gif\" alt=\"FIGURE 12. - Comparison of the average ROC curves according to &#10;$\\mathbf {k}$&#10;. The case of &#10;$\\mathbf {k}$&#10; of [0, 1, 1, 0] shows superior performance; however, variability is high (as shown in the Fig. 11).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 12. </b><fig><p>Comparison of the average ROC curves according to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula>. The case of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [0, 1, 1, 0] shows superior performance; however, variability is high (as shown in the <a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Fig. 11</a>).</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>The results imply that solely focusing on concentrating or penalizing can mislead the manifold learning of the BiSAD. On the other hand, if concentrating and penalizing are used simultaneously, stability can be improved because the latent space is explored while complementing each other. Therefore, we used <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathbf {k}$\n</tex-math></inline-formula> of [1, 1, 1, 1] for robust performance in the following experiment.</p></div><div class=\"section_2\" id=\"sec6c\"><h3>C. Generalization Test on the Beam Signal Including Target Echo</h3><p>We conducted a generalization test on the beam signal (classify-before-detect strategy in <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1(b)</a>) including target echo at a specific ping and azimuth angle using ML-based classifiers trained with the active sonar dataset. <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig. 13</a> illustrates the spectrogram of the beam signal containing the target echo and the average anomaly scores of supervised learning, deep SVDD, deep SAD, and BiSAD. The beam signals of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$11^{th}$\n</tex-math></inline-formula> and the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$29^{th}$\n</tex-math></inline-formula> pings were utilized. As mentioned in <a ref-type=\"sec\" anchor=\"sec5a\" class=\"fulltext-link\">Sec. V-A</a>, the training dataset consists of data samples from the ten first pings. Because the ocean environment changes over time, the beam signal of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$11^{th}$\n</tex-math></inline-formula> ping had similar characteristics to the training dataset, whereas the beam signal of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$29^{th}$\n</tex-math></inline-formula> ping had different characteristics.\n<div class=\"figure figure-full\" id=\"fig13\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo13ab-3227646-large.gif\" data-fig-id=\"fig13\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo13ab-3227646-small.gif\" alt=\"FIGURE 13. - The generalization test on the whole beam signal including target echo of (a) the &#10;$11^{th}$&#10; ping, and (b) the &#10;$29^{th}$&#10; ping. The spectrogram of beam signal and average anomaly scores are presented. The red dot line indicates the location of the target echo. The average anomaly scores of BiSAD show narrow and accurate results. Anomaly score of BiSAD classified target echo accurately and shows a low level for nontarget locations. These results imply that the generalization performance of BiSAD is superior to conventional ML-based classifiers.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 13. </b><fig><p>The generalization test on the whole beam signal including target echo of (a) the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$11^{th}$\n</tex-math></inline-formula> ping, and (b) the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$29^{th}$\n</tex-math></inline-formula> ping. The spectrogram of beam signal and average anomaly scores are presented. The red dot line indicates the location of the target echo. The average anomaly scores of BiSAD show narrow and accurate results. Anomaly score of BiSAD classified target echo accurately and shows a low level for nontarget locations. These results imply that the generalization performance of BiSAD is superior to conventional ML-based classifiers.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>The average anomaly scores in <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig. 13</a> are calculated by averaging anomaly scores after normalization over 30 trials as in the previous experiment; the normalization was conducted by dividing the anomaly score by its maximum value. By comparing the anomaly scores in <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Figs. 13(a) and (b)</a>, the classification performances of the considered ML-based active sonar classifiers diminish for the beam signal at the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$29^{th}$\n</tex-math></inline-formula> ping, which deviates from those in the training dataset. Particularly, the maximum value of averaged anomaly score from the supervised learning is less than 0.8 because the anomaly scores from supervised learning vary along 30 trials; the inconsistent prediction of supervised learning deteriorates reliability for target and clutter classification. However, BiSAD shows a more robust and accurate classification performance than others. Furthermore, the anomaly score of BiSAD is narrower than those of the others and shows a low level in nontarget locations; particularly in the earlier time corresponding to the reverberation region. The generalization test in <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig. 13</a> implies that BiSAD can accurately distinguish a target from a nontarget even for the unexperienced data samples and the generalization performance of BiSAD is superior to those of the conventional ML-based classifiers.</p></div><div class=\"section_2\" id=\"sec6d\"><h3>D. Comparative Analysis with Various Deep Neural Networks</h3><p>It would be interesting to analyze the performance of the well-known deep neural networks in a small dataset of the active sonar classification problem and compare them with BiSAD. We trained and tested four networks, VGG16, ResNet50, ResNeXt, and SwinViT achieving remarkable performance in the vision with a supervised learning approach <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_6d\">[25]</a>, <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_6d\">[26]</a>, <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_6d\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_6d\">[28]</a>. These networks with complex models (deeper layers with more parameters) may have a better capacity to fit datasets than the shallow networks used in previous approaches, including BiSAD. However, the deeper layers of these networks require more memory sizes and cause overfitting problems on small data sets <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_6d\">[24]</a>.</p><p><a ref-type=\"fig\" anchor=\"fig14\" class=\"fulltext-link\">Fig. 14</a> shows a comparison of the average, maximum, and minimum ROC curves of VGG16, ResNet50, ResNeXt, and SwinViT, respectively. The supervised learning approaches using VGG16, ResNet50, and ResNeXt show stable and high detection probabilities at false alarm rates greater than 0.01. However, the probability of detection decreases sharply and shows large variability with the decrease of false alarm rate. SwinViT shows poor performance compared to the previously proposed networks, contrary to general expectations. This phenomenon is because transformer-based networks require a large amount of data and do not fit the small active sonar dataset.\n<div class=\"figure figure-full\" id=\"fig14\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo14abcd-3227646-large.gif\" data-fig-id=\"fig14\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo14abcd-3227646-small.gif\" alt=\"FIGURE 14. - Comparison of the ROC curves of supervised learning with (a) VGG16, (b) ResNet50, (c) ResNeXt, and (d) SwinViT, respectively. At the low false alarm rate, deep neural network-based supervised learning shows low detection probabilities with large variability. SwinViT, which requires a large amount of data, shows the lowest performance in active sonar classification problems using small datasets.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 14. </b><fig><p>Comparison of the ROC curves of supervised learning with (a) VGG16, (b) ResNet50, (c) ResNeXt, and (d) SwinViT, respectively. At the low false alarm rate, deep neural network-based supervised learning shows low detection probabilities with large variability. SwinViT, which requires a large amount of data, shows the lowest performance in active sonar classification problems using small datasets.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p><a ref-type=\"fig\" anchor=\"fig15\" class=\"fulltext-link\">Fig. 15</a> shows the probability of detection at a false alarm rate of 0.001, where the red line means the median value of the probability of detection, and the upper and lower bounds of the blue box mean the first and third quartile, respectively. The upper and lower black lines mean the maximum and minimum probabilities of detection, and the red plus markers mean outliers. Deep SVDD and SAD show low probabilities of detection (median values of 0.14 and 0.50, respectively) with large variabilities. On the other hand, BiSAD shows a high probability of detection (median value of 0.79) with small variability. In the supervised learning approaches, shallow CNN shows a low probability of detection (median value of 0.43) although its maximum performance is high. Furthermore, it shows the largest variability. SwinViT shows a low probability of detection (median value of 0.07) with large variability and its lower bound reaches the probability of detection of zero. VGG16, ResNet50, and ResNeXt show high probabilities of detection (median value of 0.79) with relatively small variabilities, however, they have outliers that are lower than 0.5. These outliers might be caused by the overfitting problem owing to the small active sonar dataset used to train the deep neural networks.\n<div class=\"figure figure-full\" id=\"fig15\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo15-3227646-large.gif\" data-fig-id=\"fig15\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976054/choo15-3227646-small.gif\" alt=\"FIGURE 15. - The probability of detection of various ML-based approaches at a false alarm rate of 0.001. BiSAD shows better generalization performance than conventional AD approaches and deep neural networks-based supervised learning approaches even though it uses a smaller size of networks.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 15. </b><fig><p>The probability of detection of various ML-based approaches at a false alarm rate of 0.001. BiSAD shows better generalization performance than conventional AD approaches and deep neural networks-based supervised learning approaches even though it uses a smaller size of networks.</p></fig></div><p class=\"links\"><a href=\"/document/9976054/all-figures\" class=\"all\">Show All</a></p></div></p><p>It is noteworthy that the performance of shallow networks trained with supervised learning is significantly enhanced by BiSAD using the AD strategy modified based on the active sonar characteristics. When we compare three supervised learning-based approaches (VGG16, ResNet50, ResNeXt) with the BiSAD, they show a similar median value of detection probability, but BiSAD shows more stable results than supervised learning-based approaches having outliers. Also, the first quartile of BiSAD equals its median value owing to consistent results across multiple trials and it implies that BiSAD has strong reliability. From the results in <a ref-type=\"fig\" anchor=\"fig15\" class=\"fulltext-link\">Fig. 15</a>, we could confirm that BiSAD using the shallow networks with much fewer parameters has better generalization performance than deep neural networks-based supervised learning approaches. These results show that the prior assumption of BiSAD is fit for the active sonar classification problem. Therefore, BiSAD is more suitable for practical application to active sonar systems than the deep neural networks.</p></div></div>\n<div class=\"section\" id=\"sec7\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VII.</div><h2>Conclusion</h2></div><p>In this study, we proposed the BiSAD, which is a modified deep AD approach. The difference between BiSAD and the conventional deep AD approach is that BiSAD assumes that abnormal data samples have characteristics similar to those of normal data samples because all abnormal data samples are caused by artificial objects. This assumption leads BiSAD to learn two individual sphere manifolds: normal (clutter) and abnormal (target). The loss function of BiSAD consists of two concentration terms and two penalizing terms based on the relationship between the spheres and data class. Simultaneously, BiSAD also searches for the latent space where the distance between the two centroids of spheres is maximized.</p><p>To verify the BiSAD, we use sea experimental data that include scattered signals from underwater artificial objects. We divided the training and test data samples according to the ping. Subsequently, ROC curves were calculated to evaluate the qualitative performance, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P_{D}$\n</tex-math></inline-formula> and AUC were presented as quantitative evaluations. The results show that BiSAD has superior classification performance and stability compared to conventional deep AD and supervised learning approaches. We also analyzed the performance based on the weight of the loss function setting. The analysis demonstrated that robust performance was obtained when all terms in the loss function were used. Furthermore, we conduct a generalization test on the beam signal including target echo and compared the BiSAD with supervised learning approaches with various deep neural networks that have deeper layers and more parameters. The results reveal that BiSAD has superior generalization performance compared to conventional ML-based classifiers including deep neural networks-based approaches.</p></div>\n</div></div></response>\n"
}