{
    "abstract": "This paper presents the logical relationships of Aristotle\u2019s square of opposition on four basic categorial prepositions (i.e., contrary, contradictory, subcontrary, and subaltern) of Joint Opposite Selection (JOS). JOS brings a mutual reinforcement by a joint of the two opposition strategies Dynamic Opposite (DO) and Selective Leading Opposition (SLO). The DO and SLO improve the balance of explora...",
    "articleNumber": "9975297",
    "articleTitle": "Golden Jackal Optimization With Joint Opposite Selection: An Enhanced Nature-Inspired Optimization Algorithm for Solving Optimization Problems",
    "authors": [
        {
            "preferredName": "Florentina Yuni Arini",
            "normalizedName": "F. Y. Arini",
            "firstName": "Florentina Yuni",
            "lastName": "Arini",
            "searchablePreferredName": "Florentina Yuni Arini"
        },
        {
            "preferredName": "Khamron Sunat",
            "normalizedName": "K. Sunat",
            "firstName": "Khamron",
            "lastName": "Sunat",
            "searchablePreferredName": "Khamron Sunat"
        },
        {
            "preferredName": "Chitsutha Soomlek",
            "normalizedName": "C. Soomlek",
            "firstName": "Chitsutha",
            "lastName": "Soomlek",
            "searchablePreferredName": "Chitsutha Soomlek"
        }
    ],
    "doi": "10.1109/ACCESS.2022.3227510",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9975297/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION I.</div><h2>Introduction</h2></div><p>Nature-inspired optimization algorithms imitate natural behavior and phenomena to produce effective solutions <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\">[1]</a>, e.g., the Ebola optimization search algorithm <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a>, the African vultures optimization algorithm <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>, the Pelican optimization algorithm <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\">[4]</a>, and the Reptile search algorithm <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>. The more notable abilities of the enhanced nature-inspired optimization algorithms are their abilities to solve essential issues or enhance existing solutions. Examples of these abilities include the economics of combined heat and power emissions, which can be solved by applying multi-objective optimization to decision-making <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>, effective feature selection on cancer datasets is achieved by utilizing Spark Distributed PSO <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>, and the balance of convergence and diversity on many-objective PSO is accomplished by employing a hybrid leader selection strategy <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a>. Moreover, other techniques can be used to improve nature-inspired optimization algorithms, e.g., gradient-based <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a>, chaotic <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\">[10]</a>, quantum <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>, and opposition-based learning (OBL) <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_1\">[12]</a>.</p><p>Many researchers recommend OBL as a learning technique that can improve the performance of an optimization algorithm in a competition <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_1\">[13]</a>. Tizhoosh <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_1\">[14]</a> proposed the opposition-based learning (OBL) technique on the basis of Aristotle\u2019s theory of opposition. The philosophy of Aristotle\u2019s <i>square of opposition</i> introduced in the fourth century has attracted the interest of many scientists. Some of them have reviewed this philosophy in depth. Parsons reviewed the historical aspects of the logical relationship of the Square of Opposition <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\">[15]</a>, <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_1\">[16]</a>. B\u00e9ziau et al. <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\">[17]</a> described the square of opposition as \u201c<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$a$\n</tex-math></inline-formula> <i>cornerstone of thought</i>\u201d. Bernhard <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a> exhibited deep insight into the relationships within the logical diagram of the square of opposition. Other scientists have explored how the principles of the <i>square of opposition</i> can be found in nature as the basic theory of the philosophy of science. In mathematics, Smessaert et al. <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a> introduced new logical geometries based on the Aristotelian logic diagram. In physics, Arenhart et al. <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\">[20]</a> utilized the <i>square of opposition</i> to describe the potential state of quantum superposition.</p><p>Moreover, the utilization of OBL embedded in the slime mould algorithm combined with <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula>-nearest neighbor (kNN) effectively elevates its exploration ability for solving feature selection in medical classification <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_1\">[21]</a>, the Jaya algorithm is enhanced when using adaptive OBL, which integrates more than one opposition <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_1\">[22]</a>, the moth flame optimization is improved with quasi opposition based learning for solving the path planning of a mobile robot <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_1\">[23]</a>, and the tunicate swarm algorithm performance is increased to optimize solar cell power systems <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_1\">[24]</a>.</p><p>Rahnamayan et al. <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_1\">[25]</a> highlighted that opposite numbers produced a higher probability of obtaining better fit compared to pure random numbers. Supporting evidence from scientific reviews also confirmed that the opposition strategy produced promising results <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_1\">[26]</a>, <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_1\">[27]</a>, <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_1\">[28]</a>. It is for these reasons that many scientists have tried to improve, extend, or merge the opposition strategy. The examples are exhibited as follows. Rahnamayan et al. <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_1\">[29]</a> proposed Quasi-Opposition Based Learning (QOBL), which produces higher chances of being close to the solution by utilizing a jumping rate and calculating the middle of opposite points. Ergezer et al. <a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_1\">[30]</a> launched quasi-reflection, which increases the success rate of BBO with less fitness computation. Rahnamayan et al. <a ref-type=\"bibr\" anchor=\"ref31\" id=\"context_ref_31_1\">[31]</a> initialized a random opposite point between the center and boundary named centroid opposition. Hu et al. <a ref-type=\"bibr\" anchor=\"ref32\" id=\"context_ref_32_1\">[32]</a> estimated partial opposite populations simultaneously as an effort to produce a better solution. Dhargupta et al. <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_1\">[33]</a> applied selective opposition by selecting the far away dimensions that produce a fast convergence rate and improve the exploitation ability. Xu et al. <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_1\">[34]</a> merged the quasi-opposition and quasi-reflection to enrich the diversity with its asymmetric search behavior and enhance the exploration ability named dynamic opposite (DO). These examples are improvements of OBL and are still recognized as a single opposition strategy. A single opposition strategy means the opposition strategy will only perform once in every generation. As a result, the improved optimization algorithm using a single opposition strategy can only enrich either the exploration ability or the exploitation ability.</p><p>Those single opposition ideas also generate promising results for solving real-world problems. The approach of Quasi-Opposition Differential Evolution (QODE) is able to reduce grid congestion on reactive power dispatch by minimizing the loss of active power, accelerating the profile of the voltage, and improving the stability of the voltage <a ref-type=\"bibr\" anchor=\"ref35\" id=\"context_ref_35_1\">[35]</a>. An improved firefly optimization algorithm with quasi-reflection can tackle the scheduling of the workflow cloud-edge environment and satisfy real-time requirements <a ref-type=\"bibr\" anchor=\"ref36\" id=\"context_ref_36_1\">[36]</a>. Generalized opposition on the quantum salp swarm algorithm effectively approximates the accuracy of quantile function on Nakagami-m <a ref-type=\"bibr\" anchor=\"ref37\" id=\"context_ref_37_1\">[37]</a>. Centroid opposition integrated with multiple strategies embedded on the salp swarm algorithm can reduce the probability of the failure of the design system of reliability optimization <a ref-type=\"bibr\" anchor=\"ref38\" id=\"context_ref_38_1\">[38]</a>. An improved grey wolf optimizer with selective opposition shows efficiency in estimating the model parameters of proton exchange membrane fuel cells of a 250W stack <a ref-type=\"bibr\" anchor=\"ref39\" id=\"context_ref_39_1\">[39]</a>. The dynamic opposite generates mutual learning which is integrated with the mutation strategy for solving multi-task optimization problems <a ref-type=\"bibr\" anchor=\"ref40\" id=\"context_ref_40_1\">[40]</a>.</p><p>Gonzales <a ref-type=\"bibr\" anchor=\"ref41\" id=\"context_ref_41_1\">[41]</a> affirmed that maintaining the equilibrium of exploration and exploitation in the search space is essential to the main optimization process. There is no exact formula and calculation to define the balance of exploration and exploitation in the search space of the nature mimicking of nature-inspired algorithms <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_1\">[42]</a>, <a ref-type=\"bibr\" anchor=\"ref43\" id=\"context_ref_43_1\">[43]</a>, <a ref-type=\"bibr\" anchor=\"ref44\" id=\"context_ref_44_1\">[44]</a>. Moreover, Wolpert et al. <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_1\">[45]</a> emphasized that no algorithm can solve all optimization problems. Then, Wang et al. <a ref-type=\"bibr\" anchor=\"ref46\" id=\"context_ref_46_1\">[46]</a> questioned whether two oppositions are better than one.</p><p>As mentioned earlier, Aristotle claimed that there is a logical relation between the contrary ability that defines the square of opposition. In a given search space of optimization, exploration is contrary to exploitation. As mentioned in the literature, among variations of single opposition ideas, dynamic opposite (DO) conquers the exploration phase <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_1\">[34]</a> and selective opposition (SO) enriches the exploitation phase <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_1\">[33]</a>. However, SO, which employs the far away dimensions, still experiences premature convergence <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_1\">[33]</a>, which leads to a trap in the local optima. Therefore, Arini et al. <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_1\">[47]</a> proposed an improved SO named Selective Leading Opposition (SLO) and DO. SLO selects the close-distance dimensions to improve the enrichment of exploitation. Meanwhile, DO <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_1\">[34]</a> supports the diversity at the exploration and helps the search process to escape from being trapped at the local optima by moving to the center and opposite position and to the center position and current position.</p><p>Based on Aristotle\u2019s doctrine, we can correlate that DO is a sub-part of exploration, SLO is a sub-part of exploitation, and DO is sub-contrary to SLO. The opposed action of exploration and exploitation according to Gonzales <a ref-type=\"bibr\" anchor=\"ref41\" id=\"context_ref_41_1\">[41]</a> strengthen each other. Therefore, the joint of DO and SLO produces equilibrium of the mutual reinforcement and is named Joint Opposite Selection (JOS) <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_1\">[47]</a>.</p><p>In this paper, we employ JOS to enhance the Golden Jackal Optimization (GJO). GJO mimics the golden jackal\u2019s collaborative hunting behavior, which consists of three phases: prey searching, enclosing, and pouncing <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_1\">[48]</a>, and also shows the efficacy in the applications <a ref-type=\"bibr\" anchor=\"ref49\" id=\"context_ref_49_1\">[49]</a>, <a ref-type=\"bibr\" anchor=\"ref50\" id=\"context_ref_50_1\">[50]</a>. JOS assists the GJO by attacking the prey expeditiously using SLO. The SLO utilizes the existing linear decrement operator from the original version of GJO to apply its strategy. DO contributes to enriching the diversification of GJO in finding other potential prey locations.</p><p>In the process of optimization, GJO requires exploration and exploitation. Based on the experimental results of <a ref-type=\"bibr\" anchor=\"ref51\" id=\"context_ref_51_1\">[51]</a> on 23 benchmark functions, GJO offers very decent results <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_1\">[48]</a>. Nevertheless, there is no supporting evidence that GJO can conquer other benchmark problems such as CEC 2017. We conducted an experiment on CEC 2017 and found that GJO did not perform sufficiently, when compared to the other nature-inspired optimization algorithms. Therefore, we utilized the strength of JOS in balancing the exploration and exploitation to improve the capability of GJO performance in the phases of exploration and exploitation.</p><p>The performance of JOS embedded in GJO (GJO-JOS), was compared with other opposition strategies embedded in GJO, such as Dynamic Opposite (DO), Reflection (R), Quasi-opposition (QO), Generalized Opposition (GO), Selective Opposition (SO) and Selective Leading Opposition (SLO). It should be noted that we did the experiment on GJO with those OBLs to confirm the performance of GJO-JOS among the opposition-based strategies. The performance of GJO-JOS is also compared to eight nature-inspired algorithms, i.e., Wild Horse Optimization (WHO), Aquila Optimization (AO), Artificial Bee Colony (ABC), Harris Hawk Optimization (HHO), Atomic Orbital Search (AOS), Archimedes Optimization Algorithm (AOA), Reinforcement Learning Neural Network Algorithm (RLNNA), and the original version of Golden Jackal Optimization (GJO). The comparison of GJO-JOS versus GJO with the OBLs and GJO-JOS versus nature-inspired algorithms are included in a collection competition of 29 benchmark functions of CEC 2017. The main contributions of our research are highlighted as follows:\n<ul style=\"list-style-type:disc\"><li><p>The philosophy of Aristotle\u2019s square opposition exhibits the mutual reinforcement of the opposed action Dynamic Opposite (DO) and Selective Leading Opposition SLO) of Joint Opposite Selection (JOS) in exploration and exploitation, respectively.</p></li><li><p>The jumping rate adjustment of DO accelerates the diversity of GJO-JOS in the exploration phase.</p></li><li><p>The existence of the GJO linear decrement operator is used by SLO as the threshold influencing the scheduling behavior on GJO-JOS to accelerate its performance in the exploitation phase.</p></li><li><p>GJO-JOS is proposed to boost the optimization process of mimicking the collaborative hunting\u2019s performance of golden jackal (GJO).</p></li><li><p>The effectiveness of GJO-JOS is demonstrated in a competition of 29 benchmark functions CEC 2017 and is evaluated using the statistical analysis; Wilcoxon sign rank test, scoring metric, and convergence curve. GJO-JOS is also compared to seven single opposition learning techniques embedded in GJO and eight nature-inspired optimization algorithms.</p></li></ul> This paper is structured as follows. <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Section II</a> presents the philosophy of Aristotle on Joint Opposite Selection and a review of the Golden Jackal Optimization. <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Section III</a> briefly discusses the proposed GJO-JOS. <a ref-type=\"sec\" anchor=\"sec4\" class=\"fulltext-link\">Section IV</a> discusses the setup of experiments and the analysis of experimental results. <a ref-type=\"sec\" anchor=\"sec5\" class=\"fulltext-link\">Section V</a> provides conclusions and future work.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION II.</div><h2>Related Work</h2></div><p>In the first sub-section, we elaborate on the philosophy of Joint Opposite Selection (JOS), which is followed by a brief discussion of the Golden Jackal Optimization (GJO).</p><div class=\"section_2\" id=\"sec2a\"><h3>A. The Philosophy of Joint Opposite Selection (JOS)</h3><p>The philosophy of JOS adopts the theory of square of opposition <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_2a\">[15]</a>. The theory of square of opposition was defined by Aristotle in the fourth century BC <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_2a\">[15]</a>. The representation of the square opposition is illustrated in <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1(a)</a> with four corner propositions. These four corners are A, E, I, and O with each letter corresponding to a universal affirmative; (every S is P), universal negative (no S is P), particular affirmatives (some S is P), and particular negative (some S is not P), respectively.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat1ab-3227510-large.gif\" data-fig-id=\"fig1\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat1ab-3227510-small.gif\" alt=\"FIGURE 1. - (a) The square of opposition in Aristotle\u2019s philosophy and (b) the philosophy of JOS based on Aristotle\u2019s square of opposition.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>(a) The square of opposition in Aristotle\u2019s philosophy and (b) the philosophy of JOS based on Aristotle\u2019s square of opposition.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div></p><p>An affirmative statement and its negation produce a contradiction condition. For example, A is contrary to E, A is contradictory to O, and E is contradictory to I. I is subaltern to A, O is subaltern to E and I is subcontrary to O. The contrary indicates both of the statements cannot be true but both statements can be false. The contradictory presents that both statements cannot be true and also cannot be false. The subcontrary shows that both statements can be true, but both statements cannot be false. The subaltern exhibits a condition that if the global statement is true, the specific statement must be true. The subaltern is a particular statement of the global statement.</p><p>Based on the contradictory concept of the square of opposition, the philosophy of JOS can be presented as shown in <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1(b)</a>. In a given search space, <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1(b)</a> shows that the exploration is contrary to exploitation, exploration is contradictory to SLO, exploitation is contradictory to DO, DO is subcontrary to SLO, DO is subaltern to exploration, and SLO is subaltern to exploitation.</p><p>As mentioned earlier, Gonzales <a ref-type=\"bibr\" anchor=\"ref41\" id=\"context_ref_41_2a\">[41]</a> affirms that the opposed action of exploration and exploitation strengthen each other, which produces a balancing mechanism. The emergence of the balanced mechanism of JOS is described in <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a>. It starts with the basic theory of Opposition Based Learning (OBL), which contains the opposition function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}}=LB+UB- \\boldsymbol {X}$\n</tex-math></inline-formula>. The basics of opposition function are variously improved with many ideas. OBL with merging the center position and opposite position with the center position and current position named Dynamic Opposite (DO). Meanwhile, OBL utilizes the linear decrement operator, selects and counts the close distance dimensions, then analyzes their association by using Spearman\u2019s Rank Coefficient named Selective Leading Opposition (SLO). These two improved OBLs (DO and SLO) are single opposition functions. In the given search space, as exhibited in <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a>, DO supports the exploration phase and SLO supports the exploitation phase. When the DO and SLO are joined then the balanced mechanism is required. Therefore, the joint of DO and SLO is named Joint Opposite Selection (JOS).\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat2-3227510-large.gif\" data-fig-id=\"fig2\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat2-3227510-small.gif\" alt=\"FIGURE 2. - The emergence balancing mechanism of JOS.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>The emergence balancing mechanism of JOS.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div></p><p>JOS in the workflow of GJO is shown in <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figure 3</a>. This shows that DO on JOS in the workflow of GJO occurs in two parts: initialization and generation. Meanwhile, SLO on JOS occurs on each generation of the GJO workflow by setting its boundary and linear decrement energy of the prey <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{ld} =1.5 \\times \\left ({{1-t/T} }\\right)$\n</tex-math></inline-formula>. A detailed explanation of the occurrence of JOS (the joint DO and SLO) is given in <a ref-type=\"algorithm\" anchor=\"alg1\" class=\"fulltext-link\">Algorithm 1</a>.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat3-3227510-large.gif\" data-fig-id=\"fig3\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat3-3227510-small.gif\" alt=\"FIGURE 3. - The workflow of GJO-JOS.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>The workflow of GJO-JOS.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div><div class=\"algorithm\" id=\"alg1\"><h3>Algorithm 1 GJO-JOS</h3><p>Generate initial random population of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p>Produce initial random population of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> based on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p><b>//Algoritm 2 Stage 1</b></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}\\leftarrow \\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> //Assign <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p><i>nFE</i> = 0, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t$\n</tex-math></inline-formula> = 0, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula> = <i>max</i> _ <i>iteration</i></p><p><b>while</b> <i>nFE</i> &lt; <i>maxFE</i> <b>do</b></p><p>Checked Boundary <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p>Evaluate Fitness values of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p>Update <i>nFE</i></p><p>Update Position of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p>Set selective boundary for SLO</p><p><b>Set <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {E}_{ \\boldsymbol {ld}}$\n</tex-math></inline-formula> = 1.5 <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\times $\n</tex-math></inline-formula> (1 \u2212 t/T) as threshold for SLO //SLO Threshold</b></p><p>Perform SLO // <b><a ref-type=\"algorithm\" anchor=\"alg1\" class=\"fulltext-link\">Algorithm 1</a></b></p><p><b>for</b> each pair jackals <b>do</b></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{0} ={2}\\times {rand} -{1}$\n</tex-math></inline-formula> //Initial Prey Energy</p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v}=E_{ld}\\times E_{0}$\n</tex-math></inline-formula> //Prey Evading Energy</p><p><b>if</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} &gt; 1$\n</tex-math></inline-formula> <b>then //Exploration</b></p><p>Update the position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{M}$\n</tex-math></inline-formula> dan <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F}$\n</tex-math></inline-formula> // <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (2)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (3)</a></p><p><b>else // if <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} &lt; 1$\n</tex-math></inline-formula> then //Exploitation</b></p><p>Update the position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{M}$\n</tex-math></inline-formula> dan <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F}$\n</tex-math></inline-formula> // <a ref-type=\"disp-formula\" anchor=\"deqn5-deqn6\" href=\"#deqn5-deqn6\" class=\"fulltext-link\">Eq. (5) and Eq. (6)</a></p><p><b>end if</b></p><p><b>end for</b></p><p><b>if</b> <i>rand</i> &lt; <i>Jr</i></p><p>Perform DO position (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula>) // <b><a ref-type=\"algorithm\" anchor=\"alg2\" class=\"fulltext-link\">Algorithm 2</a> Stage 2</b></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}\\leftarrow \\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> //Assign <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{jackal}$\n</tex-math></inline-formula></p><p><b>end</b></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t =t+1$\n</tex-math></inline-formula></p><p><b>end</b></p></div></p><p>For further details, the steps process of SLO is described in <a ref-type=\"algorithm\" anchor=\"alg2\" class=\"fulltext-link\">Algorithm 2</a>. The SLO can be applied by setting the population size <i>NP</i>, dimension <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>, iteration <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t$\n</tex-math></inline-formula>, and maximum iteration <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula>, as inputs and setting the linear decrement as the threshold. The SLO will check on the position of each population. If the current position of an individual <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{k}$\n</tex-math></inline-formula> is not equal to the best position of an individual <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{kbest}$\n</tex-math></inline-formula> then SLO will measure the difference distance <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m}$\n</tex-math></inline-formula> on each dimension based on the best position of the dimension <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{kbest,m}$\n</tex-math></inline-formula> and the current position of the dimension <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{k,m}$\n</tex-math></inline-formula>. If the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m}$\n</tex-math></inline-formula> is less than the threshold then they are identified as close distance dimensions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}$\n</tex-math></inline-formula> and are counted. However, if the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m}$\n</tex-math></inline-formula> is greater than the threshold then identify the far away distance dimension <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{f}$\n</tex-math></inline-formula> and count them. Then, measure the associativity of the current position and the best position with the Spearman\u2019s Correlation Coefficient (<i>src</i>).<div class=\"algorithm\" id=\"alg2\"><h3>Algorithm 2 Selective Leading Opposition (SLO)</h3><p><b>Input:</b> <i>NP</i>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$t$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula></p><p><b>Ouput:</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{Dc}$\n</tex-math></inline-formula>: new opposition population based on SLO</p><p>Set linear decrement as <i>threshold</i></p><p><b>for</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$k=1$\n</tex-math></inline-formula>: <i>NP</i> <b>do</b></p><p><b>if</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{k}$\n</tex-math></inline-formula> is not equal to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{kbest}$\n</tex-math></inline-formula></p><p><b>for</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m=1$\n</tex-math></inline-formula>:<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula> <b>do</b></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m}=\\vert \\,\\,\\boldsymbol {X} _{kbest,m} - \\boldsymbol {X} _{k} \\vert $\n</tex-math></inline-formula></p><p><b>if</b> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m} \\le $\n</tex-math></inline-formula> <i>threshold</i></p><p>identify <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}$\n</tex-math></inline-formula> (close distance dimensions)</p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}= D_{c}+1$\n</tex-math></inline-formula></p><p><b>else</b></p><p>identify <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{f}$\n</tex-math></inline-formula> (faraway distance dimensions)</p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{f}= D_{f}+1$\n</tex-math></inline-formula></p><p><b>end if</b></p><p><b>end for</b></p><p>sum all <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$dd_{m}$\n</tex-math></inline-formula> (difference distance)</p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$src=1-\\frac {6\\left ({{\\sum \\limits _{m=1} {\\left ({{dd_{m}} }\\right)^{2}}} }\\right)}{dd_{m} \\left ({{dd_{m}^{2} -1} }\\right)}$\n</tex-math></inline-formula></p><p><b>if</b> <i>src</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\le $\n</tex-math></inline-formula> zero and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}$\n</tex-math></inline-formula> greater than <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{f}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X} _{Dc}=LB_{Dc} + UB_{Dc} - \\boldsymbol {X} _{Dc}$\n</tex-math></inline-formula></p><p><b>end if</b></p><p><b>end if</b></p><p><b>end for</b></p></div></p><p>If the <i>src</i> is less than zero and the number of close dimensions (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}$\n</tex-math></inline-formula>) is greater than the number of far away dimensions then the opposition strategy of SLO will occur. The computational complexity of SLO <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_2a\">[47]</a> is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O$\n</tex-math></inline-formula>(<i>NP</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\times T \\times D_{c}$\n</tex-math></inline-formula>) where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> is presented as the number of search agents, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula> is the maximum number of iterations and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c}$\n</tex-math></inline-formula> is the number of close dimensions.</p><p>Meanwhile, the detailed steps of DO are exhibited in <a ref-type=\"algorithm\" anchor=\"alg3\" class=\"fulltext-link\">Algorithm 3</a> on stage 1 and stage 2, respectively. In the population initialization stage, the DO occurs after the initial population (See line number 2-5). Line 2 sets the opposition-based learning (OBL) strategy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{OP}}} }\\right)$\n</tex-math></inline-formula> by utilizing the initial position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}$\n</tex-math></inline-formula> within the range of lower boundary <i>LB</i> and upper boundary <i>UB</i>. In line 3, the OBL moves with a random number that produces the reflection opposition position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{OR}}} }\\right)$\n</tex-math></inline-formula>. With the influence of the random number, the initial position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}$\n</tex-math></inline-formula> approaches the reflection opposition position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{OR}}} }\\right)$\n</tex-math></inline-formula> and at the same time this approach moves away from the initial position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}$\n</tex-math></inline-formula>. This move is named the dynamic opposite <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{DO}}} }\\right)$\n</tex-math></inline-formula>. Before the start of the process generation, the dynamic opposite position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{DO}}} }\\right)$\n</tex-math></inline-formula> is set as the initial position as stated in stage 1 line 5. In each of the generations at stage 2, the DO will proceed with the same process as in stage 1, with the condition that the random number is less than the Jumping rate <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Jr$\n</tex-math></inline-formula>. The suitable <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Jr$\n</tex-math></inline-formula> for DO on JOS is 0.25 <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_2a\">[47]</a>. The computational complexity of DO is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O(NP \\times Jr \\times T \\times D) $\n</tex-math></inline-formula> where <i>NP</i> is presented as the number of search agents, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Jr$\n</tex-math></inline-formula> is the jumping rate, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula> is the maximum number of iterations and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula> is the number of dimensions.<div class=\"algorithm\" id=\"alg3\"><h3>Algorithm 3 Dynamic Opposite (DO)</h3><p><b>Stage 1 Population Initialization</b></p><p>Initialize search agents\u2019 position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{OP}}=LB+UB- \\boldsymbol {X}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{OR}}=rand\\times \\widetilde { \\boldsymbol {X}_{OR}}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}= \\boldsymbol {X}+rand\\times \\left ({{\\widetilde { \\boldsymbol {X}_{DO}}- \\boldsymbol {X}} }\\right)$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}\\leftarrow \\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula></p><p><b>Stage 2 Population Generation utilizes Jr</b></p><p><b>while</b> <i>nFE</i> &lt; <i>maxFE <b>do</b></i></p><p><b>if</b> <i>rand</i> &lt; <i>Jr</i></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{OP}}=LB+UB- \\boldsymbol {X}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{OR}}=rand\\times \\widetilde { \\boldsymbol {X}_{OR}}$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}= \\boldsymbol {X}+rand\\times \\left ({{\\widetilde { \\boldsymbol {X}_{OR}}- \\boldsymbol {X}} }\\right)$\n</tex-math></inline-formula></p><p><inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}\\leftarrow \\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula></p><p><b>end if</b></p><p><b>end while</b></p></div></p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Golden Jackal Optimization</h3><p>GJO is proposed by Chopra et al. <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_2b\">[48]</a>. GJO is inspired by the pair (male and female) bond-hunting behavior of golden jackals in nature. The bond of a pair of golden jackals is shown by their choral howling. The howling of the golden jackal is considered as some kind of engagement <a ref-type=\"bibr\" anchor=\"ref52\" id=\"context_ref_52_2b\">[52]</a>. With their choral howl, golden jackals inform others of their position and communicate with those others to locate their prey <a ref-type=\"bibr\" anchor=\"ref53\" id=\"context_ref_53_2b\">[53]</a>. For foraging, golden jackals utilize cooperative foraging, which allows them to search an available territory of larger prey <a ref-type=\"bibr\" anchor=\"ref54\" id=\"context_ref_54_2b\">[54]</a>, <a ref-type=\"bibr\" anchor=\"ref55\" id=\"context_ref_55_2b\">[55]</a>. They will move around the prey to ensure and prepare for their assault, then they encircle the prey until it cannot escape. Finally, if escape seems hopeless, they will attack the prey. This foraging hunting behavior of golden jackals is then formulated into a mathematical formula. First, the population of golden jackals in the search space is defined in <a ref-type=\"disp-formula\" anchor=\"deqn1\" href=\"#deqn1\" class=\"fulltext-link\">Eq. (1)</a> <disp-formula id=\"deqn1\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\boldsymbol {X}_{0} =LB+rand\\times \\left ({{UB-LB} }\\right)\\tag{1}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\boldsymbol {X}_{0} =LB+rand\\times \\left ({{UB-LB} }\\right)\\tag{1}\\end{equation*}\n</span></span></disp-formula> where <i>UB</i> is the upper boundary and <i>LB</i> is the lower boundary in the search space with <i>rand</i> as a random number in the range of [0, 1]. The phases of mimicking the hunting behavior of golden jackals in the optimization are exhibited in the phase of exploration, exploitation, and transition from exploration and exploitation.</p><p>In the phase of exploration, golden jackals in nature seek and track their prey. However, sometimes the prey cannot consistently be spotted in a certain place and can easily be lost. The strength of the prey energy is presented as Evading Energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula>. When <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left |{ {E_{v}} }\\right |$\n</tex-math></inline-formula> is greater than 1 means that the prey still has enough energy to escape. In this state, the phase of exploration occurs. At this phase, the hunting action of the golden jackals preferred the male <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{ \\boldsymbol {X}_{male}} }\\right)$\n</tex-math></inline-formula> as the leader and the female <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{ \\boldsymbol {X}_{female}} }\\right)$\n</tex-math></inline-formula> as adherent, as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (2)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (3)</a> respectively <disp-formula id=\"deqn2-deqn3\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\boldsymbol {X}_{M}=&amp;\\boldsymbol {X}_{male} -E_{v} \\left |{ { \\boldsymbol {X}_{male} -\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{prey}} }\\right)} }\\right | \\\\{}\\tag{2}\\\\ \\boldsymbol {X}_{F}=&amp;\\boldsymbol {X}_{female} -E_{v} \\left |{ { \\boldsymbol {X}_{female} -\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{prey}} }\\right)} }\\right | \\\\{}\\tag{3}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\boldsymbol {X}_{M}=&amp;\\boldsymbol {X}_{male} -E_{v} \\left |{ { \\boldsymbol {X}_{male} -\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{prey}} }\\right)} }\\right | \\\\{}\\tag{2}\\\\ \\boldsymbol {X}_{F}=&amp;\\boldsymbol {X}_{female} -E_{v} \\left |{ { \\boldsymbol {X}_{female} -\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{prey}} }\\right)} }\\right | \\\\{}\\tag{3}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{prey} $\n</tex-math></inline-formula> is the prey vector position with the influence of a constant value of 0.05 and the L\u00e9vy flights <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$LF_{D} (\\beta)$\n</tex-math></inline-formula>, as formulated in <a ref-type=\"disp-formula\" anchor=\"deqn4\" href=\"#deqn4\" class=\"fulltext-link\">Eq. (4)</a>, approach the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{male} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{female} $\n</tex-math></inline-formula> as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (2)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (3)</a> sequentially. Note that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\otimes $\n</tex-math></inline-formula> is the element-wise multiplication. The move of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{male} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{female} $\n</tex-math></inline-formula> are controlled by the prey Evading Energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} =E_{ld} \\times E_{0}$\n</tex-math></inline-formula>. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{ld} $\n</tex-math></inline-formula> shows the prey decrement energy. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{ld} =1.5\\times \\left ({{1-\\frac {t}{T}} }\\right)$\n</tex-math></inline-formula> linear decreases from 1.5 to zero during the generation. Meanwhile, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{0} $\n</tex-math></inline-formula> is defined as the prey\u2019s initial energy. <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{0} $\n</tex-math></inline-formula> is equal to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$2\\times $\n</tex-math></inline-formula> rand \u22121 with rand being within [0, 1]. Therefore, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{M} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F} $\n</tex-math></inline-formula> indicate the male and female updated position toward the prey in the phase of exploration.</p><p>Mantegna <a ref-type=\"bibr\" anchor=\"ref56\" id=\"context_ref_56_2b\">[56]</a> affirms that L\u00e9vy flights, as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn4\" href=\"#deqn4\" class=\"fulltext-link\">Eq. (4)</a>, contain random numbers <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {u}_{D} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {v}_{D} $\n</tex-math></inline-formula> as the results of a normal distribution with standard deviations of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {u}_{D} $\n</tex-math></inline-formula> is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\sigma $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {v}_{D} $\n</tex-math></inline-formula> is 1. The parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\beta $\n</tex-math></inline-formula> of L\u00e9vy flights is 1.5. The dimension of the L\u00e9vy flights vector is represented as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>.<disp-formula id=\"deqn4\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} LF_{D} \\left ({\\beta }\\right)=\\left ({{\\frac { \\boldsymbol {u}_{D} \\cdot \\sigma }{\\left |{ { \\boldsymbol {v}_{D}} }\\right |^{\\frac {1}{\\beta }}}} }\\right),\\quad \\! \\sigma =\\left ({{\\frac {\\Gamma \\left ({{1\\!+\\!\\beta } }\\right)\\!\\times \\!\\sin \\left ({{\\frac {\\pi \\beta }{2}} }\\right) }{\\Gamma \\left ({{\\frac {1+\\beta }{2}} }\\right)\\!\\times \\! \\beta \\! \\times \\! 2^{\\left ({{\\frac {\\beta -1}{2}} }\\right)}}} }\\right)^{\\frac {1}{\\beta }}\\!\\!\\!\\! \\\\{}\\tag{4}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} LF_{D} \\left ({\\beta }\\right)=\\left ({{\\frac { \\boldsymbol {u}_{D} \\cdot \\sigma }{\\left |{ { \\boldsymbol {v}_{D}} }\\right |^{\\frac {1}{\\beta }}}} }\\right),\\quad \\! \\sigma =\\left ({{\\frac {\\Gamma \\left ({{1\\!+\\!\\beta } }\\right)\\!\\times \\!\\sin \\left ({{\\frac {\\pi \\beta }{2}} }\\right) }{\\Gamma \\left ({{\\frac {1+\\beta }{2}} }\\right)\\!\\times \\! \\beta \\! \\times \\! 2^{\\left ({{\\frac {\\beta -1}{2}} }\\right)}}} }\\right)^{\\frac {1}{\\beta }}\\!\\!\\!\\! \\\\{}\\tag{4}\\end{align*}\n</span></span></disp-formula></p><p>In the phase of exploitation, the pair of golden jackals enclose the prey and then chase them. Undoubtedly the Evading Energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula> of the prey becomes weak. This state shows that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left |{ {E_{v}} }\\right |$\n</tex-math></inline-formula> is less than 1 and that the exploitation occurs. When the mates of the golden jackals succeed in surrounding the prey, they will assault the prey until it looks lifeless. This pair hunting behavior of golden jackals (male (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{male}$\n</tex-math></inline-formula>) and female (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{female} $\n</tex-math></inline-formula>)) is then formulated in <a ref-type=\"disp-formula\" anchor=\"deqn5-deqn6\" href=\"#deqn5-deqn6\" class=\"fulltext-link\">Eq. (5)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn5-deqn6\" href=\"#deqn5-deqn6\" class=\"fulltext-link\">Eq. (6)</a> respectively.<disp-formula id=\"deqn5-deqn6\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\boldsymbol {X}_{M}=&amp;\\boldsymbol {X}_{male} -E_{v} \\left |{ {\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{male}} }\\right)- \\boldsymbol {X}_{prey}} }\\right | \\\\{}\\tag{5}\\\\ \\boldsymbol {X}_{F}=&amp;\\boldsymbol {X}_{female} -E_{v} \\left |{ {\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{female}} }\\right)- \\boldsymbol {X}_{prey}} }\\right | \\\\{}\\tag{6}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\boldsymbol {X}_{M}=&amp;\\boldsymbol {X}_{male} -E_{v} \\left |{ {\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{male}} }\\right)- \\boldsymbol {X}_{prey}} }\\right | \\\\{}\\tag{5}\\\\ \\boldsymbol {X}_{F}=&amp;\\boldsymbol {X}_{female} -E_{v} \\left |{ {\\left ({{0.05\\times LF_{D} (\\beta)\\otimes \\boldsymbol {X}_{female}} }\\right)- \\boldsymbol {X}_{prey}} }\\right | \\\\{}\\tag{6}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{prey} $\n</tex-math></inline-formula> is the prey vector position approach the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{male} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{female} $\n</tex-math></inline-formula> as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (2)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (3)</a>, respectively. The position of male <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{male} $\n</tex-math></inline-formula> and female <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{female} $\n</tex-math></inline-formula> is influenced by the constant value of 0.05, the L\u00e9vy flights <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$LF_{D} (\\beta)$\n</tex-math></inline-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula> represents the dimension as formulated in <a ref-type=\"disp-formula\" anchor=\"deqn4\" href=\"#deqn4\" class=\"fulltext-link\">Eq. (4)</a>. This is the main difference of the pair of golden jackals\u2019 movements in the exploitation phase compared to the exploration phase. The constant value of 0.05 and the L\u00e9vy flights <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$LF_{D} (\\beta)$\n</tex-math></inline-formula> are utilized to avoid the sluggishness trapped in the local optima. Nevertheless, in the exploitation phase, the operator of prey Evading Energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula> performs the in same manner as in the exploration, by considering the rapid move of the golden jackal approaching the prey. Note that detailed variables and parameters are given in the Appendix.</p></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION III.</div><h2>The Proposed Golden Jackal Optimation (GJO) With Joint Opposite Selection (JOS)</h2></div><p>In this paper, a joint of two single oppositions Dynamic Opposite (DO) <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_3\">[34]</a> and Selection Leading Opposition (SLO) <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_3\">[47]</a>, namely Joint Opposite Selection (JOS) <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_3\">[47]</a>, was utilized to improve the performance of the Golden Jackal Optimization <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_3\">[48]</a>. We named the proposed algorithm Golden Jackal Optimization \u2013 Joint Opposite Selection (GJO-JOS). In the flowchart of optimization, shown in <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figure 3</a>, at the very initialization, the initial jackal position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{j} $\n</tex-math></inline-formula> is defined randomly. This generates the initial DO position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula>. Then, the initial DO position <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\widetilde { \\boldsymbol {X}_{DO}}$\n</tex-math></inline-formula> is assigned to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{j}$\n</tex-math></inline-formula>. The following step then generates the new jackal position based on SLO and DO. The jackal\u2019s upper and lower boundary is checked first then the jackal\u2019s fitness is assessed. SLO is applied by utilizing the linear decrement operator <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{ld} =1.5 \\times \\left ({{1-\\frac {t}{T}} }\\right)$\n</tex-math></inline-formula> as a threshold. The new position based on SLO influences the main optimization. Following the main optimization process, the DO occurs and is optimized under a proper Jumping Rate (<i>Jr</i>). This process is terminated when it reaches the maximum number of function evaluations (<i>maxFE</i>).</p><p>The detail optimization process of GJO-JOS is exhibited in <a ref-type=\"algorithm\" anchor=\"alg3\" class=\"fulltext-link\">Algorithm 3</a>. The original GJO is described in the black font and the red font shows the JOS occurring in the GJO, as stated in <a ref-type=\"algorithm\" anchor=\"alg3\" class=\"fulltext-link\">Algorithm 3</a> lines no. 2, 3, 12, 20, 21, and 22. As shown in line no. 12, the SLO is executed. The SLO utilizes the linear decrement operator <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{ld} =1.5 \\times \\left ({{1-\\frac {t}{T}} }\\right)$\n</tex-math></inline-formula> as the threshold as stated in the green font at line no. 11. The action of SLO is described in detail in <a ref-type=\"algorithm\" anchor=\"alg1\" class=\"fulltext-link\">Algorithm 1</a> in <a ref-type=\"sec\" anchor=\"sec2a\" class=\"fulltext-link\">Section IIA</a>. The main optimization process, shown in <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figure 3</a>, is shown in detail in lines 13-21. The position of each pair of jackals is updated based on the Evading Energy of the prey <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula>. If <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} \\ge 1$\n</tex-math></inline-formula> then update <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{M} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F} $\n</tex-math></inline-formula> positions, based on <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (2)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn2-deqn3\" href=\"#deqn2-deqn3\" class=\"fulltext-link\">Eq. (3)</a>. The phase of this condition is exploration. It means that in this phase the jackals attempt to trap their prey. However, the prey could escape from the jackals\u2019 trap because it still has the energy to escape. If <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} &lt; 1$\n</tex-math></inline-formula> then update <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{M} $\n</tex-math></inline-formula> dan <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F} $\n</tex-math></inline-formula> positions based on <a ref-type=\"disp-formula\" anchor=\"deqn5-deqn6\" href=\"#deqn5-deqn6\" class=\"fulltext-link\">Eq. (5)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn5-deqn6\" href=\"#deqn5-deqn6\" class=\"fulltext-link\">Eq. (6)</a>. This phase is defined as exploitation. In this phase, the evading energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula> of the prey has already decreased and the jackals have managed to lead the prey into their trap. If all these strategies still do not achieve optimally, the DO strategy occurs as defined in lines 22-25. With DO, the jackal position will be scattered. This effort is to find a better location for an appropriate prey. The detailed description of DO is shown in <a ref-type=\"algorithm\" anchor=\"alg2\" class=\"fulltext-link\">Algorithm 2</a> in <a ref-type=\"sec\" anchor=\"sec2a\" class=\"fulltext-link\">Section IIA</a>. <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Figure 4(a)</a> illustrates the linear decrement operator that is used in GJO and is utilized by the SLO of JOS. <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Figure 4(b)</a> delineates the magnitude scheduling behavior of the prey evading energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula>.\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat4ab-3227510-large.gif\" data-fig-id=\"fig4\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat4ab-3227510-small.gif\" alt=\"FIGURE 4. - (a) Linear decrement operator and (b) Prey evading energy.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>(a) Linear decrement operator and (b) Prey evading energy.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div></p><p>Both figures show the evolution of the value which decreases from 1.5 to zero, carried out along 1000 iterations. The evading energy of the prey <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula> restrains the occurrence of updates to the golden jackal pair\u2019s position in the phases of exploration and exploitation. Therefore, we can see that the linear decrement operator influences the scheduling behavior of the Evading Energy <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$E_{v} $\n</tex-math></inline-formula> of the prey.</p><p>The efficiency of an algorithm can be measured in terms of computational cost or computational complexity of time complexity <a ref-type=\"bibr\" anchor=\"ref57\" id=\"context_ref_57_3\">[57]</a>. For GJO, Chopra et al. <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_3\">[48]</a> affirmed that the computational complexity of GJO consists of the main two computational complexities. They are initialization and updating mechanisms. The initialization computational complexity of GJO is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O$\n</tex-math></inline-formula>(<i>NP</i>), where <i>NP</i> is the number of jackals. The updating mechanism computational complexity of GJO is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O$\n</tex-math></inline-formula>(<i>NP</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\times T$\n</tex-math></inline-formula>) + <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O$\n</tex-math></inline-formula>(<i>NP</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\times T \\times D$\n</tex-math></inline-formula>), where <i>NP</i> is the number of jackals, T is the number of maximum iterations, and D is the dimension of definite problems. The run-time computational complexity of GJO is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$O(NP \\times (T+(T \\times D)+1))$\n</tex-math></inline-formula>, which means that the time complexity of GJO grows based on the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$NP \\times T \\times D$\n</tex-math></inline-formula>.</p><p>Arini et al. <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_3\">[47]</a> confirmed that the computational complexity of JOS (SLO and DO) concludes as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} O(SLO)=O(NP\\times T\\times D_{c}),\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} O(SLO)=O(NP\\times T\\times D_{c}),\\end{equation*}\n</span></span></disp-formula> where <i>NP</i> is the number of jackals, T is the number of maximum iterations, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D_{c} $\n</tex-math></inline-formula> is represented for close distance dimensions, <disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} O(DO)=O(NP\\times Jr\\times T\\times D),\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} O(DO)=O(NP\\times Jr\\times T\\times D),\\end{equation*}\n</span></span></disp-formula> where <i>NP</i> is the number of jackals, <i>Jr</i> represents jumping rate, T is the number of maximum iterations, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula> is present as the dimensions.</p><p>Therefore, the computational complexity efficiency for GJO-JOS is:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} O(GJO-JOS)=&amp;O(NP\\times (T+(T\\times D)+1))\\\\&amp;+\\, O(NP\\times T\\times D_{c} +NP\\times Jr\\times T\\times D)\\\\=&amp;O(NP\\times T(2 +D_{c} +D(T+Jr)).\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} O(GJO-JOS)=&amp;O(NP\\times (T+(T\\times D)+1))\\\\&amp;+\\, O(NP\\times T\\times D_{c} +NP\\times Jr\\times T\\times D)\\\\=&amp;O(NP\\times T(2 +D_{c} +D(T+Jr)).\\end{align*}\n</span></span></disp-formula> Hence, the computational complexity of GJO-JOS still shows the same order time complexity as that of GJO. For the proposed algorithm, the memoryrequirement is influenced by the size of the variables and the parameters of the algorithm, which are shown in the Appendix. <a ref-type=\"app\" anchor=\"app2\" class=\"fulltext-link\">Appendix A</a> shows the memory size of GJO with the updated vector position of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{M} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{F} $\n</tex-math></inline-formula> equals <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$2 \\times (NP \\times D)$\n</tex-math></inline-formula>. Meanwhile, <a ref-type=\"app\" anchor=\"app3\" class=\"fulltext-link\">Appendix B</a> presents the memory size of DO <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{\\widetilde { \\boldsymbol {X}_{DO}}} }\\right)$\n</tex-math></inline-formula>: <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$NP \\times D$\n</tex-math></inline-formula> and <a ref-type=\"app\" anchor=\"app4\" class=\"fulltext-link\">Appendix C</a> presents the memory size of SLO (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {X}_{D_{c}}$\n</tex-math></inline-formula>): <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$NP \\times D$\n</tex-math></inline-formula> Therefore, the memory size of GJO-JOS is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$k \\times (NP \\times D)$\n</tex-math></inline-formula>.</p></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION IV.</div><h2>Experimental Results and Discussion</h2></div><p>The experiments were carried out with an Intel\u00ae Core\u2122 i9-7980XE CPU @ 2.60 GHz and 64 GB RAM, running Microsoft Windows 10 Pro. The optimization algorithms were written in MATLAB.</p><p>The experiments include solving the single-objective real parameter numerical optimization of Congress on Evolutionary Computation (CEC) 2017 <a ref-type=\"bibr\" anchor=\"ref58\" id=\"context_ref_58_4\">[58]</a>. The CEC is comprised of 29 benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{1},f_{3} -f_{30})$\n</tex-math></inline-formula>. These benchmark functions are used to evaluate the performance of GJO-JOS compared to its competitors and are classified into four categories as shown in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>. The four categories of the benchmark functions are defined as follows: unimodal, simple modal, hybrid, and composition functions. The unimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{1},f_{3})$\n</tex-math></inline-formula> consist of shifted and rotated Bent Cigar and Zakhow Fincton, respectively; the simple multimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{4} -f_{10})$\n</tex-math></inline-formula> are the representation of one function that has been shifted and rotated; the hybrid functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{11} -f_{20})$\n</tex-math></inline-formula> are the representation of two or more functions that blend into one function; and the composition functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{21} -f_{30})$\n</tex-math></inline-formula> are composed of at least three functions. Note that due to unjustified results, the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{2} $\n</tex-math></inline-formula> was omitted from this experiment. According to CEC evaluation criteria, the search space in all categories of benchmark functions is determined as [\u2212100, 100]<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$^{D}$\n</tex-math></inline-formula>. The lower bound (<i>LB</i>) is \u2212100 and the upper bound (<i>UB</i>) is 100.<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nThe Description of Benchmark Functions CEC 2017</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t1-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t1-3227510-small.gif\" alt=\"Table 1- &#10;The Description of Benchmark Functions CEC 2017\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>The performance of the proposed GJO-JOS and its comparison algorithms on CEC 2017 were assessed by a scoring metric <a ref-type=\"bibr\" anchor=\"ref58\" id=\"context_ref_58_4\">[58]</a>. The scoring metric is summarized by the sum of the error (<i>SE</i>) and the sum of the rank (<i>SR</i>). The highest scoring metric is 100. Therefore, the maximum score of each item is 50.</p><p>The value of <i>SE</i> is present in <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (7)</a>. The <i>SE</i> is formulated by weight and summation of best objective values (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$ef$\n</tex-math></inline-formula>) in all CEC 2017 benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{1,3-30})$\n</tex-math></inline-formula> based on 10, 30, 50, and 100 dimensions (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>) <a ref-type=\"bibr\" anchor=\"ref58\" id=\"context_ref_58_4\">[58]</a>. The higher the dimensions, the higher its weight. The weight for 10D is 0.1, for 30D it\u2019s 0.2, for 50D it\u2019s 0.3, and last for 100D it\u2019s 0.4. For <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR$\n</tex-math></inline-formula>, the obtained value is also influenced by the weight. However, the summation on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR$\n</tex-math></inline-formula> based on the rank of the algorithm in the comparison, as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (8)</a>,<disp-formula id=\"deqn7-deqn8\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} SE=&amp;0.1\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{10D}}} }\\right)+0.2\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{30D}}} }\\right) \\\\&amp;+\\,0.3\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{50D}}} }\\right) \\\\&amp;+\\,0.4\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{100D}}} }\\right).\\tag{7}\\\\ Score_{SE}=&amp;50\\times \\left ({{1-\\frac {SE-SE_{\\min }}{SE}} }\\right),\\tag{8}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} SE=&amp;0.1\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{10D}}} }\\right)+0.2\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{30D}}} }\\right) \\\\&amp;+\\,0.3\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{50D}}} }\\right) \\\\&amp;+\\,0.4\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{100D}}} }\\right).\\tag{7}\\\\ Score_{SE}=&amp;50\\times \\left ({{1-\\frac {SE-SE_{\\min }}{SE}} }\\right),\\tag{8}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SE_{\\min } $\n</tex-math></inline-formula> is the minimum value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SE$\n</tex-math></inline-formula>. The obtained result value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR$\n</tex-math></inline-formula> and the score of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR$\n</tex-math></inline-formula> are shown in <a ref-type=\"disp-formula\" anchor=\"deqn9-deqn10\" href=\"#deqn9-deqn10\" class=\"fulltext-link\">Eq. (9)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn9-deqn10\" href=\"#deqn9-deqn10\" class=\"fulltext-link\">Eq. (10)</a>, respectively.<disp-formula id=\"deqn9-deqn10\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} SR=&amp;0.1\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{10D}}} }\\right)+0.2\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{30D}}} }\\right) \\\\&amp;+\\,0.3\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{50D}}} }\\right) \\\\&amp;+\\,0.4\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{100D}}} }\\right).\\tag{9}\\\\ Score_{SR}=&amp;50\\times \\left ({{1-\\frac {SR-SR_{\\min }}{SR}} }\\right),\\tag{10}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} SR=&amp;0.1\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{10D}}} }\\right)+0.2\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{30D}}} }\\right) \\\\&amp;+\\,0.3\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{50D}}} }\\right) \\\\&amp;+\\,0.4\\times \\left ({{\\sum \\limits _{f_{1,3-30}} {ef_{100D}}} }\\right).\\tag{9}\\\\ Score_{SR}=&amp;50\\times \\left ({{1-\\frac {SR-SR_{\\min }}{SR}} }\\right),\\tag{10}\\end{align*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR_{\\min } $\n</tex-math></inline-formula> is the minimal value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$SR$\n</tex-math></inline-formula>. Thus, the total score is summarized in <a ref-type=\"disp-formula\" anchor=\"deqn11\" href=\"#deqn11\" class=\"fulltext-link\">Eq. (11)</a>.<disp-formula id=\"deqn11\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} Total Score = Score_{SE} + Score_{SR}.\\tag{11}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} Total Score = Score_{SE} + Score_{SR}.\\tag{11}\\end{equation*}\n</span></span></disp-formula></p><p>Therefore, the parameters required to run each algorithm on the CEC are shown as follows: (a) population size (<i>NP</i>) is fixed equal to 30 and (b) Jumping Rate (<i>Jr</i>) is set at 0.25 <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_4\">[47]</a>. Each algorithm (a) repeats in 51 runs, each run tests 29 benchmark functions of CEC 2017 in 10, 30, 50, and 100 dimensions (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>); (b) defines the maximum number of function evaluations (<i>maxFE</i>) as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$1\\,\\,\\times10$\n</tex-math></inline-formula><sup>4</sup> multiplied by the number of dimensions (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$D$\n</tex-math></inline-formula>); and (c) the maximum number of iterations (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$T$\n</tex-math></inline-formula>) is defined by dividing the <i>maxFE</i> with <i>NP</i>.</p><p>The obtained experimental results are further discussed in three sub-sections. Section A describes the performance of GJO-JOS and GJO on Hybrid and composition functions CEC 2017. Section B, the GJO-JOS is compared to six single variants of oppositions (i.e., DO, SLO, SO, Quasi, Generalized Opposition, and Reflection Opposition) and the original version of GJO. Section C discusses the comparison of GJO-JOS to seven nature-inspired algorithms and the original version of GJO.</p><div class=\"section_2\" id=\"sec4a\"><h3>A. GJO-JOS vs. GJO on Hybrid and Composition Functions CEC 2017</h3><p>The GJO-JOS versus GJO was tested on four categories of benchmark functions (unimodal, simple unimodal, hybrid, and composition) of CEC 2017. In all categories, GJO-JOS showed promising best fitness values compared to the original version of GJO. It was noticed that the hybrid and composition functions of CEC 2017 have higher complexity problems compared to the other two groups (unimodal and simple multimodal) in CEC 2017. Both hybrid and composition functions consist of 10 benchmark functions on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{11} -f_{20})$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{21} -f_{30})$\n</tex-math></inline-formula>, respectively. Each of the functions is a representation of a hybrid or is composed of several functions.</p><p><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figure 5</a> and <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Figure 6</a> show the GJO-JOS and GJO performance, respectively, on hybrid functions on 10, 30, 50, and 100 dimensions in CEC 2017. <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Figure 7</a> and <a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Figure 8</a> show the GJO-JOS and GJO performance, respectively, on composition functions on 10, 30, 50, and 100 dimensions in CEC 2017. The left and right sides of the four figures present the same best fitness scale of the GJO-JOS and GJO hybrid functions. The red arrows on the hybrid and composition figures show the better mean best fitness of the algorithms. The lower the mean best fitness of the algorithms, the higher their performance.\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat5-3227510-large.gif\" data-fig-id=\"fig5\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat5-3227510-small.gif\" alt=\"FIGURE 5. - The comparison of GJO-JOS Hybrid Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in Tables 4, 5, 6, and 7.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>The comparison of GJO-JOS Hybrid Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4</a>, <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a>, and <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">7</a>.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat6-3227510-large.gif\" data-fig-id=\"fig6\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat6-3227510-small.gif\" alt=\"FIGURE 6. - The comparison of GJO Hybrid Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in Tables 4, 5, 6, and 7.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p>The comparison of GJO Hybrid Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4</a>, <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a>, and <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">7</a>.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig7\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat7-3227510-large.gif\" data-fig-id=\"fig7\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat7-3227510-small.gif\" alt=\"FIGURE 7. - The comparison of GJO-JOS Composition Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in Tables 4, 5, 6, and 7.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 7. </b><fig><p>The comparison of GJO-JOS Composition Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4</a>, <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a>, and <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">7</a>.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig8\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat8-3227510-large.gif\" data-fig-id=\"fig8\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat8-3227510-small.gif\" alt=\"FIGURE 8. - The comparison of GJO Composition Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in Tables 4, 5, 6, and 7.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 8. </b><fig><p>The comparison of GJO Composition Functions in 10, 30, 50, and 100 dimensions based on the obtained experiment results in <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4</a>, <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a>, and <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">7</a>.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div></p><p><a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Figure 6</a> shows the mean best fitness of GJO on hybrid functions. In 100D, we found that four benchmark functions of GJO on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{12},f_{13},f_{15} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{19} $\n</tex-math></inline-formula> did not perform as well as the others with values of 4.70E+10, 8.10E+09, 2.80E+09, and 2.70E+09, respectively. Of those four, the mean best fitness of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{12} $\n</tex-math></inline-formula> is the worst case compared to the best case that reached by <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula> with values of 5.50E+03. In 30D and 50D, only <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11},f_{16},f_{17}$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula> produced mean best fitness around +03, with the others producing above that number. However, in the lower dimension of 10D, GJO on the hybrid function relatively generates considerable mean best fitness of around +03 and +04. The +03 numbers produced were on benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11},f_{14},f_{15},f_{16},f_{17} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula> with the mean best fitness at 1.20E+03, 1.60E+03, 3.30E+03, 1.80E+03, 1.80E+03, and 2.10+03, respectively. Only <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{12} $\n</tex-math></inline-formula> produced 1.20E+06 on 10D.</p><p>In <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figure 5</a> and <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Figure 7</a>, we zoom in on the rapid line of the hybrid and composition functions of GJO-JOS on 30D and 50D to see the trend of the mean best fitness. The mean best fitness on hybrid functions of GJO-JOS (<a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figure 5</a>) 30D and 50D showed promising results on benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11},f_{16},f_{17} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula>. The results produced by benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11} $\n</tex-math></inline-formula> on 30D and 50D were 1.20E+03 and 1.40E+03, respectively; <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16} $\n</tex-math></inline-formula> on 30D and 50D produced 2.50E+03 and 2.90E+03, respectively; <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{17} $\n</tex-math></inline-formula> on 30D and 50D obtained 2.00E+03 and 2.80E+03, respectively; <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula> on 30D and 50D generated 2.30E+03 and 2.80E+03, respectively. However, the mean best fitness of GJO-JOS on hybrid functions did not perform as badly as the original GJO.</p><p>The worst case of mean best fitness of GJO-JOS was only 2.70E+08.</p><p>Overall, the mean best fitness of the GJO-JOS composition function (<a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Figure 7</a>) produced a better result than the original GJO composition function (<a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Figure 8</a>). For the most part, the result values of the mean best fitness of GJO-JOS and original GJO were around +03 and +04 except benchmark for function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{30}$\n</tex-math></inline-formula>. The benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{30} $\n</tex-math></inline-formula> GJO on 10D, 30D, 50D, and 100D produced mean best fitness values of 2.04E+05, 2.30E+07, 4.20E+08, and 6.50E+09, respectively. The benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{30} $\n</tex-math></inline-formula> GJO-JOS on 10D, 30D, 50D, and 100D produced mean best fitness values of 5.10E+04, 2.00E+06, 2.00E+07, and 2.10E+07, respectively. These mean best fitness results show that GJO-JOS resulted in a considerable improvement, however, it did not reach the mean best fitness of around +03 in all dimensions.</p><p>Moreover, an interesting trend occurs on 100D, the mean best fitness of benchmark functions GJO-JOS compared to GJO also showed promising improvement on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{25},f_{26},f_{28}$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{29}$\n</tex-math></inline-formula>. The mean best fitness results of GJO on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{25},f_{26},f_{28} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{29} $\n</tex-math></inline-formula> were 1.10E+04, 2.70E+04, 1.60E+04, and 1.40E+04, respectively. The mean best fitness results of GJO on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{25},f_{26},f_{28} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{29} $\n</tex-math></inline-formula> were 3.50E+03, 6.20E+03, 3.50E+03, and 6.90E+03, respectively.</p></div><div class=\"section_2\" id=\"sec4b\"><h3>B. The Comparison of GJO-JOS With Six Single Variants of Oppositions and GJO</h3><p>This sub-section discusses the experimental results of GJO-JOS, GJO with variant oppositions (DO, SLO, SO, Quasi, Generalized, and Reflection), and the original GJO using a scoring metric (as explained previously), statistical analysis based on the mean and the standard deviation of each algorithm on GJO-JOS, GJO-DO, GJO-SLO, GJO-SO, GJO-Quasi, GJO-Generalized, GJO-Reflection, and GJO, and the convergence curve of those algorithms.</p><div class=\"section_2\" id=\"sec4b1\"><h4>1) Scoring Metric of GJO-JOS Compared to Six Single Variants of Oppositions and GJO</h4><p><a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> and <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Table 3</a> show the experimental results from the calculation outcome of the scoring metric on <i>SE</i> and <i>SR</i>, respectively. The <i>SE</i> values are represented in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> as type of problem size and are calculated from <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (7)</a>. The total <i>SR</i> is a calculation result from <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (8)</a>.<div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nThe SE Score of GJO-JOS With Six Single Variant Oppositions and GJO</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t2-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t2-3227510-small.gif\" alt=\"Table 2- &#10;The SE Score of GJO-JOS With Six Single Variant Oppositions and GJO\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table3\"><div class=\"figcaption\"><b class=\"title\">TABLE 3 </b>\nThe SR Score of GJO-JOS With Six Single Variant Oppositions and GJO</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t3-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t3-3227510-small.gif\" alt=\"Table 3- &#10;The SR Score of GJO-JOS With Six Single Variant Oppositions and GJO\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>In both tables, the result values (<i>SE</i> and <i>SR</i>) are shown in problem sizes of 10, 30, 50, and 100 dimensions. The total score is presented as the conclusion of each algorithm. With regards to the problem size, <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> presents a summation of mean best fitness in all benchmark functions CEC 2017 of each algorithm, each of which is then multiplied by its weight as a result of the total score according to the aforementioned scoring metric formula (<a ref-type=\"disp-formula\" anchor=\"deqn9-deqn10\" href=\"#deqn9-deqn10\" class=\"fulltext-link\">Eq. 9</a>, <a ref-type=\"disp-formula\" anchor=\"deqn9-deqn10\" href=\"#deqn9-deqn10\" class=\"fulltext-link\">10</a>, and <a ref-type=\"disp-formula\" anchor=\"deqn11\" href=\"#deqn11\" class=\"fulltext-link\">11</a>). The results in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> clearly show that <i>SE</i> on GJO-JOS in 10D, 30D, 50D, and 100D have the lowest scores of 7.20E+05, 1.54E+07, 7.10E+07, and 2.96E+08, respectively. Moreover, we can see three trends based on the total scores of <i>SE</i>. Those trends are high, middle, and low values. The low scores of GJO-SLO, GJO-SO, GJO-Generalized, and the original GJO are 0.0904, 0.0756, 0.9202, and 0.0747, respectively. The middle scores of GJO-DO, GJO-Quasi, and GJO-Reflection are 17.5759, 15.3323, and 16.5037, respectively. GJO-JOS reaches a high trend with a total score of 50. Therefore, GJO-JOS on <i>SE</i> produces a promising score compared to GJO with other variant oppositions and the original GJO.</p><p>Furthermore, the problem size of <i>SR</i> in <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Table 3</a> shows the rank summation among its competitors. The best rank score of an algorithm among its competitors is valued as 1. The maximum rank is based on the total number of the compared algorithms. Among the comparison, the GJO-JOS produced the lowest rank value in 10D, 30D, 50D, and 100D with values 45, 31, 30, and 30, respectively. Moreover, GJO-JOS in <i>SR</i> also achieved the highest value of the <i>SR</i> total score (50). The highest score was achieved by GJO-DO with a total score of 19.1986. Next was GJO-Reflection with a total score of <i>SR</i> 15.4031, which was just slightly above GJO-Quasi with a score of 15.0281. GJO-SLO achieved a score of 10.9407, which was slightly above GJO-Generalized with a total score of 10.8373. Although the original GJO has the lowest total score in <i>SR</i> with 7.5035, GJO-SO is only slightly higher with a score of 7.6942.</p></div><div class=\"section_2\" id=\"sec4b2\"><h4>2) Statistical Analysis of GJO-JOS Compared to Six Single Variants of Oppositions and GJO</h4><p>This section exhibits the effectiveness of GJO-JOS among six existing single variants of oppositions embedded on GJO and the original version of GJO <a ref-type=\"bibr\" anchor=\"ref48\" id=\"context_ref_48_4b2\">[48]</a> on 10, 30, 50, and 100 dimensions (D) on the 29 benchmark functions of CEC 2017. The opposition variants were Dynamic Opposite (DO) <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_4b2\">[34]</a>, Selective Leading Opposition (SLO) <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_4b2\">[47]</a>, Selective Opposition (SO) <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_4b2\">[33]</a>, Quasi Opposition (Q) <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_4b2\">[29]</a>, Generalized Opposition (G) <a ref-type=\"bibr\" anchor=\"ref59\" id=\"context_ref_59_4b2\">[59]</a> and Reflection Opposition (R) <a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_4b2\">[30]</a>. The 29 benchmark functions were classified into four categories: unimodal, simple multimodal, hybrid, and composition. The effectivenesses of GJO-JOS and its competitors were measured by statistical analysis (mean and standard deviation) based on the best fitness as seen in <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4</a>, <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a>, and <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">7</a>. The boldface indicates the best result based on the mean best fitness. The italic presents the tied results among the competitors; however, the results of standard deviations (std) that are informed along the mean values are varied.<div class=\"figure figure-full table\" id=\"table4\"><div class=\"figcaption\"><b class=\"title\">TABLE 4 </b>\nGJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 10 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t4-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t4-3227510-small.gif\" alt=\"Table 4- &#10;GJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 10 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table5\"><div class=\"figcaption\"><b class=\"title\">TABLE 5 </b>\nGJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 30 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t5-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t5-3227510-small.gif\" alt=\"Table 5- &#10;GJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 30 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table6\"><div class=\"figcaption\"><b class=\"title\">TABLE 6 </b>\nGJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 50 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t6-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t6-3227510-small.gif\" alt=\"Table 6- &#10;GJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 50 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table7\"><div class=\"figcaption\"><b class=\"title\">TABLE 7 </b>\nGJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 100 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t7-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t7-3227510-small.gif\" alt=\"Table 7- &#10;GJO-JOS Compared to Six Variant Oppositions and GJO (Tested on 100 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>In all dimensions and in all categories of the benchmark functions, GJO-JOS among six existing single variants of oppositions embedded on GJO and the original version of GJO obtained promising experimental results. For unimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{1},f_{3})$\n</tex-math></inline-formula> in all dimensions, GJO-JOS produced a better fitness value compared to other competitors. For simple multimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{4} -f_{10})$\n</tex-math></inline-formula> in 10 dimensions, GJO-JOS only achieved better results in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{7} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{9} $\n</tex-math></inline-formula>. For the other benchmark functions of simple multimodal, GJO-JOS experienced a tie with GJO-DO (3 benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{7}, f_{8},f_{10}$\n</tex-math></inline-formula>), GJO-SLO (3 benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{7},f_{8},f_{10}$\n</tex-math></inline-formula>), and GJO-R (3 benchmark functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{4},f_{8},f_{10}$\n</tex-math></inline-formula>). Therefore, in simple multimodal 10D mostly tied in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{8} $\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{10} $\n</tex-math></inline-formula>. Nevertheless, GJO-JOS did not experience any losses compared to all of the other competitors in simple multimodal 10D. In simple multimodal with higher dimensions (30, 50 and 100), GJO-JOS only tied with GJO-DO on the 50D in the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{10} $\n</tex-math></inline-formula> (8.2E+03) and only lost to GJO-SLO on 100D in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{9} $\n</tex-math></inline-formula> (4.4E+04). For hybrid functions on 10D, GJO-JOS mostly experienced wins and ties compared with its competitors. The ties of GJO-JOS on 10D occurred on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11} $\n</tex-math></inline-formula> with GJO-DO, GJO-Q, and GJO-R with a score of 1.2E+03, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{13} $\n</tex-math></inline-formula> with GJO-Q, and GJO-R with a score of 1.1E+04, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{15} $\n</tex-math></inline-formula> with GJO-SLO with a score of 1.5E+03, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{20} $\n</tex-math></inline-formula> with GJO-DO, GJO-SLO, GJO-SO, GJO-Q, GJO-R and the original GJO with a score of 2.1E+03. However, GJO-JOS experienced a slight loss to GJO-SLO on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16} $\n</tex-math></inline-formula> (1.7E+03) and GJO-G on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{18} $\n</tex-math></inline-formula> (2.9E+04).</p><p>We also discovered losses in 30D for the hybrid function GJO-JOS with GJO-DO in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{13} $\n</tex-math></inline-formula> (8.6E+04) and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{15} $\n</tex-math></inline-formula> (2.7E+04). The other benchmark functions, GJO-JOS won. On the higher dimensions (50 and 100) in the hybrid functions, GJO-JOS showed superiority among its competitors without any ties or losses. In the higher dimensions (50 and 100) on the composition functions, GJO-JOS exhibited dominancy, however, GJO-JOS tied with GJO-DO in only one function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{24} $\n</tex-math></inline-formula> (3.1E+03). In the 10D and 30D of the composition functions, GJO-JOS achieved wins and ties with the other competitors.</p></div><div class=\"section_2\" id=\"sec4b3\"><h4>3) Convergence Curve of GJO-JOS Compared to Six Single Variants of Oppositions and GJO</h4><p>The sufficiency of GJO-JOS with six variants of oppositions and GJO is also measured by the convergence curve. The convergence curve is the visualization of the mean best fitness of an algorithm over the generations <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_4b3\">[17]</a>. In this case, the progress of the convergence curve is analyzed with the benchmark functions CEC 2017. The convergence of GJO-JOS and its competitors should reach the global optimum and should be able to avoid premature convergence, which would not leave it trapped in the local optima.</p><p>The convergence curves of GJO-JOS and GJO with six variants of oppositions and GJO are plotted based on the mean best fitness on the y-axis and the number of function evaluations on the x-axis as seen in <a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">Tables 8</a> and <a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">9</a>. The lower the mean best fitness, the better the algorithm. The GJO-JOS is presented in a bold diamond line at the very bottom of each graph and the original GJO is presented with a bold arrow. The convergences are displayed in four categories of the benchmark functions of CEC 2017 on 10, 30, 50, and 100 dimensions. We selected one function for each category of benchmark functions: unimodal (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{1}$\n</tex-math></inline-formula>), simple multimodal <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{6})$\n</tex-math></inline-formula>, hybrid (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16}$\n</tex-math></inline-formula>), and composition (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{24}$\n</tex-math></inline-formula>).<div class=\"figure figure-full table\" id=\"table8\"><div class=\"figcaption\"><b class=\"title\">TABLE 8 </b>\nConvergence Curve of GJO-JOS vs. Six Variant Oppositions and GJO: Unimodal Function on \n$f_{1}$\n and Simple Multimodal Function on \n$f_{6}$\n</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t8-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t8-3227510-small.gif\" alt=\"Table 8- &#10;Convergence Curve of GJO-JOS vs. Six Variant Oppositions and GJO: Unimodal Function on &#10;$f_{1}$&#10; and Simple Multimodal Function on &#10;$f_{6}$&#10;\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table9\"><div class=\"figcaption\"><b class=\"title\">TABLE 9 </b>\nConvergence Curve of GJO-JOS vs. Six Variant Oppositions and GJO: Hybrid Function on \n$f_{16}$\n and Composition Function on \n$f_{24}$\n</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t9-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t9-3227510-small.gif\" alt=\"Table 9- &#10;Convergence Curve of GJO-JOS vs. Six Variant Oppositions and GJO: Hybrid Function on &#10;$f_{16}$&#10; and Composition Function on &#10;$f_{24}$&#10;\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>For the unimodal benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{1} $\n</tex-math></inline-formula> in 10D, GJO-JOS is in close competition with the other algorithms. In order to observe this more closely we zoomed in on the tight line at <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$9\\,\\,\\times10$\n</tex-math></inline-formula><sup>4</sup> to get a better view of the GJO-JOS competitiveness with its competitors. As further proof, the harder the problem (30, 50, and 100 dimensions), the better the result of the convergence curve of GJO-JOS among its competitors.</p><p>In the case of the simple multimodal on the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{6} $\n</tex-math></inline-formula> in 10, 30, and 50 dimensions, GJO-JOS showed dominancy among its competitors. However, in 100D fierce competition occurred among all algorithms then we tried to zoom in on. Based on the zoomed in on line at <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\left ({{9-10} }\\right)\\times 10^{4}$\n</tex-math></inline-formula>, the GJO-JOS is able to compete with the original GJO, however, GJO-JOS did not reach the lowest score. At 100D, only GJO-SLO came slightly lower than the GJO-JOS.</p><p>For the hybrid on the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16} $\n</tex-math></inline-formula> in 10D, the GJO-JOS line was located just below the GJO. Underneath GJO-JOS, there are three algorithms (GJO-R in purple, GJO-G in light brown and the lowest GJO-SLO in light blue). However, the line representation of all algorithms in 30, 50, and 100 dimensions seems to converge in one place.</p><p>On 30D, when we zoom in on those lines, the mean best fitness of GJO-JOS is able to reach lower than the original GJO. However, the GJO-Q position is just slightly under the mean best fitness of GJO-JOS. Zooming in to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$9\\,\\,\\times10$\n</tex-math></inline-formula><sup>4</sup> on 50D, GJO-Q with the other two algorithms, GJO-G and GJO-SO, also have lower mean best fitness compared to GJO-JOS. However, the zoom in at <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$9 \\,\\,\\times10$\n</tex-math></inline-formula><sup>4</sup> on 50D, GJO-JOS managed to achieve the lowest mean best fitness among its competitors.</p><p>The composition of the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{24} $\n</tex-math></inline-formula> in 10D shows very clearly that GJO-JOS produced the lowest mean best fitness among its competitors in all dimensions (10, 30, 50, and 100 dimensions).</p></div></div><div class=\"section_2\" id=\"sec4c\"><h3>C. GJO-JOS Compared With Seven Variant Nature-Inspired Algorithms and GJO</h3><p>The experimental evaluation discussions of GJO-JOS with seven variant nature-inspired algorithms (Wild Horse Optimization (WHO) <a ref-type=\"bibr\" anchor=\"ref60\" id=\"context_ref_60_4c\">[60]</a>, Aquila Optimization (AO) <a ref-type=\"bibr\" anchor=\"ref61\" id=\"context_ref_61_4c\">[61]</a>, Artificial Bee Colony (ABC) <a ref-type=\"bibr\" anchor=\"ref62\" id=\"context_ref_62_4c\">[62]</a>, Harris Hawk Optimization (HHO) <a ref-type=\"bibr\" anchor=\"ref63\" id=\"context_ref_63_4c\">[63]</a>, Atomic Orbital Search (AOS) <a ref-type=\"bibr\" anchor=\"ref64\" id=\"context_ref_64_4c\">[64]</a>, Archimedes Optimization Algorithm (AOA) <a ref-type=\"bibr\" anchor=\"ref65\" id=\"context_ref_65_4c\">[65]</a>, and Neural Network Algorithm with Reinforcement Learning (RLNNA) <a ref-type=\"bibr\" anchor=\"ref66\" id=\"context_ref_66_4c\">[66]</a>) and original GJO are explained in detail as follows.</p><p>The first sub-section describes the performance of GJO-JOS with seven variant nature-inspired algorithms and GJO using a scoring metric. The second sub-section elucidates the statistical analysis of GJO-JOS with seven variant nature-inspired algorithms and GJO using mean and standard deviation (std). The third sub-section discusses the convergence ability of GJO-JOS with seven variant nature-inspired algorithms and GJO based on the mean best fitness and number of function evaluations.</p><div class=\"section_2\" id=\"sec4c1\"><h4>1) Scoring Metric GJO-JOS With Seven Variant Algorithms and Original GJO</h4><p><a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Figure 9</a> and <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Figure 10</a> show the total score of the scoring metric of GJO-JOS with seven variant algorithms and the original GJO based on the sum of error (<i>SE</i>) and the sum of rank (<i>SR</i>), respectively, present in <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (7)</a> and <a ref-type=\"disp-formula\" anchor=\"deqn7-deqn8\" href=\"#deqn7-deqn8\" class=\"fulltext-link\">Eq. (8)</a>. The patterned brick on the very left and right side in both figures shows the proposed GJO-JOS and the original GJO. The solid bricks that are shown between GJO-JOS and GJO are the competitor algorithms that were used to validate GJO-JOS performance.\n<div class=\"figure figure-full\" id=\"fig9\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat9-3227510-large.gif\" data-fig-id=\"fig9\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat9-3227510-small.gif\" alt=\"FIGURE 9. - Scoring Metric Result Sum of Error (SE) GJO-JOS and its competitors.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 9. </b><fig><p>Scoring Metric Result Sum of Error (SE) GJO-JOS and its competitors.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig10\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat10-3227510-large.gif\" data-fig-id=\"fig10\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat10-3227510-small.gif\" alt=\"FIGURE 10. - Scoring Metric Result Sum of Rank (SR) GJO-JOS and its competitors.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 10. </b><fig><p>Scoring Metric Result Sum of Rank (SR) GJO-JOS and its competitors.</p></fig></div><p class=\"links\"><a href=\"/document/9975297/all-figures\" class=\"all\">Show All</a></p></div></p><p>The arrow pointing up represents the score value of <i>SE</i> and <i>SR</i>. The higher the score the better the performance. The scores presented at the top of the bricks are the achievement scores for each algorithm in <i>SE</i> and <i>SR</i>. Both figures confirm that JOS on GJO does enhance the performance of GJO.</p><p>In <a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Figure 9</a>, the <i>SE</i> score on the total score of GJO-JOS (47.69) shows a huge improvement compared with the original GJO (0.07). We determined, from the <i>SE</i> based on GJO-JOS and its competitors, that there were three trends: low, mid, and high. The lower scores are on AOA, RLNNA, and GJO with values of 0.54, 0.08, and 0.07, respectively. The middle scores of 27.90 and 18.48 are achieved by HHO and AOS. The higher scores obtained by GJO-JOS (47.69), WHO (44.04), AO (46.96), and ABC (50). This demonstrates that these algorithms can produce considerable results of mean best fitness values.</p><p><a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Figure 10</a> shows the <i>SR</i> scores with GJO-JOS achieving the highest score at 50. The original GJO, however, reached a score of 15.43, which is slightly under the RLNNA (16.14). Therefore, the occurrence of the gap between GJO-JOS and the original GJO is not as significant as in <i>SE</i> (<a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Figure 9</a>). Interestingly, the <i>SR</i> score values of AO, ABC, HHO, AOS, AOA, RLNNA, and GJO are all quite close with score values of 26.45, 18.03, 18.97, 19.10, 23.53, 16.14, and 15.43, respectively.</p><p>We did, however, notice discrepancies in the algorithms based on <i>SE</i> and <i>SR</i>. On the <i>SE</i> scores, we saw three trends but only two trends on the SR, low and high. <i>SR</i> is the scoring summation of the comparison scoring on each algorithm. The lower scores of <i>SR</i> were acquired on AO, ABC, HHO, AOS, AOA, RLNNA, and GJO with scores of 26.45, 18.03, 18.97, 19.10, 23.53, 16.14, and 15.43, respectively. The high scores were achieved by GJO-JOS (50) and WHO (46.50). Although GJO-JOS at <i>SE</i> did not reach the highest score of 50 among its competitors, GJO-JOS still gained a promising total score (97.69) for <i>SE</i> and <i>SR</i>, as denoted in <a ref-type=\"disp-formula\" anchor=\"deqn11\" href=\"#deqn11\" class=\"fulltext-link\">Eq. (11)</a>.</p></div><div class=\"section_2\" id=\"sec4c2\"><h4>2) Statistical Analysis of GJO-JOS With Seven Variant Algorithms and the Original GJO</h4><p>This section presents the statistical analysis of GJO-JOS with seven variant algorithms (WHO, AO, ABC, HHO, AOS, AOA, and RLNNA) and the original GJO. The representation of the statistical analysis is presented in the same way as the previous sub-section, which evaluated the algorithms based on the mean and standard deviation (std) of 29 benchmark functions CEC 2017 in 10, 30, 50, and 100 dimensions. The discussions are specified on the four classifications for the 29 benchmark functions: unimodal, simple multimodal, hybrid, and composition as shown in <a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">Tables 10</a>, <a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\">11</a>, <a ref-type=\"table\" anchor=\"table12\" class=\"fulltext-link\">12</a>, and <a ref-type=\"table\" anchor=\"table13\" class=\"fulltext-link\">13</a>. The best-obtained results are shown in boldface on those tables and the ties are presented in italic.<div class=\"figure figure-full table\" id=\"table10\"><div class=\"figcaption\"><b class=\"title\">TABLE 10 </b>\nGJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 10 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t10-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t10-3227510-small.gif\" alt=\"Table 10- &#10;GJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 10 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table11\"><div class=\"figcaption\"><b class=\"title\">TABLE 11 </b>\nGJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 30 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t11-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t11-3227510-small.gif\" alt=\"Table 11- &#10;GJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 30 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table12\"><div class=\"figcaption\"><b class=\"title\">TABLE 12 </b>\nGJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 50 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t12-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t12-3227510-small.gif\" alt=\"Table 12- &#10;GJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 50 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table13\"><div class=\"figcaption\"><b class=\"title\">TABLE 13 </b>\nGJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 100 Dimensions, CEC 2017)</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t13-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t13-3227510-small.gif\" alt=\"Table 13- &#10;GJO-JOS Compared to Seven Nature-Inspired Algorithms and GJO (Tested on 100 Dimensions, CEC 2017)\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>In all dimensions (10, 30, 50, and 100) and in all categories of the benchmark functions (unimodal, simple multimodal, hybrid, and composition), GJO-JOS showed dominant result values to all seven variant algorithms (WHO, AO, ABC, HHO, AOS, AOA, and RLNNA) and the original GJO. WHO produced a slight high loss on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{1} $\n</tex-math></inline-formula> in 10, 30 and 50 dimensions with values 3.6E+02, 8.5E+03, and 8.6E+03, respectively. However, GJO-JOS generated better best fitness for all unimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{1},f_{3})$\n</tex-math></inline-formula> in all dimensions, compared to AO, ABC, HHO, AOS, AOA, RLNNA, and GJO.</p><p>As shown in <a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">Table 10</a>, for unimodal function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{3} $\n</tex-math></inline-formula> on 10 dimensions, we discovered several ties for the mean best fitness of GJO-JOS with WHO, AO, HHO, AOS, and AOA with a score of 3.0E+02.</p><p>For the simple multimodal functions <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{4} -f_{10})$\n</tex-math></inline-formula>, GJO-JOS showed promising results in all dimensions, which is confirmed by the fact that GJO-JOS did not experience any losses in 30, 50, and 100 dimensions as shown in <a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\">Tables 11</a>, <a ref-type=\"table\" anchor=\"table12\" class=\"fulltext-link\">12</a>, and <a ref-type=\"table\" anchor=\"table13\" class=\"fulltext-link\">13</a>. However, in 10D, for the simple multimodal functions, GJO-JOS only lost out to WHO (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{4},f_{8},f_{10}$\n</tex-math></inline-formula>) and ABC (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{4} $\n</tex-math></inline-formula>). On 10D for simple multimodal functions, GJO-JOS tied with WHO <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{5},f_{6})$\n</tex-math></inline-formula>, AO <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{5})$\n</tex-math></inline-formula>, AOA <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{5})$\n</tex-math></inline-formula>, and RLNNA <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{5},f_{6})$\n</tex-math></inline-formula>. <a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">Table 8</a> shows that for the hybrid functions on 10D, GJO-JOS experienced fragility compared to RLNNA. However, with other competitors, GJO-JOS just experienced ties with WHO (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11},f_{19}$\n</tex-math></inline-formula>), AO (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{11}$\n</tex-math></inline-formula>), ABC <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{17})$\n</tex-math></inline-formula>, AOA <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{11},f_{19},f_{20})$\n</tex-math></inline-formula>, and RLNNA <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{11},f_{17},f_{19},f_{20})$\n</tex-math></inline-formula>. In the higher dimensions (30, 50, and 100 dimensions), GJO-JOS dominated its competitors, as shown in <a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">Tables 9</a>\u2013<a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\"/><a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\">11</a>.</p><p>For the composition functions, GJO-JOS experienced more ties than the unimodal, simple multimodal, and hybrid functions. However, based on <a ref-type=\"table\" anchor=\"table10\" class=\"fulltext-link\">Tables 10</a>\u2013<a ref-type=\"table\" anchor=\"table11\" class=\"fulltext-link\"/><a ref-type=\"table\" anchor=\"table12\" class=\"fulltext-link\"/><a ref-type=\"table\" anchor=\"table13\" class=\"fulltext-link\">13</a> it can be seen that as the dimension size increases the number of ties reduces. This is confirmed by the result of the 100D score, GJO-JOS produced a better mean best fitness value compared to its competitors.</p></div><div class=\"section_2\" id=\"sec4c3\"><h4>3) Convergence Curve of GJO-JOS Compared to Seven Algorithms and the Original GJO</h4><p>The convergence curve of GJO-JOS compared to the seven variant algorithms and GJO, as shown in <a ref-type=\"table\" anchor=\"table14\" class=\"fulltext-link\">Tables 14</a> and <a ref-type=\"table\" anchor=\"table15\" class=\"fulltext-link\">15</a>, is similar to the convergence curve of GJO-JOS compared to the six variants of oppositions and GJO as shown in <a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">Tables 8</a> and <a ref-type=\"table\" anchor=\"table9\" class=\"fulltext-link\">9</a>. We describe the convergence curve of the algorithms by selecting one of the benchmark functions of CEC 2017 on each classified function, i.e., unimodal (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{1}$\n</tex-math></inline-formula>), simple multi-modal (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{6}$\n</tex-math></inline-formula>), hybrid (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16}$\n</tex-math></inline-formula>), and composition <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(f_{24})$\n</tex-math></inline-formula>. These selected benchmark functions are then evaluated on 10, 30, 50, and 100 dimensions. The lines representing each algorithm in the convergence curve are detailed and explained in the legend. The lines of GJO-JOS and GJO exhibited differently than the other algorithms. The aim of this was to see the strength of the GJO-JOS compared to the original GJO and the other nature-inspired algorithms. The line of GJO-JOS is presented in bold diamond and the line of GJO is defined in bold arrow. The lower line means that the mean of the best fitness algorithm is better.<div class=\"figure figure-full table\" id=\"table14\"><div class=\"figcaption\"><b class=\"title\">TABLE 14 </b>\nConvergence Curve of GJO-JOS vs. Seven Variant Algorithms and GJO: Unimodal Function on \n$f_{1}$\n and Simple Multimodal Function on \n$f_{6}$\n</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t14-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t14-3227510-small.gif\" alt=\"Table 14- &#10;Convergence Curve of GJO-JOS vs. Seven Variant Algorithms and GJO: Unimodal Function on &#10;$f_{1}$&#10; and Simple Multimodal Function on &#10;$f_{6}$&#10;\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table15\"><div class=\"figcaption\"><b class=\"title\">TABLE 15 </b>\nConvergence Curve of GJO-JOS vs. Seven Variant Algorithms and GJO: Hybrid Function on \n$f_{16}$\n and Composition Function on \n$f_{24}$\n</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t15-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t15-3227510-small.gif\" alt=\"Table 15- &#10;Convergence Curve of GJO-JOS vs. Seven Variant Algorithms and GJO: Hybrid Function on &#10;$f_{16}$&#10; and Composition Function on &#10;$f_{24}$&#10;\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>In unimodal benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{1} $\n</tex-math></inline-formula> in 10D, GJO-JOS with the variant nature-inspired algorithms demonstrated rapid solutions with each other. Therefore, we elucidate and zoom out the rapid line around the point of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$9\\,\\,\\times10$\n</tex-math></inline-formula><sup>4</sup>. In this case, the GJO-JOS (with the diamond line) showed a lower line than the original GJO arrowed line. GJO-JOS produces better results than the original GJO.</p><p>RLNNA however, displayed between GJO-JOS and GJO and the others followed the same line as GJO-JOS. This means that this problem size is convenient for the other algorithms to solve. For confirmation of this, it can be seen that the competition with GJO-JOS becomes increasingly tough when the dimensions become higher. However, GJO-JOS still manages to reach a lower mean best fitness than the original GJO.</p><p>In the simple multimodal benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{6} $\n</tex-math></inline-formula> in 10D, GJO-JOS fights fiercely with AOA, WHO, and RLNNA. On 30D, AOA gradually gained a lower mean best fitness and competed with GJO-JOS. In 30, 50, and 100 dimensions, WHO and RLNNA produced significantly mean the best fitness below GJO-JOS. Nevertheless, GJO-JOS did not lose to the original GJO, the well-known ABC, and the new promising algorithms such as AO, AOS, HHO, and AOA. The position of AOS on 50 and 100 dimensions is just under GJO-JOS.</p><p>The benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{16} $\n</tex-math></inline-formula> in all dimensions in hybrid shows that GJO-JOS performs adequately among its competitors. Finally, the benchmark function <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$f_{24} $\n</tex-math></inline-formula> in all dimensions of composition shows that WHO came just slightly below GJO-JOS. However, GJO-JOS still shows promising mean-best fitness in all dimensions.</p></div></div></div>\n<div class=\"section\" id=\"sec5\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION V.</div><h2>Conclusion and Future Work</h2></div><p>The philosophy of \u201c<i>square of opposition</i>\u201d by Aristotle exhibits the logical relationships of four basic categorial prepositions, namely contrary, contradictory, subcontrary, and subaltern. These categories successfully portray the correlation of logical relationships of the \u201c<i>square of opposition</i>\u201d and Joint Opposite Selection (JOS). Based on the \u201c<i>square of opposition</i>\u201d, the representation of JOS can define the relationship between Dynamic opposite (DO) and Selective Leading Opposition (SLO) in the exploration and exploitation phases, respectively. The relation characteristics of DO and SLO of JOS show the capability to strengthen each other in a given search space. From this, we can conclude that the JOS produces mutual reinforcement in the balance mechanism.</p><p>In the process optimization, JOS succeeds in utilizing SLO to assist GJO to strike out its prey swiftly. While DO on JOS enriches the probability of the GJO finding better chances to locate the fittest prey. We verified and analyzed the performance of GJO-JOS based on three different perspectives. First, GJO-JOS was compared to GJO among the OBLs embedded in GJO and nature-inspired algorithms on the hybrid and composition functions of CEC 2017. Second, GJO-JOS was compared to six OBLs embedded in GJO (GJO-DO, GJO-SLO, GJO-SO, GJO-Quasi, GJO-Generalized, and GJO-Reflection). Third, GJO-JOS was compared to seven nature-inspired optimization algorithms (i.e., Wild Horse Optimization (WHO), Aquila Optimization (AO), Artificial Bee Colony (ABC), Harris Hawk Optimization (HHO), Atomic Orbital Search (AOS), Archimedes Optimization Algorithm (AOA), and Neural Network Algorithm with Reinforcement Learning (RLNNA)) and the original version of GJO. These perspectives were included in the competition of 29 benchmark functions of CEC 2017. The CEC 2017 consists of four groups of classification benchmark functions: unimodal, multimodal, hybrid, and composition.</p><p>The first perspective shows the gap improvement of GJO-JOS and GJO among the OBLs embedded in GJO and nature-inspired algorithms on hybrid and composition functions of CEC 2017. In the second perspective, GJO-JOS shows consistent dominancy among the OBLs and GJO, which was determined using a scoring metric, mean and standard deviation, and convergence rates on 10D, 30D, 50D, and 100D. The determination in the second perspective was also utilized in the third perspective. Based on this determination, GJO-JOS competed fiercely with the original version of GJO and seven nature-inspired optimization algorithms. Therefore, based on those three perspectives, GJO-JOS exhibited a strong performance in improving the original version of GJO. The obtained results of GJO-JOS on the benchmark functions compared to six single OBL embedded on GJO, seven nature-inspired algorithms, and the original version of GJO demonstrated a promising result, especially in higher dimensions. Therefore, GJO-JOS can be considered to be a promising metaheuristic optimization algorithm.</p><p>Despite the usefulness of an algorithm for solving single-objective problems, scientific reviews <a ref-type=\"bibr\" anchor=\"ref44\" id=\"context_ref_44_5\">[44]</a>, <a ref-type=\"bibr\" anchor=\"ref67\" id=\"context_ref_67_5\">[67]</a>, <a ref-type=\"bibr\" anchor=\"ref68\" id=\"context_ref_68_5\">[68]</a>, <a ref-type=\"bibr\" anchor=\"ref69\" id=\"context_ref_69_5\">[69]</a>, have affirmed that there are limitations in the metaheuristic, meaning that there are no guarantees for finding an optimal global solution or the final solution even if sufficient diversity occurs. However, there are situations where GJO-JOS could be employed, i.e., it can be applied in a scenario with millions of different variables. The estimated time of GJO-JOS for solving this problem immediately requires a learning process for optimization, such as the knowledge transfer technique <a ref-type=\"bibr\" anchor=\"ref70\" id=\"context_ref_70_5\">[70]</a>, <a ref-type=\"bibr\" anchor=\"ref71\" id=\"context_ref_71_5\">[71]</a>. Using this method, the computational time can be shortened. Additionally, the management of massive data storage with millions of different variables <a ref-type=\"bibr\" anchor=\"ref72\" id=\"context_ref_72_5\">[72]</a> can be applied with distributed data and distributed processing. In the case of clustering, Tripathi et al. <a ref-type=\"bibr\" anchor=\"ref73\" id=\"context_ref_73_5\">[73]</a> partitioned a large dataset into small-scale input and then parallelized the fitness computation using the Map-Reduce mapper function.</p><p>For further future work, GJO-JOS could be applied to real-world problems. Scientific proofs have affirmed that opposition-based learning can solve real-world issues. For example, Swamy et al. <a ref-type=\"bibr\" anchor=\"ref74\" id=\"context_ref_74_5\">[74]</a> utilized an opposition-enhancing genetic algorithm that integrates with Cauchy mutation to minimize the cost of wind power plants. Kamau et al. <a ref-type=\"bibr\" anchor=\"ref75\" id=\"context_ref_75_5\">[75]</a> used opposition to improve chaotic elephant herding optimization for accelerating the MLP prediction rate, and Jiang et al. <a ref-type=\"bibr\" anchor=\"ref76\" id=\"context_ref_76_5\">[76]</a> showed the effectiveness of opposition embedded in the seagull optimization algorithm for classification achievement.</p></div>\n<h3>ACKNOWLEDGMENT</h3><p>The authors would like to thank researchers for sharing the source code and knowledge.</p>\n<div class=\"section\" id=\"app1\"><h2/><h1> Appendix of Variables/Parameters, Descriptions, and Sizes</h1><p><a ref-type=\"app\" anchor=\"app2\" class=\"fulltext-link\">Appendix A</a> presents the nomenclature of GJO, <a ref-type=\"app\" anchor=\"app3\" class=\"fulltext-link\">Appendix B</a> presents the nomenclature of DO, and <a ref-type=\"app\" anchor=\"app4\" class=\"fulltext-link\">Appendix C</a> presents the nomenclature of SLO.</p></div>\n<div class=\"section\" id=\"app2\"><h2/><h1>Appendix A GJO\u2019s Variable/Parameter, Description, and Size</h1><p><div class=\"figure figure-full table\" id=\"table16\"><div class=\"figcaption\"><b class=\"title\"> </b></div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t16-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t16-3227510-small.gif\" alt=\"Table\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div>\n<div class=\"section\" id=\"app3\"><h2/><h1>Appendix B DO\u2019s Variable/Parameter, Description, and Size</h1><p><div class=\"figure figure-full table\" id=\"table17\"><div class=\"figcaption\"><b class=\"title\"> </b></div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t17-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t17-3227510-small.gif\" alt=\"Table\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div>\n<div class=\"section\" id=\"app4\"><h2/><h1>Appendix C SLO\u2019s Variable/Parameter, Description, and Size</h1><p><div class=\"figure figure-full table\" id=\"table18\"><div class=\"figcaption\"><b class=\"title\"> </b></div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t18-3227510-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9975297/sunat.t18-3227510-small.gif\" alt=\"Table\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p><b>Declaration of Competing Interest</b></p><p>The authors declare that they have no known competing financial interests or personal relationships that could have influenced the work reported in this paper.</p></div>\n</div></div></response>\n"
}