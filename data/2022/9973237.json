{
    "abstract": "Developers use defect prediction models to efficiently allocate limited resources for quality assurance and appropriately make a plan for software quality improvement activities. Traditionally, defect predictions are conducted at the module level, such as the class or file level. However, a more recent trend is to perform defect prediction for a single or consecutive commits to the repository, whi...",
    "articleNumber": "9973237",
    "articleTitle": "Extending Developer Experience Metrics for Better Effort-Aware Just-In-Time Defect Prediction",
    "authors": [
        {
            "preferredName": "Yeongjun Cho",
            "normalizedName": "Y. Cho",
            "firstName": "Yeongjun",
            "lastName": "Cho",
            "searchablePreferredName": "Yeongjun Cho"
        },
        {
            "preferredName": "Jung-Hyun Kwon",
            "normalizedName": "J. -H. Kwon",
            "firstName": "Jung-Hyun",
            "lastName": "Kwon",
            "searchablePreferredName": "Jung-Hyun Kwon"
        },
        {
            "preferredName": "Jooyong Yi",
            "normalizedName": "J. Yi",
            "firstName": "Jooyong",
            "lastName": "Yi",
            "searchablePreferredName": "Jooyong Yi"
        },
        {
            "preferredName": "In-Young Ko",
            "normalizedName": "I. -Y. Ko",
            "firstName": "In-Young",
            "lastName": "Ko",
            "searchablePreferredName": "In-Young Ko"
        }
    ],
    "doi": "10.1109/ACCESS.2022.3227339",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9973237/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION I.</div><h2>Introduction</h2></div><p>Defect prediction helps developers identify software artifacts that are likely to have defects. It provides a sorted list of the potentially defective artifacts (those that are likely to be more error-prone appear earlier in the list), based on which developers can make a quality improvement plan considering limited resources <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\">[1]</a>. To predict the error-proneness of each software module,<a ref-type=\"fn\" anchor=\"fn1\" class=\"footnote-link\">1</a> most defect prediction techniques use a prediction model trained with various code metrics, such as the code complexity <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a> and change histories <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a> known to be effective in estimating error-proneness.</p><p>Although a defect prediction technique helps developers narrow down the modules to inspect, module inspection still requires a large effort because the module predicted to be error-prone may contain many lines of code (LOCs). To overcome this drawback of module-level defect prediction, recent studies have introduced just-in-time (JIT) defect prediction models. Given a set of code changes committed to the repository, JIT defect prediction models predict whether this set of code changes contains a defect. Because the number of changed lines at each commit is typically much smaller than the size of a potentially defective file, predicting defect-inducing code changes is known to be more effective in locating the defective lines. Moreover, JIT defect prediction techniques can provide feedback at the earlier stage of development compared to file-level defect prediction because defect prediction can be conducted as soon as a change is made into the source code repository, rather than waiting until a new version of the software is ready for inspection <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>.</p><p>To predict whether a code change induces a defect, researchers have proposed various change-level metrics, some of which are shown in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>. These metrics measure, for example, how big a code change is (Size), how many modules are changed (Diffusion), which developer modified the code and how experienced the developer is (Experience).<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nCommon Change-Level Metrics Used in the Previous Studies</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t1-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t1-3227339-small.gif\" alt=\"Table 1- &#10;Common Change-Level Metrics Used in the Previous Studies\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>To obtain accurate and useful prediction results from a defect prediction model, <i>it is important to use metrics effective for defect prediction.</i> To improve defect prediction performance, <i>we propose novel metrics extending the existing developer experience metrics.</i> Despite the fact that software defectiveness is likely to be affected by the experience of developers, developer metrics were understudied in the literature. In this work, we investigate the impact of various novel developer experience metrics and their combinations on JIT defect prediction. In particular, we compare the cost-effectiveness between different metrics. That is, we aim to find metrics that can reveal as many defects as possible after investigating the limited number of lines of changed code.</p><p>This paper makes the following contributions:\n<ol><li><p>We propose new developer experience metrics extending the existing ones. We extend developer metrics with two different dimensions. For the first dimension, we consider various <i>granularities of modules</i> (e.g., systems, subsystems, and files). For the second dimension, we consider various ways to measure <i>how recently</i> the developer made a change on the module (e.g., commit time and version numbers). We also consider the combinations of both dimensions.</p></li><li><p>We empirically evaluate our new developer experience metrics. We compare the performance (i.e., the cost-effectiveness of trained models) of our metrics with the existing ones. We find that our new experience metrics improve the cost-effectiveness of defect prediction models. In particular, we report which combination of our metrics results in consistent and statistically significant improvements.</p></li></ol></p><p>The rest of this article is organized as follows. <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Section II</a> discusses the background of our study. <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Section III</a> describes the new developer experience metrics that we propose. <a ref-type=\"sec\" anchor=\"sec4\" class=\"fulltext-link\">Section IV</a> discusses the design of our experiments, and <a ref-type=\"sec\" anchor=\"sec5\" class=\"fulltext-link\">Section V</a> presents the results of the experiments. <a ref-type=\"sec\" anchor=\"sec6\" class=\"fulltext-link\">Section VI</a> reports the threats to validity, and <a ref-type=\"sec\" anchor=\"sec7\" class=\"fulltext-link\">Section VII</a> provides the related works. Finally, <a ref-type=\"sec\" anchor=\"sec8\" class=\"fulltext-link\">Section VIII</a> presents the conclusions and future work of this study.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION II.</div><h2>Background</h2></div><div class=\"section_2\" id=\"sec2a\"><h3>A. Defect Prediction</h3><p>When developing software, software quality is one of the most critical aspects to the stakeholders of software development (e.g., customers, developers, and managers). Given limited resources, it is usually not feasible to take a close look at all parts of the software. Thus, it is important to know which part of the software is likely to be buggy so that developers can improve the software quality as much as possible within a limited time. For this purpose, defect prediction was proposed <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_2a\">[6]</a>.</p><p>Defect prediction is typically performed using a machine learning model. <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1</a> shows the typical workflow of defect prediction consisting of two phases. In the first phase (the upper right box of the figure), a defect prediction model <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M$\n</tex-math></inline-formula> is trained with data where each item of the data consists of the values of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n$\n</tex-math></inline-formula> metrics (where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n$\n</tex-math></inline-formula> represents the number of metrics used to train <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M$\n</tex-math></inline-formula>) and the label indicating whether the item is defective or not. As for metrics, diverse data such as code size, code complexity, and developer experience have been used in the literature, as shown in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>. The \u201cName\u201d and \u201cDescription\u201d column describes the name of the metrics and their descriptions, respectively. In defect prediction research, metrics are often categorized into several groups, as shown in the \u201cGroup\u201d column of the table. Training data is typically mined from version-control systems. Once a defect prediction model <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M$\n</tex-math></inline-formula> is trained, in the second phase (the lower right box of the figure), <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M$\n</tex-math></inline-formula> is used to locate modules that are likely to be defective.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi1-3227339-large.gif\" data-fig-id=\"fig1\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi1-3227339-small.gif\" alt=\"FIGURE 1. - Overview of the defect prediction activity.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>Overview of the defect prediction activity.</p></fig></div><p class=\"links\"><a href=\"/document/9973237/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Just-in-Time Defect Prediction</h3><p>In a modern software development environment where software is constantly changing, developers continue to commit their code changes to a code repository. In this environment, developers need to know whether their code changes are defective or not. For this reason, JIT (Just-In-Time) defect prediction was introduced \u2014 JIT defect prediction predicts how much the current code changes are likely to be buggy.</p></div><div class=\"section_2\" id=\"sec2c\"><h3>C. Change-Level Developer Experience Metrics Used in JIT Defect Prediction</h3><p>Metrics related to developer experience have been used in previous work <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_2c\">[7]</a>, <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_2c\">[8]</a>, <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_2c\">[9]</a>, <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_2c\">[10]</a>, <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_2c\">[11]</a>, with the rationale that more experienced developers are less likely to write faulty code. While developer experience is difficult to measure, it is commonly approximated by counting the number of changes made by the developer\u2014typically, one commit to a version control system is considered one change.</p><p>Specifically, the following three metrics have been used widely in the literature on defect prediction to measure developer experience: EXP (developer experience metric), SEXP (subsystem developer experience metric), and REXP (recent developer experience metric).</p><div class=\"section_2\" id=\"sec2c1\"><h4>1) EXP</h4><p>First, EXP for a change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is defined as:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\text {EXP}(c) = |Changes(d_{c})| \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\text {EXP}(c) = |Changes(d_{c})| \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d_{c}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Changes(d_{c})$\n</tex-math></inline-formula> represent the developer who made the change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>, and the changes <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d_{c}$\n</tex-math></inline-formula> made on the <i>project</i> until <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is made (including <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>), respectively.</p><p>Consider <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a> where the developer has made &lt;Change #4&gt; after making three changes from &lt;Change #1&gt; to &lt;Change #3&gt;. Then, EXP(&lt;Change #4&gt;) is 4 since the developer made a total of 4 changes, including &lt;Change #4&gt;. See the EXP column of <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>.<div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nThe Values of the Metrics for the Example Scenario Shown in Figure 2</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t2-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t2-3227339-small.gif\" alt=\"Table 2- &#10;The Values of the Metrics for the Example Scenario Shown in Figure 2\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div>\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi2-3227339-large.gif\" data-fig-id=\"fig2\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi2-3227339-small.gif\" alt=\"FIGURE 2. - An example scenario of code changes.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>An example scenario of code changes.</p></fig></div><p class=\"links\"><a href=\"/document/9973237/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec2c2\"><h4>2) SEXP</h4><p>In a modern distributed software development environment, developers typically work on specific subsystems. Thus, a developer usually has different levels of expertise on different subsystems. A developer who has substantial expertise on a subsystem <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{1}$\n</tex-math></inline-formula> may not be familiar with another subsystem <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{2}$\n</tex-math></inline-formula> and is more likely to induce fault on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{2}$\n</tex-math></inline-formula> than on <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{1}$\n</tex-math></inline-formula>. However, the EXP metric does not distinguish the developer experience between different subsystems. Meanwhile, the second metric, SEXP, measures the developer\u2019s experience with the subsystems under change. The following is the definition of SEXP. <disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\text {SEXP}(c) = |Changes(d_{c}, S(c))| \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\text {SEXP}(c) = |Changes(d_{c}, S(c))| \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S(c)$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Changes(d_{c}, S(c))$\n</tex-math></inline-formula> represent the subsystems modified by the change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>, and the changes <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d_{c}$\n</tex-math></inline-formula> made on a <i>subsystem</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$s \\in S(c)$\n</tex-math></inline-formula> until <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is made (including <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>), respectively.</p><p>In our running example, SEXP(&lt;Change #4&gt;) is 3 since with &lt;Change #4&gt;, the developer has made a change on two subsystems, subsys1 and subsys2, and she also changed one of those two subsystems at &lt;Change #1&gt; and &lt;Change #2&gt;. See the SEXP column of <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>.</p></div><div class=\"section_2\" id=\"sec2c3\"><h4>3) REXP</h4><p>As developers accumulate experience on the system under development, they are less likely to write faulty code. REXP, defined in the following, correlates the error-proneness of the change with how recently that change was made.<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\text {REXP}(c) = \\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + Y(c, c')} \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\text {REXP}(c) = \\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + Y(c, c')} \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Y(c, c')$\n</tex-math></inline-formula> is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\lfloor Y(c) - Y(c') \\rfloor $\n</tex-math></inline-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Y(c)$\n</tex-math></inline-formula> refers to the year when change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is made.</p><p>The REXP column of <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> shows how REXP(&lt;Change #4&gt;) is computed. Notice in <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a> that the developer made &lt;Change #1&gt; 800 days (less than 3 years) ago, &lt;Change #2&gt; 400 days (less than 2 years) ago, and &lt;Change #3&gt; 30 days (less than 1 year) ago. As shown in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>, REXP(&lt;Change #4&gt;) is the sum of 1/(1+2), 1/(1+1), 1/(1+0), and 1/(1+0).</p></div></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION III.</div><h2>New Developer Experience Metrics</h2></div><p>In this section, we describe our new developer experience metrics.</p><div class=\"section_2\" id=\"sec3a\"><h3>A. Module-Based Metrics</h3><div class=\"section_2\" id=\"sec3a1\"><h4>1) MEXP</h4><p>Although SEXP considers developer experience at a finer granularity level (i.e., a subsystem) than EXP, it may not be fine-grained enough. We propose a more fine-grained metric, MEXP, which considers developer experience at the module level \u2014 in this work, we define a module as a file. We define MEXP as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\text {MEXP}(c) = |Changes(d_{c}, M(c))| \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\text {MEXP}(c) = |Changes(d_{c}, M(c))| \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M(c)$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Changes(d_{c}, M(c))$\n</tex-math></inline-formula> refer to the modules modified by the change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>, and the changes <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d_{c}$\n</tex-math></inline-formula> made on a <i>module</i> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m \\in M(c)$\n</tex-math></inline-formula> until <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is made (including <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>), respectively. MEXP counts the number of changes developer <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d_{c}$\n</tex-math></inline-formula> made on the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M(c)$\n</tex-math></inline-formula> modules.</p><p>In our running example, MEXP(&lt;Change #4&gt;) is 2 since at &lt;Change #4&gt;, moduleA and moduleE are modified, and one of these two modules is modified at &lt;Change #1&gt;. See the MEXP column of <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>.</p></div><div class=\"section_2\" id=\"sec3a2\"><h4>2) AVG_MEXP and AVG_SEXP</h4><p>Consider the following two scenarios. In the first scenario, the developer has created the initial version of 100 modules and committed them to the repository. In the second scenario, the developer has modified a single module she previously modified 99 times. Although the first change would be more error-prone than the second one, MEXP does not distinguish between them \u2014 in both cases, MEXP is 100. While this example is an extreme case, it reveals the limitation of MEXP. Motivated by this problem, we suggest a new metric AVG_MEXP defined as follows, which computes the average value of MEXP:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\mathrm {AVG\\_{}MEXP}(c) = \\frac {\\text {MEXP}(c)}{|M(c)|} \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\mathrm {AVG\\_{}MEXP}(c) = \\frac {\\text {MEXP}(c)}{|M(c)|} \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M(c)$\n</tex-math></inline-formula> refers to the modules modified by change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>. In our running example, AVG_MEXP(&lt;Change #4&gt;) is 1 since MEXP(&lt;Change #4&gt;) is 2 and &lt;Change #4&gt; modifies two modules.</p><p>Similar to AVG_MEXP, we also use AVG_SEXP defined as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\mathrm {AVG\\_{}SEXP}(c) = \\frac {\\text {SEXP}(c)}{|S(c)|} \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\mathrm {AVG\\_{}SEXP}(c) = \\frac {\\text {SEXP}(c)}{|S(c)|} \\end{equation*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S(c)$\n</tex-math></inline-formula> refers to the subsystems modified by change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>.</p></div><div class=\"section_2\" id=\"sec3a3\"><h4>3) SimEXP</h4><p>Suppose that a developer <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d$\n</tex-math></inline-formula> made the following two code changes. In the first code change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{1}$\n</tex-math></inline-formula>, she modified module <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{1}$\n</tex-math></inline-formula>. In the second code change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{2}$\n</tex-math></inline-formula>, she modified two modules, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{1}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{2}$\n</tex-math></inline-formula>. The developer may gain different experiences when performing these two changes. While the task performed at <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{1}$\n</tex-math></inline-formula> is concentrated on a single module <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{1}$\n</tex-math></inline-formula>, the second change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{2}$\n</tex-math></inline-formula> is likely to involve interaction between the two modified modules. When the same developer <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d$\n</tex-math></inline-formula> later makes a new change only on a module <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{1}$\n</tex-math></inline-formula>, the experience she gained from <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{1}$\n</tex-math></inline-formula> is more likely to be relevant to the current task than the other experience gained from <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{2}$\n</tex-math></inline-formula>. Conversely, when <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$d$\n</tex-math></inline-formula> modifies the two modules <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{1}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$m_{2}$\n</tex-math></inline-formula>, the opposite is more likely to be true. More generally, we conjecture that the more similar the past experience of the developer is to the current change, that experience is likely to have a bigger influence on the current change. Here, the similarity between two changes <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{1}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{2}$\n</tex-math></inline-formula> is proxied by the similarity between the two sets of modules modified in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{1}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{2}$\n</tex-math></inline-formula>, which we formally describe as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\frac {\\left |{ M(c_{1}) \\cap M(c_{2}) }\\right |}{\\left |{ M(c_{1}) \\cup M(c_{2}) }\\right |}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\frac {\\left |{ M(c_{1}) \\cap M(c_{2}) }\\right |}{\\left |{ M(c_{1}) \\cup M(c_{2}) }\\right |}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M(c_{i})$\n</tex-math></inline-formula> represents the modules modified in change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{i}$\n</tex-math></inline-formula>. Based on this notion, we define a new metric SimEXP as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\text {SimEXP}(c) = \\sum _{c' \\in Changes(d_{c})} \\frac {\\left |{ M(c) \\cap M(c') }\\right |}{\\left |{ M(c) \\cup M(c') }\\right |} \\end{equation*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\text {SimEXP}(c) = \\sum _{c' \\in Changes(d_{c})} \\frac {\\left |{ M(c) \\cap M(c') }\\right |}{\\left |{ M(c) \\cup M(c') }\\right |} \\end{equation*} \n</span></span></disp-formula></p><p>In our running example, SimEXP is 1.5 as shown in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>. Note that for &lt;Change #1&gt;, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(| M(c) \\cap M(c')|)/(| M(c) \\cup M(c')|)$\n</tex-math></inline-formula> is <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$|\\{$\n</tex-math></inline-formula>moduleA<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\}| / |\\{$\n</tex-math></inline-formula>moduleA, moduleE<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\}|$\n</tex-math></inline-formula>, which equals 0.5. The rest of the changes can be handled similarly.</p></div></div><div class=\"section_2\" id=\"sec3b\"><h3>B. Temporal Metrics</h3><div class=\"section_2\" id=\"sec3b1\"><h4>1) RVEXP and RvEXP</h4><p>The motivation of REXP is to assign a larger weight to a more recent change. To define how recent a past change <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is, REXP compares the time when <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> was made and the time when the current change is made.</p><p>There is another way to measure how recently the past changes were made. Many software products are maintained using the semantic versioning scheme <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_3b1\">[12]</a>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n_{1}.n_{2}.n_{3}$\n</tex-math></inline-formula>, where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n_{1}$\n</tex-math></inline-formula>, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n_{2}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$n_{3}$\n</tex-math></inline-formula> represent the major version number, the minor version number, and the patch version number, respectively. By comparing the versions of two different changes (i.e., commits), one can measure the interval between those two changes.</p><p>In this study, we experiment with two new metrics (RVEXP and RvEXP), each of which computes the interval at the granularity of the major versions (RVEXP) and the minor versions (RvEXP), respectively. We define these two new metrics as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\text {RVEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + V(c, c')} \\\\ \\text {RvEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + v(c, c')} \\end{align*} \n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\text {RVEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + V(c, c')} \\\\ \\text {RvEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c})} \\frac {1}{1 + v(c, c')} \\end{align*} \n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$V(c,c')$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$v(c,c')$\n</tex-math></inline-formula> represent the version difference between <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c'$\n</tex-math></inline-formula> at the granularity of major versions and minor versions, respectively.</p><p>In our running example, RVEXP is 3 as shown in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>. Note that the major version at &lt;Change #1&gt; and &lt;Change #2&gt; is 2, while the major version at &lt;Change #3&gt; is 3. Thus, for &lt;Change #1&gt; and &lt;Change #2&gt;, value 1/(1+1) is obtained. Meanwhile, for &lt;Change #3&gt; whose major version is 3, value 1/(1+0) is obtained.</p><p>RvEXP is computed similarly based on minor versions, as shown in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>. For example, the minor version difference between &lt;Change #3&gt; and &lt;Change #1&gt; is 5 (the version change history is shown in the bottom part of <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a>), and the value 1/(1+5) is obtained.</p></div><div class=\"section_2\" id=\"sec3b2\"><h4>2) RSEXP, RMEXP, RVSEXP, RVMEXP, RvSEXP and RvMEXP</h4><p>We also define temporal metrics at the subsystem and module levels as follows, similar to before.<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\text {RSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + Y(c, c')} \\\\ \\text {RMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + Y(c, c')} \\\\ \\text {RVSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + V(c, c')} \\\\ \\text {RVMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + V(c, c')} \\\\ \\text {RvSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + v(c, c')} \\\\ \\text {RvMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + v(c, c')}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\text {RSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + Y(c, c')} \\\\ \\text {RMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + Y(c, c')} \\\\ \\text {RVSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + V(c, c')} \\\\ \\text {RVMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + V(c, c')} \\\\ \\text {RvSEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, S(c))} \\frac {1}{1 + v(c, c')} \\\\ \\text {RvMEXP}(c)=&amp;\\sum _{c' \\in Changes(d_{c}, M(c))} \\frac {1}{1 + v(c, c')}\\end{align*}\n</span></span></disp-formula></p></div><div class=\"section_2\" id=\"sec3b3\"><h4>3) AVG Metrics</h4><p>For the six metrics shown in <a ref-type=\"sec\" anchor=\"sec3b2\" class=\"fulltext-link\">Section III-B2</a>, we define the AVG metrics. For example, AVG_RSEXP and AVG_RMEXP are defined as follows:<disp-formula id=\"\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mathrm {AVG\\_{}RSEXP}(c)=&amp;\\frac {\\text {RSEXP}(c)}{|S(c)|}\\\\ \\mathrm {AVG\\_{}RMEXP}(c)=&amp;\\frac {\\text {RMEXP}(c)}{|M(c)|}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mathrm {AVG\\_{}RSEXP}(c)=&amp;\\frac {\\text {RSEXP}(c)}{|S(c)|}\\\\ \\mathrm {AVG\\_{}RMEXP}(c)=&amp;\\frac {\\text {RMEXP}(c)}{|M(c)|}\\end{align*}\n</span></span></disp-formula></p></div></div></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION IV.</div><h2>Experiment Design</h2></div><div class=\"section_2\" id=\"sec4a\"><h3>A. Research Questions</h3><p>In this paper, our main goal is to see whether using our new developer experience metrics improves the performance of defect prediction. We accordingly ask the following research questions.\n<ol><li><p>Do our module-based metrics improve the performance of defect prediction?</p></li><li><p>Do our temporal metrics improve the performance of defect prediction?</p></li><li><p>Does the performance of defect prediction improve when our module-based and temporal metrics are combined?</p></li></ol></p></div><div class=\"section_2\" id=\"sec4b\"><h3>B. Dataset</h3><p>We extracted the dataset from the five open-source projects listed in <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Table 3</a>. The table shows meta-data about the projects, including (from left to right) the domain of the projects, the programming languages used in the projects, LOC,<a ref-type=\"fn\" anchor=\"fn2\" class=\"footnote-link\">2</a> the number of commits, the number of developers who contributed to the projects, and the ratio of defective commits. Our dataset covers diverse domains and programming languages. Note that the datasets used in the previous studies <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_4b\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_4b\">[9]</a>, <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_4b\">[13]</a>, <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_4b\">[14]</a> do not contain our new metrics and cannot be directly used for our experiments.<div class=\"figure figure-full table\" id=\"table3\"><div class=\"figcaption\"><b class=\"title\">TABLE 3 </b>\nDataset Used in Our Experiment</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t3-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t3-3227339-small.gif\" alt=\"Table 3- &#10;Dataset Used in Our Experiment\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>We extracted all 14 change-level metrics shown in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>.<a ref-type=\"fn\" anchor=\"fn3\" class=\"footnote-link\">3</a> In addition, we extracted our new experience metrics descried in <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Section III</a>. To label whether a change is defective or not, we use the standard SZZ algorithm <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_4b\">[16]</a>.</p></div><div class=\"section_2\" id=\"sec4c\"><h3>C. JIT Defect Prediction Models</h3><p>We train our JIT defect prediction models using random forest <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_4c\">[17]</a>. Random forest is a classification (and regression) technique using multiple decision trees (we used 100 decision trees in our experiments). A classification decision (e.g., whether a change is defective or not) is made by performing the majority voting with the trained multiple decision trees. Random forest is commonly used in the literature of defect prediction research due to its high effectiveness <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_4c\">[18]</a>, <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_4c\">[19]</a>, <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_4c\">[20]</a></p></div><div class=\"section_2\" id=\"sec4d\"><h3>D. Performance Measures</h3><p>To measure the performance of effort-aware JIT defect prediction, we use the Area Under the Cost Effectiveness Curve (AUCEC). AUCEC is commonly used in the literature on defect prediction to measure the cost-effectiveness of defect prediction <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_4d\">[20]</a>, <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_4d\">[21]</a>, <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_4d\">[22]</a>.</p><p><a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figure 3</a> illustrates AUCEC. In the figure, the X and Y-axis represent the ratio of inspected changed lines and the ratio of detected defects, respectively. Each point <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$(x,y)$\n</tex-math></inline-formula> of the curve denotes the portion of the detected defects (represented with the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$y$\n</tex-math></inline-formula> value) after investigating the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$x$\n</tex-math></inline-formula> portion of the changes (represented with the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$x$\n</tex-math></inline-formula> value). Note that the ratio of the inspected changed lines is used as a proxy for the effort the developers put in.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi3-3227339-large.gif\" data-fig-id=\"fig3\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi3-3227339-small.gif\" alt=\"FIGURE 3. - Area Under the Cost Effectiveness Curve (AUCEC).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>Area Under the Cost Effectiveness Curve (AUCEC).</p></fig></div><p class=\"links\"><a href=\"/document/9973237/all-figures\" class=\"all\">Show All</a></p></div></p><p>When measuring AUCEC, we assume that the developers investigate changes <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> in the order of their cost-effectiveness scores <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$ce(c)$\n</tex-math></inline-formula> computed using the following formula.<disp-formula id=\"deqn1\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} ce(c) = p(c) \\times \\left({1 -\\frac {e(c)}{\\max \\limits _{i \\in Changes}{e(i)}}}\\right) \\tag{1}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} ce(c) = p(c) \\times \\left({1 -\\frac {e(c)}{\\max \\limits _{i \\in Changes}{e(i)}}}\\right) \\tag{1}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$p(c)$\n</tex-math></inline-formula> represents the error-proneness of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> returned from the trained JIT defect prediction model,<a ref-type=\"fn\" anchor=\"fn4\" class=\"footnote-link\">4</a> <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$e(c)$\n</tex-math></inline-formula> represents the effort proxied by the number of changed lines of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$Changes$\n</tex-math></inline-formula> represents a set of changes to investigate. Notice that as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$p(c)$\n</tex-math></inline-formula> increases (i.e., <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> is predicted to be more error-prone) and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$e(c)$\n</tex-math></inline-formula> decreases (i.e., <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c$\n</tex-math></inline-formula> modifies the smaller number of lines), the value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$ec(c)$\n</tex-math></inline-formula> increases.</p><p>If a defect prediction model <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$A$\n</tex-math></inline-formula> shows a higher AUCEC value than another model <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$B$\n</tex-math></inline-formula>, this implies that after investigating the same amount of lines of code, more defects are detected by <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$A$\n</tex-math></inline-formula> than <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$B$\n</tex-math></inline-formula>. In the literature on defect prediction, it is often assumed that developers usually investigate only <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula>% of the changed lines within a limited time. As for the value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula>, 20 is most often used, and we also use the same. We use the notation AUCEC<sub>20</sub> to denote the AUCEC score obtained after inspecting the 20% of SLOC (source lines of code).</p></div><div class=\"section_2\" id=\"sec4e\"><h3>E. Evaluation Methods</h3><p>To assess how useful our extended metrics are, we perform defect prediction with two different datasets, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{target}$\n</tex-math></inline-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> contains the common existing metrics used in previous studies while <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{target}$\n</tex-math></inline-formula> is defined as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base} \\cup \\{\\text {extended metric(s)}\\}$\n</tex-math></inline-formula>. More specifically, we first add all metrics shown in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a> except for two developer experience metrics, SEXP and REXP, into <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula>. To refer to these common base metrics, we use the notation <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common}$\n</tex-math></inline-formula>. Then, depending on which extended metrics are evaluated, we add either SEXP or REXP into <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula>. When evaluating module-based metrics, we define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {SEXP}\\}$\n</tex-math></inline-formula>. Meanwhile, when evaluating temporal metrics, we define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {REXP}\\}$\n</tex-math></inline-formula>. This is to evaluate module-based (or temporal) metrics separately without them being affected by temporal (or module-based) metrics. When assessing RQ3 where we consider both module-based and temporal metrics, and accordingly define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {SEXP, REXP}\\}$\n</tex-math></inline-formula>.</p><p>Given <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{target}$\n</tex-math></inline-formula>, we compare their performance using the two validation methods described in the following.</p><div class=\"section_2\" id=\"sec4e1\"><h4>1) 30 Times 10-Fold Time-Aware Cross Validation</h4><p>The 10-fold cross-validation method is commonly used to evaluate machine-learning models. This method splits the dataset into 10 folds and uses 9 for training and the remaining one for testing. In total, 10 different pairs of training/testing sets can be obtained, and all of them are used for validation. We repeat this process 30 times.</p><p>Considering the fact that a defection prediction model is trained with the past data, we make sure all commits in training set <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{train}$\n</tex-math></inline-formula> are made before the commits in the testing set <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{test}$\n</tex-math></inline-formula>, using the following method. For a given testing dataset <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{test}$\n</tex-math></inline-formula>, we sort <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{test}$\n</tex-math></inline-formula> in reverse chronological order. We also prepare two lists, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S'_{test}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S'_{train}$\n</tex-math></inline-formula>, initialized with an empty set and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{train}$\n</tex-math></inline-formula>, respectively. Then, we perform the following two tasks in a row.\n<ol><li><p>We move the first item <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{test}$\n</tex-math></inline-formula> from <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{test}$\n</tex-math></inline-formula> to <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S'_{test}$\n</tex-math></inline-formula>.</p></li><li><p>We find items <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{train} \\in S_{train}$\n</tex-math></inline-formula> committed later than <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{test}$\n</tex-math></inline-formula> and then remove <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{train}$\n</tex-math></inline-formula> from <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S'_{train}$\n</tex-math></inline-formula>.</p></li></ol> We repeat these two steps as long as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$|S'_{train}| / |S'_{test}|$\n</tex-math></inline-formula> is larger than 9.</p></div><div class=\"section_2\" id=\"sec4e2\"><h4>2) Time-Aware Hold-Out Cross Validation</h4><p>We found that the 30 times 10-fold time-aware cross-validation often results in low statistical power. To compensate for this problem, we also apply hold-out cross validation. We sort our dataset in chronological order and use the first 90% of the data for training and the last 10% for testing. We train and test a model 300 times for each metric we evaluate.</p></div></div></div>\n<div class=\"section\" id=\"sec5\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION V.</div><h2>Experiment Results</h2></div><div class=\"section_2\" id=\"sec5a\"><h3>A. RQ1. Do Our Module-Based Metrics Improve the Performance of Defect Prediction?</h3><p><a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Tables 4(a)</a> and <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">4(b)</a> show the results for RQ1 from 30 times 10-fold time-aware cross validation and time-aware hold-out cross validation, respectively. The first column of the table shows the subjects under evaluation, and the second column shows the median AUCEC<sub>20</sub> score obtained when the base metrics <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> is used. Recall that for RQ1, we define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {SEXP}\\}$\n</tex-math></inline-formula>.<div class=\"figure figure-full table\" id=\"table4\"><div class=\"figcaption\"><b class=\"title\">TABLE 4 </b>\nAUCEC20 of Our Module-Based Metrics; Positive Improvement Rates (Shown in the \u201c\n$\\uparrow$\n Rate\u201d Column), p-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t4-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t4-3227339-small.gif\" alt=\"Table 4- &#10;AUCEC20 of Our Module-Based Metrics; Positive Improvement Rates (Shown in the \u201c&#10;$\\uparrow$&#10; Rate\u201d Column), p-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>To assess our extended module-based metrics, we measure the AUCEC<sub>20</sub> score after replacing SEXP with each of those extended metrics. The third to fifth columns of the table show the results. For each extended metric, we report the median AUCEC<sub>20</sub> score, the improvement rate (<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\uparrow $\n</tex-math></inline-formula> rate) (which we describe shortly), p-value, and effect size. We compute the p-value and effect size using the Wilcoxon-Mann-Whitney test <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_5a\">[23]</a>. The improvement rate shows how much AUCEC<sub>20</sub> score improves when SEXP is replaced with the metric under consideration. We define the improvement rate as ((median<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$_{target} -$\n</tex-math></inline-formula> median<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$_{base}$\n</tex-math></inline-formula>) / median<inline-formula id=\"\"><tex-math notation=\"LaTeX\">$_{base}$\n</tex-math></inline-formula>) <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\times 100$\n</tex-math></inline-formula>.</p><p>The results of the first validation (30 times 10-fold time-aware cross-validation) show that our module-based metrics tend to cause a positive effect, although statistical significance is not observed except for one (AVG_SEXP for React). However, the hold-out validation results show that in most cases, statistically significant improvement is observed. Our three metrics, MEXP, AVG_MEXP, and SimEXP outperform SEXP across all subjects. In particular, AVG_MEXP outperforms SEXP with statistical significance (i.e., <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\leq0.05$\n</tex-math></inline-formula>) across all subjects except for Notepad++ where the p-value is 0.058.</p><p>The box plots in <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Figure 4</a> illustrate the observation that MEXP, AVG_MEXP, and SimEXP outperform SEXP.<div class=\"inline-story\"><p>Our three module-based metrics, MEXP, AVG_MEXP, and SimEXP outperform the existing metrics across all subjects.</p></div>\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi4-3227339-large.gif\" data-fig-id=\"fig4\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi4-3227339-small.gif\" alt=\"FIGURE 4. - Time-aware hold-out cross-validation: performance comparison between SEXP and our three new metrics (MEXP, AVG_MEXP, SimEXP).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>Time-aware hold-out cross-validation: performance comparison between SEXP and our three new metrics (MEXP, AVG_MEXP, SimEXP).</p></fig></div><p class=\"links\"><a href=\"/document/9973237/all-figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec5b\"><h3>B. RQ2: Do Our Temporal Metrics Improve the Performance of Defect Prediction?</h3><p>For RQ2, we define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {REXP}\\}$\n</tex-math></inline-formula>. Similar to RQ1, we measure the AUCEC<sub>20</sub> score after replacing REXP with each of our temporal metrics. <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">Tables 5</a> and <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">6</a> show the results for RQ2 from 30 times 10-fold time-aware cross validation and time-aware hold-out cross validation, respectively. As compared to the module-based metrics, positive effects are less observed. Nonetheless, we can observe from <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">Table 6</a> that AVG_RVMEXP outperforms REXP across all subjects. Also, performance improvement is observed for all subjects except for React when RSEXP, RVSEXP, RvSEXP, RvMEXP, or AVG_RvMEXP is used.<div class=\"inline-story\"><p>Our temporal metric, AVG_RVMEXP, outperforms the existing metrics across all subjects.</p></div><div class=\"figure figure-full table\" id=\"table5\"><div class=\"figcaption\"><b class=\"title\">TABLE 5 </b>\n30 Times 10-Fold Time-Aware Cross-Validation: AUCEC20 Comparison Between REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c\n$\\uparrow$\n Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t5-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t5-3227339-small.gif\" alt=\"Table 5- &#10;30 Times 10-Fold Time-Aware Cross-Validation: AUCEC20 Comparison Between REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c&#10;$\\uparrow$&#10; Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table6\"><div class=\"figcaption\"><b class=\"title\">TABLE 6 </b>\nTime-Aware Hold-Out Cross-Validation: AUCEC20 Comparison Between REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c\n$\\uparrow $\n Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t6-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t6-3227339-small.gif\" alt=\"Table 6- &#10;Time-Aware Hold-Out Cross-Validation: AUCEC20 Comparison Between REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c&#10;$\\uparrow $&#10; Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div><div class=\"section_2\" id=\"sec5c\"><h3>C. RQ3: Does the Performance of Defect Prediction Improve When Our Module-Based and Temporal Metrics are Combined?</h3><p>Since combining 6 module-based metrics and 18 temporal metrics results in too many combinations (108), we combine the three best module-based metrics with which performance improvement is observed across all subjects (i.e., AVG_MEXP, SimEXP, and AVG_RVMEXP) and the six temporal metrics with which performance improvement is observed in at least 4 subjects (i.e., AVG_RVMEXP, RSEXP, RVSEXP, RvSEXP, RvMEXP, and AVG_RvEXP). We compare each of the 18 combinations with the base case where we define <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> as <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{common} \\cup \\{\\text {SEXP, REXP}\\}$\n</tex-math></inline-formula>. Note that SEXP and REXP are the existing module-level and temporal metrics, respectively.</p><p><a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">Tables 7</a> and <a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">8</a> show the results. <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">Table 7</a> shows the result of the 30 times 10-fold time-aware cross-validation, and it is observed that SimEXP+AVG_RvMEXP outperforms <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> across all subjects.<div class=\"figure figure-full table\" id=\"table7\"><div class=\"figcaption\"><b class=\"title\">TABLE 7 </b>\n30 Times 10-Fold Time-Aware Cross-Validation: AUCEC20 Comparison Between SEXP+REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c\n$\\uparrow$\n Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t7-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t7-3227339-small.gif\" alt=\"Table 7- &#10;30 Times 10-Fold Time-Aware Cross-Validation: AUCEC20 Comparison Between SEXP+REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c&#10;$\\uparrow$&#10; Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table8\"><div class=\"figcaption\"><b class=\"title\">TABLE 8 </b>\nTime-Aware Hold-Out Cross-Validation: AUCEC20 Comparison Between SEXP+REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c\n$\\uparrow$\n Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t8-3227339-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi.t8-3227339-small.gif\" alt=\"Table 8- &#10;Time-Aware Hold-Out Cross-Validation: AUCEC20 Comparison Between SEXP+REXP and the Metrics Behind the Double Vertical Bar (||); Positive Improvement Rates (Shown in the \u201c&#10;$\\uparrow$&#10; Rate\u201d Column), P-Values Less Than or Equal to 0.5, and Effect Sizes (Shown in the \u201cEffect\u201d Column) Larger Than or Equal to 0.1 are Highlighted in Yellow\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p><a ref-type=\"table\" anchor=\"table8\" class=\"fulltext-link\">Table 8</a> shows the result of the time-aware hold-out cross-validation. It is observed that in most cases, p-values are less than 0.05, and effect sizes are larger than 0.1, indicating statistically-significant non-negligible results are obtained. As compared to RQ1 and RQ2, combining our module-based and temporal metrics tends to cause more visible changes in performance.</p><p>SimEXP+AVG_RVMEXP outperforms <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$M_{base}$\n</tex-math></inline-formula> across all subjects, with statistical significance. In addition to that, in three more combinations (i.e., AVG_MEXP+AVG_ RVMEXP, AVG_MEXP+RSEXP, and AVG_MEXP+ AVG_RvMEXP), performance improves across all subjects. The box plots in <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figure 5</a> illustrate the observation that these four combinations outperform the base case using the combination of SEXP and REXP.<div class=\"inline-story\"><p>When combining our module-based and temporal metrics, statistically significant improvement is observed. In particular, SimEXP+AVG_RVMEXP outperforms the existing metrics across all subjects, with statistical significance.</p></div>\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi5-3227339-large.gif\" data-fig-id=\"fig5\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9973237/yi5-3227339-small.gif\" alt=\"FIGURE 5. - Time-aware hold-out cross-validation: performance comparison between SEXP+REXP and the four combination of our metrics.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>Time-aware hold-out cross-validation: performance comparison between SEXP+REXP and the four combination of our metrics.</p></fig></div><p class=\"links\"><a href=\"/document/9973237/all-figures\" class=\"all\">Show All</a></p></div></p></div></div>\n<div class=\"section\" id=\"sec6\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VI.</div><h2>Threats to Validity</h2></div><div class=\"section_2\" id=\"sec6a\"><h3>A. Construct Validity</h3><p>We collected independent variables (i.e, the change-level metrics) based on the CodeRepoAnalyzer <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_6a\">[15]</a>, and the dependent variable (i.e., the variable indicating whether a commit is defective or not) using the SZZ algorithm. Although these algorithms have been widely used in defect prediction studies <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_6a\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_6a\">[24]</a>, they may produce incorrect results (e.g., non-defective change may be labeled defective). The computation of REXP and its extended metrics (i.e., RSEXP, RMEXP) are computed based on the commit history. There is a potential threat to the validity in case the developers \u201csquash\u201d (merge) multiple commits since by doing so, the commit order between commits is lost.</p></div><div class=\"section_2\" id=\"sec6b\"><h3>B. Internal Validity</h3><p>When measuring AUCEC, we used 20% as the cutoff point, as commonly conducted in the literature on defect prediction. Nonetheless, it is unknown which cutoff point is best. To mitigate this threat, we also evaluated the performance with the 10% cutoff point and observed the same general tendency.</p></div><div class=\"section_2\" id=\"sec6c\"><h3>C. External Validity</h3><p>We conducted the experiments with data from five open-source projects. Although we carefully chose various projects with different sizes, domains, and programming languages used, our subjects may not represent all software projects. Nonetheless, to the best of our knowledge, this is the first study that investigates the impact of extended developer experience metrics on defect prediction. We expect our positive results to foster further studies on developer experience metrics.</p></div></div>\n<div class=\"section\" id=\"sec7\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VII.</div><h2>Related Works</h2></div><div class=\"section_2\" id=\"sec7a\"><h3>A. Identification of Buggy Patterns Based on Developer Experience Factors</h3><p>Matsumoto et al. <a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_7a\">[25]</a> defined five metrics that characterize a developer\u2019s activities for a specific version of the software and analyzed the correlation between those metrics and the ratio of the buggy commits authored by a developer. The five metrics they defined for each developer for a specific software version are 1) the number of commits made by a developer 2) the number of lines revised by a developer 3) the number of unique modules revised by a developer, 4) the number of unique packages revised by a developer, and 5) the ratio of buggy commits by a developer for the previous version. Analysis results showed that the number of unique modules revised and the ratio of buggy commits for the previous version significantly correlated with the ratio of buggy commits for the chosen version. Although the authors used version information in collecting a developer\u2019s experience, those developer experience metrics are defined per developer for a specific version rather than per change. Moreover, whether these metrics are a good predictor of defect prediction was not determined, even though the authors showed that developer experiences may have an impact on software quality.</p><p>Bird et al. <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_7a\">[26]</a> examined the effects of code ownership on software quality. For each file, they counted the number of contributors; the number of minor or major contributors, which is distinguished by the ratio of the contribution, whether it is higher than 5%; and the ownership, which is computed by using the top contributor\u2019s contribution ratio. To evaluate the effects of four ownership metrics on software quality, they conducted a correlation analysis of the pre- and post-release failures and built linear regression models using code metrics and ownership metrics as the independent variables and failures as the dependent variable. They specified that their purpose for building the linear regression models was not to predict whether a file contains any defect but to check whether the ownership metrics can be effectively used in classification models. Based on their experimental results, they recommended that developers should review the changes made by minor contributors more carefully since their limited experiences may induce defects. Unlike our work, this work is conducted at the file level, not at the change level.</p><p>Eyolfson et al. <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_7a\">[27]</a> studied the correlation between the error-proneness of a commit and the developer\u2019s experience, which was proxied by the days passed after the first commit the developer made on the Linux kernel and PostgreSQL projects. They reported that there are several threats that may affect the interpretation of the relationship between the developer experience metric and the bugginess of a commit, such as more experienced developers working on more complex source code or inflation of the developer experience metric value caused by his/her extremely low commit frequency. Nonetheless, the authors observed that data from both projects showed that the error-proneness of a commit decreases as the author\u2019s experience increases in general, and they reported that this correlation could be exploited in predicting the locations of buggy code. Although the authors showed the possibility of using developer experience metrics in defect prediction, they used a very basic method in quantifying a developer\u2019s experience. Moreover, the performance impact of the developer experience metric they proposed for defect prediction models was not evaluated.</p><p>Tufano et al. <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_7a\">[28]</a> analyzed the effect of the experience level of developers on the bugginess of a commit on five Java open-source projects. They defined four different developer experience metrics at the change level that consider the lexical experience and the frequency of experience on modified files. More specifically, the lexical experience metric is calculated by using the textual similarity between the texts in a modified file and the concatenated texts from all files modified by an author of the change. After obtaining the lexical experience on the files that were modified in a commit, the authors computed the mean value of the lexical experience on multiple files to ensure that the metric is defined at the change level. The frequency of experience was computed by counting the number of commits that were made by the author on the file modified in the target commit, and then dividing that counted number by the number of the commits the author made in the past. Furthermore, two additional developer experience metrics were defined in the same manner as the previous two metrics, except that these metrics only consider the commits from the past six months. The authors concluded that the mean value of the four developer experience metrics from fix-inducing commits and clean commits was significantly different. Although they defined four new developer experience metrics and showed the possibility of the usefulness of these metrics in defect prediction models, they used fixed time windows for calculating the developer\u2019s recent experience, and the performance impact of these metrics on JIT defect prediction was not shown.</p></div><div class=\"section_2\" id=\"sec7b\"><h3>B. Developer Experience Metric on JIT Defect Prediction</h3><p>Mockus and Weiss <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_7b\">[8]</a> suggested various change-level metrics, including EXP, SEXP, and REXP described in <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Section II</a>. Kamei et al. <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_7b\">[4]</a> used various metrics, including the developer experience metrics of Mockus and Weiss <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_7b\">[8]</a> to evaluate the performance of JIT defect prediction. However, they did not extend developer experience metrics. McIntosh and Kamei <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_7b\">[9]</a> proposed the author awareness metrics, which is defined as the proportion of past changes that were made to a subsystem that the reviewer has authored or reviewed. They did not find this metric useful in improving the performance of the JIT defect prediction. In this work, we proposed another developer experience metrics that show a positive effect on the performance of JIT defect prediction.</p></div></div>\n<div class=\"section\" id=\"sec8\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION VIII.</div><h2>Conclusion and Future Work</h2></div><p>In this work, we have proposed novel developer experience metrics. In particular, we extended the widely-used two experience metrics, SEXP and REXP. SEXP is defined at the granularity of subsystems, and we have proposed MEXP defined at the file granularity. We also proposed SimEXP, which measures the similarities between commits. Regarding REXP, which measures how recently the developer made a change with the unit of the year, we have suggested RVEXP and RvEXP, which measures the same with the unit of the major and minor versions, respectively. We also suggested the variation of those metrics (i.e., AVG_RVMEXP) by averaging the experiences, instead of summing them up. We also combined these metrics together when conducting experiments.</p><p>Our experimental results show that our new metrics often improve the cost-effectiveness of defect-prediction models. When we combined module-based metrics and temporal metrics, we obtained stronger results. In particular, when combining SimEXP and AVG_RVMEXP, the statistically significant performance improvement was observed across all 5 subjects. In future work, we plan to experiment with more subjects to study how general our findings are.</p></div>\n<h3>ACKNOWLEDGMENT</h3><p>This work is done while Stavros Yeongjun Cho and Jung-Hyung Kwon were at KAIST.</p></div></div></response>\n"
}