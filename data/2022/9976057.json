{
    "abstract": "Among the prevalent cyberattacks on Android devices, a ransomware attack is the most common and damaging. Although there are many solutions for detecting Android ransomware attacks, existing solutions have limited detection accuracy and high computational complexity. This paper proposes a new Android ransomware detection method based on traffic analysis to address the limitations. We exploit parti...",
    "articleNumber": "9976057",
    "articleTitle": "Android Ransomware Detection From Traffic Analysis Using Metaheuristic Feature Selection",
    "authors": [
        {
            "preferredName": "Md. Sakir Hossain",
            "normalizedName": "M. S. Hossain",
            "firstName": "Md. Sakir",
            "lastName": "Hossain",
            "searchablePreferredName": "Md. Sakir Hossain"
        },
        {
            "preferredName": "Naim Hasan",
            "normalizedName": "N. Hasan",
            "firstName": "Naim",
            "lastName": "Hasan",
            "searchablePreferredName": "Naim Hasan"
        },
        {
            "preferredName": "Md. Abdus Samad",
            "normalizedName": "M. A. Samad",
            "firstName": "Md. Abdus",
            "lastName": "Samad",
            "searchablePreferredName": "Md. Abdus Samad"
        },
        {
            "preferredName": "Hossain Md. Shakhawat",
            "normalizedName": "H. M. Shakhawat",
            "firstName": "Hossain Md.",
            "lastName": "Shakhawat",
            "searchablePreferredName": "Hossain Md. Shakhawat"
        },
        {
            "preferredName": "Joydeep Karmoker",
            "normalizedName": "J. Karmoker",
            "firstName": "Joydeep",
            "lastName": "Karmoker",
            "searchablePreferredName": "Joydeep Karmoker"
        },
        {
            "preferredName": "Foysol Ahmed",
            "normalizedName": "F. Ahmed",
            "firstName": "Foysol",
            "lastName": "Ahmed",
            "searchablePreferredName": "Foysol Ahmed"
        },
        {
            "preferredName": "K. F. M. Nafiz Fuad",
            "normalizedName": "K. F. M. N. Fuad",
            "firstName": "K. F. M. Nafiz",
            "lastName": "Fuad",
            "searchablePreferredName": "K. F. M. Nafiz Fuad"
        },
        {
            "preferredName": "Kwonhue Choi",
            "normalizedName": "K. Choi",
            "firstName": "Kwonhue",
            "lastName": "Choi",
            "searchablePreferredName": "Kwonhue Choi"
        }
    ],
    "doi": "10.1109/ACCESS.2022.3227579",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9976057/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION I.</div><h2>Introduction</h2></div><p>With our increasing reliance on mobile devices, people keep valuable information in their devices and online storage. The wicked people get lured by the potential access to confidential information mainly for illicit financial gain, and other purposes <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\">[1]</a>. Such wicked people carry out cyber-attacks to steal that information or hamper the regular usage of the devices. One of the most common attacks on mobile devices is the ransomware attack, in which an attacker either encrypts the data on the devices or locks the devices, thereby preventing legitimate users from accessing the data or devices. Since Android is the most popular operating system in the world of mobile devices <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\">[2]</a>, these devices are the common target of ransomware attacks. An effective ransomware attack detection technique should be devised to ensure the security of our Android device. Next, innovative approaches are discussed for detecting Android malware. In <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>, the authors propose a permission-based malware detection method to differentiate between benign and malware applications in the case of an unknown signature. This method involves two steps: feature selection using information gain and classification using Na\u00efve Bayes, random forest, and decision tree (J48). In <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\">[3]</a>, the author uses the Genome Project dataset with 100 newly downloaded benign and 100 malware. The authors then use the APK file to extract permission. The random forest gives a higher accuracy of 89.8% than the others. The true positive rate (TPR) and false positive rate (FPR) are 0.890 and 0.110, respectively. In <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\">[4]</a>, the authors propose to find the best feature selection set with the best classifier for detecting Android malware. A dataset of 30 malicious and 30 benign applications is created. Four sets of features are selected on the basis of four feature selection algorithms. Then, five classifiers named Na\u00efve Bayes, k-nearest neighbor, decision tree (J48), multi-layer perceptron (MLP), and random forest are trained against the selected features. The MLP classifier with Chi-square and information gain achieves the best overall result, with a TPR of 0.9, FPR of 0.23, and accuracy of 0.83. However, the reduction of 70% features still results in a good performance. In <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\">[5]</a>, an optimizer named genetic algorithm is used to select the best subset from the feature set. The genetic algorithm\u2019s fitness function is defined so that the chromosome that gives the machine learning-based classifier high accuracy is assigned a higher weight. The author works on 40000 APK files with 99 extracted features. After applying the SVM and MLP classifiers, 33 and 40 features are selected from 99 features using SVM and MLP. In this <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\">[6]</a>, the author proposes a feature selection based on a self-variant genetic algorithm (SV-GA) for detecting Android malware. The proposed algorithm is compared to the existing genetic algorithm using the UCI dataset <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\">[7]</a>. Four classifiers are trained using 88-feature datasets. The SV-GA attains 93.6% accuracy.</p><p>A static Android malware detection method is proposed that uses ML classifiers based on the symmetric features of Android malware applications. Three feature selection techniques are used to find a lightweight ML algorithm that can reduce data size and features. In <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\">[8]</a>, a framework is proposed that uses machine learning to prevent permission-based malware attacks. The authors first extract the features from the Android.apk files and then create a dataset from the extracted features from the Android applications. In feature selection, the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {k-}$\n</tex-math></inline-formula>best information gain method is used. A random forest is found to outperform other classifiers. A comparative study of various combinations of features and classification algorithms is presented in <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\">[9]</a> for classifying Android malware. The feature selection algorithms include gain ratio attribute evaluator, consistency subset evaluator, relief attribute evaluator, and correlation feature selection (CFS) subset evaluator. The random forest with the CFS subset evaluation provides the highest accuracy (94.9%). In <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\">[10]</a>, the selection of features based on the Linux kernel is proposed to detect malware in the Android 5 or later version. In this study, a total of 59 features have been selected by the authors. The system detects the malware by using the SVM classifier. As a result, 23 features are removed, which gives the best result with the 36 features. In <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\">[11]</a>, the authors propose a method for detecting malicious Android applications using the feature selection method. Three types of features opcodes, methods, and strings, are selected from each Android file using feature selection techniques. Authors use feature selection methods such as Goodman Kruskals, information gain, and CFS. The CFS adaboost classifier achieves the highest malware detection accuracy of 88.75%. The model is biased toward benign apps due to an imbalanced dataset. In <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_1\">[12]</a>, a lightweight system is proposed that combines static and dynamic analysis to detect malware on Android devices. In the PCA-RELIEF feature selection method, principal component analysis (PCA) is used to reduce the dimensions of the features. RELIEF then provides the corresponding weights for each feature. Then the features with higher weights are chosen from the dataset. The Androguard is used for static analysis, and the Droidbox is used for dynamic analysis to extract features. The PCA-RELIEF gets the best accuracy, which is 95.2%. Article <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_1\">[13]</a> proposes a method to protect a network from an adversarial attack. They created adversarial samples to achieve this goal through evolutionary optimization. The adversarial and conventional samples are then used to train a deep-learning model. In <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_1\">[14]</a>, an improvised particle swarm optimization (PSO) algorithm and a feature selection technique based on a rough set are proposed to select features in the permission-based detection of Android malware. A new random key encoding method converts a classical continuous PSO to a discrete domain. The performance of the proposed method is evaluated using two datasets: Wang\u2019s repository dataset and another is Contagiodump dataset. The proposed technique outperforms feature selection algorithms such as Pearson correlation, information gain, gain ratio, chi-square, and so on. Article <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\">[15]</a> introduces a new method to detect ransomware using an evolutionary-based machine learning approach. The SVM algorithm is used for classification. The dataset is generated using API calls. Whereas PSO is used to select features, five oversampling methods balance the datasets. The SMOTE-PSO-SVM approach provides the best result. In <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_1\">[16]</a>, the effect of feature selection on malware detection is investigated. In this study, the author works with supervised and unsupervised machine learning. It includes both classification and clustering. The dataset consists of 149 samples, where 68 and 81 samples are malicious and benign, respectively. For dynamic analysis, a cuckoo sandbox is used. In the machine learning phase, both supervised and unsupervised techniques are used. Six supervised learning algorithms are used. In unsupervised learning, the authors use the expectation-maximization (EM) algorithm. The MLP is found to achieve the highest accuracy of 77.18%.</p><p>In contrast to most of the above works in which API analysis is considered, a ransomware detection method based on traffic analysis is proposed in <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\">[17]</a>. Several feature selection algorithms are used to find the most influential features. A total of 19 features are selected. Then, the long short-term memory (LSTM) is used to classify the ransomware. Only binary classification (ransomware vs. benign traffic) is performed. An accuracy of 97.08% is achieved. Article <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a> suggests another method to find ransomware based on traffic analysis. This study investigates the accuracy of finding different ransomware. In each case, a binary classification is performed between a type of ransomware and benign traffic. The random forest is found to achieve the best performance among various machine learning algorithms. A semi-supervised approach is used in <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a>, where a binary classification between ransomware and benign traffic is performed. In addition, a family classification similar to <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a> is also performed. In <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\">[17]</a>, <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a>, and <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a>, CICAndMal2017 dataset is used. Among the studies discussed above, most articles work with API calls to detect ransomware detection. The PSO is used in <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\">[15]</a> for feature selection of ransomware detection. However, the number of features is about 200, which incurs a substantial computational complexity. It has yet to explore the field of traffic analysis. The detection of a specific class of ransomware is done in <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\">[20]</a>. Decision tree algorithm is used, where hyperparameter tuning is performed using the grid search algorithm. No feature selection is made in <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\">[20]</a>. In <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_1\">[21]</a>, about 97% precision is obtained with 19 features. However, the flow information, such as the source IP, destination IP, protocol, and timestamp features, are considered. However, these features are experimentally dependent, and the values of these features will not be related to the production network. As a result, using these features gives the experiment a very high degree of accuracy. However, the accuracy of the production network will be much lower. In <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_1\">[18]</a> and <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_1\">[19]</a>, the source and destination IP addresses, protocol, and timestamp features are removed to eliminate the experiment dependency. The accuracy of ransomware detection is limited, and feature selection techniques are not applied. Because of the above limitations, we need to find a ransomware detection technique that uses a minimum number of features while providing better accuracy. This paper proposes an Android ransomware detection method from traffic analysis using PSO-based feature selection. We separately select the most influential features for both binary and multiclass classification. An extensive experiment compares the proposed method\u2019s performance with various feature selection methods and classifiers.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION II.</div><h2>Proposed Ransomware Detection Algorithm</h2></div><p>In this chapter, we present the proposed Android ransomware detection system. The system model of the proposed system is shown in <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1</a>. The details of each of the constituents of the proposed system are described in the following.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi1-3227579-large.gif\" data-fig-id=\"fig1\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi1-3227579-small.gif\" alt=\"FIGURE 1. - Block diagram of the proposed Android ransomware detection system.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>Block diagram of the proposed Android ransomware detection system.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><div class=\"section_2\" id=\"sec2a\"><h3>A. Dataset</h3><p>The CICAndMal2017 dataset <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_2a\">[22]</a> is generated by the Canadian center for the cyber security of the University of New Brunswick. Besides benign traffic, this dataset contains traffic information for four different types of malware: scareware, adware, ransomware, and SMS malware. They installed the applications in real Android devices to avoid the stealthy features of various malware in an emulator environment. They collected traffic data in three different phases: (i) just after installing the apps, (ii) 15 minutes before rebooting the devices, and (iii) 15 minutes after rebooting the devices. Each of the malware categories has about ten families. For example, the ransomware category comprises ten families: charger, jisut, koler, lockerpin, simplocker, pletor, porndroid, ransomBO, svpeng, and wannalocker. Each instance of the dataset contains 84 features. The detection of Android ransomware is the subject of this study. As a result, we look at the samples that correspond to the ransomware. To do this, we created a new dataset that included both ransomware traffic and benign traffic. In <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a>, we give the number of instances per ransomware class. We merge plenty of ransomware into a single file and add 54161 instances of benign traffic samples captured in 2017 to reduce the imbalance issue in the dataset. Thus, the number of samples in the dataset (ransomware and benign) becomes 402834.<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nNumber of Instances Per Ransomware Class in the CICAndMal2017 Dataset</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t1-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t1-3227579-small.gif\" alt=\"Table 1- &#10;Number of Instances Per Ransomware Class in the CICAndMal2017 Dataset\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>In the aggregated dataset, the F1 (Flow ID), F2 (Source IP), F4 (Destination IP), and F7 (Timestamp) features depend on the experimental setup and cannot be matched in a production network. For this reason, we remove these features, as they have no impact on traffic categories, as is done in <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_2a\">[18]</a> and <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_2a\">[19]</a>. In addition, some features have zero values for all instances. Since the values of the features do not change for the instances, they do not correlate with the class labels. For this reason, we removed those features. The all-zero features include: F38, F39, F40, F52, F56, F57, F63, F64, F65, F66, F67, and F68. In addition, we also removed the F62 feature, as it duplicates the F41 feature. After removing the above features, we have 68 features left in the dataset.</p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Preprocessing</h3><div class=\"section_2\" id=\"sec2b1\"><h4>1) Normalization</h4><p>We normalize the dataset to lessen the dominance of some features with high values relative to other features with low values in the prediction results. In this paper, we use minimax normalization, which is defined as follows:<disp-formula id=\"deqn1\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} x_{i}=\\frac {x_{i}-x_{\\mathrm {min}}}{x_{\\mathrm {max}}-x_{\\mathrm {min}}}\\tag{1}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} x_{i}=\\frac {x_{i}-x_{\\mathrm {min}}}{x_{\\mathrm {max}}-x_{\\mathrm {min}}}\\tag{1}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {x_{i}}$\n</tex-math></inline-formula> is the value of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {i^{th}}$\n</tex-math></inline-formula> instance of a feature, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {x_{min}}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\mathrm {x_{max}}$\n</tex-math></inline-formula> are the smallest and largest values of the feature.</p></div><div class=\"section_2\" id=\"sec2b2\"><h4>2) Oversampling</h4><p>The number of samples per class of ransomware differs significantly, which leads to a severe imbalance in the aggregated ransomware dataset. A machine learning model trained against an imbalanced dataset suffers from the effect of bias toward the classes having a higher number of samples. It predicts more frequently that the class has more samples to achieve higher accuracy. Such a model cannot perform in the production network as efficiently as on the test set. To eliminate the bias effect, we perform an over-sampling of the dataset to produce an equal number of samples in each class. We perform the oversampling by replicating the samples of the classes that have a lower number of samples.</p></div></div><div class=\"section_2\" id=\"sec2c\"><h3>C. Feature Selection</h3><p>Once the preprocessing is done, we split the dataset into training and testing parts. We select the set of most influential features using the training dataset by applying particle swarm optimization. Then, a machine learning model is trained against the training dataset with the selected features only. After that, we remove unwanted features from the training dataset, keeping only the most influential features. Finally, the trained model is evaluated against the modified test dataset. The proposed method for selecting features uses a metaheuristic algorithm to find the best way to improve the accuracy of classification. We use particle swarm optimization (PSO) as the optimizer. The reasons for using the PSO include its easy implementation, low memory requirement, and high speed of convergence <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_2c\">[23]</a>. PSO optimization follows the techniques that various groups of living beings, such as a flock of birds or a school of fish, follow to find their desired target in a search space. Their current directions of searching, the best individual results (so far), influence the movements of the birds in the flock, the best results found by all birds (so far), and a random perturbation. Each bird keeps tracking its own best solution. Then, it exchanges its position with other birds. The exchange of information among birds in a flock enables them to find the desired target. A single bird\u2019s search effort cannot achieve substantial progress in finding the target. However, the flock of birds can find the target. Next, we will describe the use of the PSO algorithm for selecting the best features of the CICAndMal2017 dataset to achieve the highest accuracy with lower computation complexity.</p><p>The PSO algorithm for the proposed feature selection is given in <a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Algorithm 1</a>. We use the common PSO proposed in <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c\">[24]</a>. The algorithm starts with a random population, where the population is the positions of a set of particles. Each particle presents a possible solution where a solution is the subset of features that meet some performance criteria most efficiently. The position is defined in a <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}$\n</tex-math></inline-formula>-dimensional space where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}$\n</tex-math></inline-formula> is the number of features. If the dataset consists of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}$\n</tex-math></inline-formula> number of features, the position of a particle will be presented using an <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}$\n</tex-math></inline-formula>-dimensional vector. Suppose that we consider <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> particles. Then, the population is presented by <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {S}$\n</tex-math></inline-formula>, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{i}$\n</tex-math></inline-formula> indicates the position of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle. That is, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {S}$\n</tex-math></inline-formula> is a matrix of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}\\times N_{f}$\n</tex-math></inline-formula>. The position shows a subset of features for training a machine learning model. The position of each particle is generated randomly and is independent of the positions of other particles. Each particle\u2019s position is generated following the uniform distribution. Afterward, the population is discretized. The lower and upper bounds of each coordinate of the position are \u20180\u2019 and \u20181\u2019, respectively. Then, each coordinate is rounded to its nearest integer. If a coordinate\u2019s value is more than 0.5, it is rounded to \u20181\u2019; otherwise, it is rounded to \u20180\u2019. In this way, the position of a particle is represented as a binary sequence. Repeating this procedure for all particles, we get a binary population where each row of the population matrix represents the position (a binary sequence) of a particle. The \u20180\u2019 coordinate of the position of the particle shows that the respective feature will be excluded from the dataset for training an ML model. However, \u20181\u2019 shows that the corresponding feature will be considered in training an ML model. For example, if <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}=4$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{1}=[{0 1 1 0}]$\n</tex-math></inline-formula>, where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$S_{1}$\n</tex-math></inline-formula> represents the position of the first particle, the first subset of features includes the second and the third features for training. In contrast, the first and fourth features are excluded from the dataset. Next, the velocity matrix, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {V}$\n</tex-math></inline-formula>, is generated randomly following the uniform distribution. It consists of the velocities of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> particles, with each particle having <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}$\n</tex-math></inline-formula> elements in each velocity vector, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$v_{i}$\n</tex-math></inline-formula>. We use the notation <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$v_{i}$\n</tex-math></inline-formula> to show a row of the matrix <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {V}$\n</tex-math></inline-formula>. Once the population and velocity matrices are initialized, we compute the fitness of each particle, where the following fitness represents the value of the fitness function (also known as the objective function).<disp-formula id=\"deqn2\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} F_{i}=qa_{i}+\\frac {1-q}{N_{f}^{sel,i}}\\tag{2}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} F_{i}=qa_{i}+\\frac {1-q}{N_{f}^{sel,i}}\\tag{2}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{i}$\n</tex-math></inline-formula> is the fitness of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$a_{i}$\n</tex-math></inline-formula> is the accuracy obtained due to the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}^{sel,i}$\n</tex-math></inline-formula> is the number of features selected in the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle. We use multi-objective optimization as we want to achieve a higher detection accuracy with a lower number of features. The parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> shows the weight we put on the above-mentioned two objectives. A higher value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> emphasizes accuracy in maximizing fitness, whereas a lower value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> emphasizes the number of selected features. To compute the fitness function, we must select a subset of features (in line 2). For each particle, we get a subset of features. Then, the selected features are separated from the dataset, and are used to train an ML classification algorithm. Then, the accuracy of the trained ML classifier is evaluated. In line 4, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$\\boldsymbol {N}$\n</tex-math></inline-formula> represents the set of features in the dataset. Next, we select the best fitness value for each particle (line 5). Since this is the initialization phase, the best fitness value of a particle is the fitness value computed in line 4. For the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> particles, we have <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> fitness value with a fitness value for each particle (calculated in line 4). We select the highest fitness (called the best global fitness value), <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F^{gb}$\n</tex-math></inline-formula>, in line 6. Then we find the position (called the best global particle), <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P^{gb}$\n</tex-math></inline-formula>, of the particle that provides the highest fitness. where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F_{i}$\n</tex-math></inline-formula> is the fitness of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$a_{i}$\n</tex-math></inline-formula> is the accuracy obtained due to the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle, and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{f}^{sel,i}$\n</tex-math></inline-formula> is the number of features selected in the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle. We use multi-objective optimization as we want to achieve a higher detection accuracy with a lower number of features. The parameter <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> shows the weight we put on the two objectives, as mentioned above. A higher value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> emphasizes accuracy in maximizing fitness, whereas a lower value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> emphasizes the number of selected features. To compute the fitness function, we must first select a subset of features (in line 2). For each particle, we get a subset of features. Then, the selected features are separated from the dataset, and are used to train an ML classification algorithm. We then evaluated the trained ML classifier for accuracy. In line 4, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> represents the set of features in the dataset.\n<div class=\"figure figure-full\" id=\"fig9\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi9-3227579-large.gif\" data-fig-id=\"fig9\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi9-3227579-small.gif\" alt=\"Algorithm 1: - Feature Selection Using PSO\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">Algorithm 1: </b><fig><p>Feature Selection Using PSO</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>Next, we select the best fitness value for each particle (line 5). Since this is the initialization phase, the best fitness value of a particle is the fitness value computed in line 4. For the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> particles, we have a <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$N_{p}$\n</tex-math></inline-formula> fitness value with a fitness value for each particle (calculated in line 4). Of them, we select the highest fitness (called the best global fitness value), <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F^{gb}$\n</tex-math></inline-formula>, value in line 6. Then we find the position (called the best global particle), <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P^{gb}$\n</tex-math></inline-formula>, of the particle that provides the highest fitness.</p><p>An iterative process begins when the global best-fitness value and particle are calculated. For each particle, the velocity vector, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$v_{i}$\n</tex-math></inline-formula>, is updated using the following equation:<disp-formula id=\"deqn3\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} v_{i}=wv_{i}+r_{p} \\left ({P_{i}^{pb}-S_{i}}\\right)+r_{g} \\left ({P_{i}^{gb}-S_{i}}\\right)\\tag{3}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} v_{i}=wv_{i}+r_{p} \\left ({P_{i}^{pb}-S_{i}}\\right)+r_{g} \\left ({P_{i}^{gb}-S_{i}}\\right)\\tag{3}\\end{equation*}\n</span></span></disp-formula> where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$w$\n</tex-math></inline-formula> is the weight of the inertia of a particle\u2019s movement, the higher value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$w$\n</tex-math></inline-formula> causes more exploration, whereas the lower value leads to more exploitation <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c\">[24]</a>. The notations <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$r_{p}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$r_{g}$\n</tex-math></inline-formula> are the random numbers between <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$[0,c_{p}]$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$[0,c_{g}]$\n</tex-math></inline-formula>, respectively. The notations <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{p}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$c_{g}$\n</tex-math></inline-formula> represent the acceleration coefficients toward the particle and global best positions, respectively. The acceleration coefficients give random forces in the respective direction to perturb the direction of the particle. The second term on the right side of <a ref-type=\"disp-formula\" anchor=\"deqn3\" href=\"#deqn3\" class=\"fulltext-link\">(3)</a> is the random weighted difference between the best position (so far), and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${i}^{th}$\n</tex-math></inline-formula> is the latest particle position. The larger difference leads to more exploration of the search space. A small value of this term causes the confinement of the particle at a local minimum. On the other hand, the third term of the right side of <a ref-type=\"disp-formula\" anchor=\"deqn3\" href=\"#deqn3\" class=\"fulltext-link\">(3)</a> is the weighted difference between the best position among all particles and the latest position of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$i^{th}$\n</tex-math></inline-formula> particle. The larger value of this term results in more exploitation. A balance between exploration and exploitation can cause a stable optimization process <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c\">[24]</a>. For this reason, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${c_{p}}$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${c_{g}}$\n</tex-math></inline-formula> can be assumed to be equal <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c\">[24]</a>. Then, the position of the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${i^{th}}$\n</tex-math></inline-formula> particle is updated by adding its velocity to its current position (line 11). Afterward, the fitness of the new position of the particle is computed. Then, the new fitness is compared with the particle\u2019s best fitness as well as the global best fitness (lines 12-18). If the new fitness is higher than the best fitness of the particle, the new fitness is considered the best fitness of the particle (line 14), and the new fitness that provides the position of the particle is considered the best position of the particle (line 15). Then, the new fitness of the particle is compared against the best fitness of the swarm of particles. If the new best fitness of the particle is higher than the global best of the swarm, the best fitness of the particle is considered as the global best of the swarm (17), and the position of the particle is considered as the closest position (so far) to the target (18). This procedure is performed by updating the velocity vector to update the best global position (if required) for each particle. When the operation is performed for all particles, a new iteration starts, and the above-mentioned procedure is followed. At the end of all iterations, the global best fitness, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$F^{gb}$\n</tex-math></inline-formula>, represents the best fitness value which can be achieved using the subset of features defined by the global best particle\u2019s position, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$P^{gb}$\n</tex-math></inline-formula>.</p></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION III.</div><h2>Experimental Results and Analysis</h2></div><p>In this section, we evaluate the performance of the proposed Android ransomware detection method. We use the decision tree classifier to classify traffic, whereas the PSO is used to optimize the system performance. The parameters of the proposed method are given in <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a>. The decision tree is implemented using the default parameters of scikit-learn. In this study, we consider two scenarios: Scenario I: binary classification between ransomware traffic and benign traffic, and scenario II: multiclass classification among 10 types of ransomware traffic and benign traffic.<div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nSimulation Parameters</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t2-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t2-3227579-small.gif\" alt=\"Table 2- &#10;Simulation Parameters\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>We present the proposed ransomware detection method for binary classification in the first case. In this case, the goal is to determine if there is ransomware in the traffic. Before detection, we use a PSO-based feature selection algorithm to select the most important features, improving the detection accuracy and providing a high detection rate. <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Table 3</a> shows the selected features. We perform experiments for three different weights, <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula>; the case <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q= 1$\n</tex-math></inline-formula> indicates that the emphasis is given to increasing the accuracy, and the number of features selected is completely ignored when calculating the objective function. In this case, the proposed method selects 26 features from 62 features, thereby reducing computational overhead by more than 50%. In the second case, we show the situation where <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=0.85$\n</tex-math></inline-formula>. In this case, we see that 13 features are selected. Even though the reduction in feature selection is considered in this case, accuracy is the most important thing. In the third case, the importance of the reduced number of features is increased. The decreased number of features selection policy selects only 8 features. The common features selected in all these three cases include F3, F5, F13, F17, F44, F49, F73, and F74. In multiclass classification, fewer features are selected (see <a ref-type=\"table\" anchor=\"table4\" class=\"fulltext-link\">Table 4</a>). The number of features selected for <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>, 0.85, and 0.7 is 23, 8, and 5, respectively. The common features in all three scenarios include F3, F5, F73, and F74. These four features are also common among all cases of binary and multiclass classification scenarios.<div class=\"figure figure-full table\" id=\"table3\"><div class=\"figcaption\"><b class=\"title\">TABLE 3 </b>\nSelected Features for Binary Classification</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t3-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t3-3227579-small.gif\" alt=\"Table 3- &#10;Selected Features for Binary Classification\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table4\"><div class=\"figcaption\"><b class=\"title\">TABLE 4 </b>\nSelected Features for Multiclass Classification</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t4-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t4-3227579-small.gif\" alt=\"Table 4- &#10;Selected Features for Multiclass Classification\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>We investigated the impact of the proposed method on the fitness function in <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Fig. 2</a>. We see that the value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> considerably impacts fitness. There is roughly a 0.1 difference in fitness for every 0.15 change in the value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula>. After the first iteration, the highest and the lowest fitness of 0.781 and 56 are obtained for <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula> and <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=0.7$\n</tex-math></inline-formula>, respectively. Fitness starts to increase after the first iteration. The improvement in the fitness value almost stops at about 10 iterations, showing its quick convergence speed. The final fitness values are 0.80, 0.69, and 0.595 for <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>, 0.85, and 0.70, respectively.\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi2-3227579-large.gif\" data-fig-id=\"fig2\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi2-3227579-small.gif\" alt=\"FIGURE 2. - Optimization of the fitness with respect to iteration for binary classification.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>Optimization of the fitness with respect to iteration for binary classification.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>The impact of the selection of features on the accuracy is shown in <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Fig. 3</a> for binary classification. It is evident that the accuracy improves significantly because of the proposed technique, and the value of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q$\n</tex-math></inline-formula> considerably impacts the accuracy. We obtain the highest accuracy when <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>. That is, the proposed method achieves the highest accuracy of 80.14% when the requirement of a reduced number of features is not imposed. The accuracy has to be compromised a bit by imposing the requirement. However, the sacrifice is only 0.47%. The accuracy of the values of <inline-formula id=\"\"><tex-math notation=\"LaTeX\">${q}$\n</tex-math></inline-formula> at 1, 0.85, and 0.70 are respectively 80.14%, 79.88%, and 79.68%. This little sacrifice (0.47%) of precision leads to a dramatic reduction in the number of features. It is noted that an accuracy of 80.14% can be obtained with a 58.06% reduction of the features, which signifies that sacrificing only 0.47% results in 87.1% feature shedding.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi3-3227579-large.gif\" data-fig-id=\"fig3\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi3-3227579-small.gif\" alt=\"FIGURE 3. - Illustration of the optimization of the accuracy with respect to the iteration for ransomware detection.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>Illustration of the optimization of the accuracy with respect to the iteration for ransomware detection.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>To investigate how the number of selected features is optimized, we can consider <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Fig. 4</a>. We can see that just after one iteration, the number of selected features is reduced by 41.93%, 46.77%, and 54.84% in the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$p=1$\n</tex-math></inline-formula>, 0.85, and 0.70 cases, respectively. Although the reduction in the number of features initially occurs rapidly, the number stays steady around the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{th}$\n</tex-math></inline-formula> iteration. Finally, the reduction in the number of features is 58.06% (26 features), 79.03% (13 features), and 87.1% (8 features), respectively, in the three cases.\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi4-3227579-large.gif\" data-fig-id=\"fig4\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi4-3227579-small.gif\" alt=\"FIGURE 4. - Optimization of the number of selected features with the iteration for ransomware detection.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>Optimization of the number of selected features with the iteration for ransomware detection.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>Next, we investigate the performance of the proposed method for ransomware family classification. There are 11 classes with 10 ransomware types and benign traffic. <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Fig. 5</a> shows the optimization of the fitness for several iterations. As is seen, the fitness function improves with iteration. The fitness values are 0.678, 0.596, and 0.53 in <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>, 0.85, and 0.70 cases, respectively. However, the fitness value is comparatively lower if we compare <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Fig. 5</a> with <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Fig. 2</a> (for binary classification). The reductions are 0.122, 0.094, and 0.065 for the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>, 0.85, and 0.70 cases, respectively. The reduction might be due to the higher number of classes. In multiclass classification, there exist 11 classes. The higher number of classes leads to more errors in the classification.\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi5-3227579-large.gif\" data-fig-id=\"fig5\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi5-3227579-small.gif\" alt=\"FIGURE 5. - Optimization of the fitness with respect to iteration for ransomware family classification.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>Optimization of the fitness with respect to iteration for ransomware family classification.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>The precision of the types of ransomware classification is shown in <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Fig. 6</a>. The accuracy ranges from 67.1% to 67.9%, which is 12%-13% less than the binary classification. In this scenario, we see that <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=0.85$\n</tex-math></inline-formula> gives the highest accuracy. A drop in the accuracy is observed for <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=0.70$\n</tex-math></inline-formula> in iteration 8. The decline in accuracy might be the reason for finding a smaller number of features in attaining a little more fitness. Since improving fitness optimization is the main objective of an optimization algorithm, when it encounters an opportunity to enhance fitness by reducing accuracy with a reduced number of features, it takes this path of optimization. However, we see an improvement in precision in the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$14^{th}$\n</tex-math></inline-formula> iteration, which leads to an accuracy of 67.06%. <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig. 7</a> shows the gradual reduction in the number of features. We see that the number of features reduced from 62 to 31, 35, and 29 after one algorithm iteration. The number of features becomes stable with a few iterations after the <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$10^{th}$\n</tex-math></inline-formula> iteration. Finally, the number of features selected are 26, 8, and 5, respectively, for <inline-formula id=\"\"><tex-math notation=\"LaTeX\">$q=1$\n</tex-math></inline-formula>, 0.85, and 0.7, thus reducing 58.06%, 87.1%, and 91.94% of the features. Comparing <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig. 7</a> with <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Fig. 4</a>, we can say that the multiclass classification of the ransomware can be done faster with the proposed method as this method can reduce the number of features in the multiclass classification compared to the binary classification.\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi6-3227579-large.gif\" data-fig-id=\"fig6\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi6-3227579-small.gif\" alt=\"FIGURE 6. - Illustration of the optimization of the accuracy with respect to the iteration for ransomware family classification.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p>Illustration of the optimization of the accuracy with respect to the iteration for ransomware family classification.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig7\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi7-3227579-large.gif\" data-fig-id=\"fig7\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi7-3227579-small.gif\" alt=\"FIGURE 7. - Optimization of the number of selected features with the iteration for ransomware family classification.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 7. </b><fig><p>Optimization of the number of selected features with the iteration for ransomware family classification.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>A performance comparison in terms of the accuracy of the proposed method with four prominent ML algorithms is shown in <a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Fig. 8</a>. We use random forest for binary classification in the proposed feature selection method experiment. In contrast, the decision tree for the multiclass classification as these two classifiers works best without feature selection. The proposed method outperforms all other methods in detecting ransomware (binary classification) and its classes (multiclass classification). In binary classification, the proposed method with random forest achieves 2.26% more accuracy than the random forest (RF) ensemble learning method. In <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_3\">[19]</a>, the ransomware detection accuracy is 69.5%, which is 12.08% less than our proposed method. The proposed method performs better than any other method in the detection of the types of ransomware. Whereas the proposed method provides 67.8% accuracy, the decision tree, which offers the best performance among other techniques, provides 64.1% accuracy. Thus, the improvement, in this case, is 3.7%. Although the XGBoost is an ensemble classifier, its performance is not even close to the proposed method.\n<div class=\"figure figure-full\" id=\"fig8\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi8-3227579-large.gif\" data-fig-id=\"fig8\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi8-3227579-small.gif\" alt=\"FIGURE 8. - Performance comparison of the proposed method with various methods.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 8. </b><fig><p>Performance comparison of the proposed method with various methods.</p></fig></div><p class=\"links\"><a href=\"/document/9976057/all-figures\" class=\"all\">Show All</a></p></div></p><p>We compare the performance of the proposed feature selection method with four benchmark feature selection methods: recursive feature elimination (RFE), Anova-F, Chi-square, and information gain. The decision tree is used as the classifier for all feature selection methods. We select the same number of features in all cases. The accuracy for various feature selection methods for ransomware classification is shown in <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">Table 5</a>. For 26 features, whereas the RFE obtains the highest accuracy of 77.27% among the benchmarks, the proposed method attains 2.87% higher accuracy than the RFE. The gains in accuracy for 13 and 8 features are 2.82% and 2.29%, respectively. In the classification of ransomware types (see <a ref-type=\"table\" anchor=\"table6\" class=\"fulltext-link\">Table 6</a>), the gains in accuracy for 23, 8, and 5 are 3.81%, 7.64%, and 10.59%, respectively. When comparing <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Tables 3</a> and <a ref-type=\"table\" anchor=\"table5\" class=\"fulltext-link\">5</a>, it is found that among the benchmarks, while the RFE method works best to select a higher number of features, the information gain performs best for a minimal number of features. In <a ref-type=\"table\" anchor=\"table7\" class=\"fulltext-link\">Table 7</a>, the performance of the proposed method is compared to that of the existing techniques. The proposed method outperforms the existing procedure for ransomware detection and ransomware types detection.<div class=\"figure figure-full table\" id=\"table5\"><div class=\"figcaption\"><b class=\"title\">TABLE 5 </b>\nComparison of the Proposed Method With Various Feature Selection Methods for Ransomware Detection [%]</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t5-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t5-3227579-small.gif\" alt=\"Table 5- &#10;Comparison of the Proposed Method With Various Feature Selection Methods for Ransomware Detection [%]\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table6\"><div class=\"figcaption\"><b class=\"title\">TABLE 6 </b>\nComparison of the Proposed Method With Various Feature Selection Methods for Types of Ransomware Detection [%]</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t6-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t6-3227579-small.gif\" alt=\"Table 6- &#10;Comparison of the Proposed Method With Various Feature Selection Methods for Types of Ransomware Detection [%]\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table7\"><div class=\"figcaption\"><b class=\"title\">TABLE 7 </b>\nComparison With Existing Methods [%]</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t7-3227579-large.gif\"><img src=\"/mediastore_new/IEEE/content/media/6287639/9668973/9976057/choi.t7-3227579-small.gif\" alt=\"Table 7- &#10;Comparison With Existing Methods [%]\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n\t\t                        SECTION IV.</div><h2>Conclusion</h2></div><p>In this paper, we proposed a method for detecting Android ransomware using machine learning. The core part of the method uses the nature-inspired optimization algorithm, PSO. In this method, we iteratively selected a subset of the available features to optimize the accuracy and computational overhead of the detection method. We exploited the traffic of the Android devices to train a machine learning classifier. We showed that the proposed method outperformed the conventional classifier regarding optimization variables throughout the experiments. It achieved up to 81.58% accuracy in detecting ransomware attacks. Furthermore, the types of ransomware attacks could be detected with up to 67.8% of accuracy compared to the conventional method. The computational overhead could be significantly reduced by shedding up to 91.94% of the features. The proposed optimization method convergence quickly (by around 10 iterations). Compared to the traditional feature selection methods, the proposed method attained up to 10.59% more accuracy for the same number of features. In this paper, we use the default parameter settings of various classifiers. However, in the future, we plan to employ optimization in two levels. In the first optimization level, we are interested in enhancing the hyperparameters of the classifier. In the second level, we aim to improve the precision of the ransomware detection system.</p></div>\n</div></div></response>\n"
}