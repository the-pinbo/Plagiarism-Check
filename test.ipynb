{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2022/9973293.json\n"
     ]
    }
   ],
   "source": [
    "for path in Path('./data/').rglob('*.json'):\n",
    "    print(path)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.json = json.load(open(path, encoding='utf-8'))\n",
    "        self.title = self.json['articleTitle']\n",
    "        self.number = self.json['articleNumber']\n",
    "        self.authors = self.json['authors']\n",
    "        self.abstract = self.json['abstract']\n",
    "        self.text = self._get_text()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.title}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.title}'\n",
    "\n",
    "    def _get_text(self):\n",
    "        text = self.abstract + \"\\n\" + \"\\n\".join([p.text for p in BeautifulSoup(self.json['xml'], 'lxml').find_all('p')])\n",
    "        return self._clean_text(text)\n",
    "\n",
    "    def _clean_text(text):\n",
    "        regex = r\"CCBY - IEEE.*|\\[\\d+\\]|\\$.*\\$|View Source.*|\\\\begin.*|FIGURE \\d+|Fig. \\d+|[^A-Za-z0-9^ ]|SECTION [A-Z]+|\\t\\t|\\n|Eq \\d+|  \"\n",
    "        regex_empty = r\" +\"\n",
    "        regex_eqns = r\"Eq \\d+|Lemma \\d+|section \\d+|section \\d+ \\d+|From \\d+|Eqs[^a-z^A-Z]+\"\n",
    "        result = re.sub(regex, \" \", text, 0, re.MULTILINE)\n",
    "        result = re.sub(regex_empty, \" \", result, 0, re.MULTILINE)\n",
    "        result = re.sub(regex_eqns, \"\", result, 0, re.MULTILINE).strip()\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.\n",
      "\n",
      "\t\t                        SECTION I.IntroductionWith our increasing reliance on mobile devices, people keep valuable information in their devices and online storage. The wicked people get lured by the potential access to confidential information mainly for illicit financial gain, and othe\n"
     ]
    }
   ],
   "source": [
    "print(papers[2].text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper.xml', 'w', encoding='utf-8') as f:\n",
    "    f.write(papers[0].json['xml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pinbo/Documents/WOC/Plagiarism-Check/.venv/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "soup = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher Information Matrix and its Application of Bipolar Activation Function Based Multilayer Perceptrons With General Gaussian Input\n"
     ]
    }
   ],
   "source": [
    "print(papers[0].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the widely used multilayer perceptrons (MLPs), there exist singularities in the parameter space where Fisher information matrix (FIM) degenerates on these subspaces. The singularities seriously influence the learning dynamics of MLPs which have attracted many researchers’ attentions. As FIM plays key role in investigating the singular learning dynamics of MLPs, it is very important to obtain t...\n"
     ]
    }
   ],
   "source": [
    "print(papers[0].abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As one of the most important subject in computer science, artificial intelligence has been developed fast in the last years and has been successfully applied in various areas and applications [1], [2], such as pattern recognition, computer vision, intelligence control etc [3], [4], [5]. For artificial intelligence, artificial neural networks play key roles in achieving such outstanding performance [6], [7]. Multilayer perceptrons (MLPs), which are typical feedforward neural networks, also have been widely applied in artificial intelligence [8], [9]. The main advantages of multilayer perceptrons are that they are easy to handle and can approximate any continuous function arbitrary well.\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p'):\n",
    "    print(p.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"CCBY - IEEE.*|\\[\\d+\\]|\\$.*\\$|View Source.*|\\\\begin.*|FIGURE \\d+|Fig. \\d+|[^A-Za-z0-9^ ]|SECTION [A-Z]+|\\t\\t|\\n|Eq \\d+|  \"\n",
    "\n",
    "regex_empty = r\" +\"\n",
    "regex_eqns = r\"Eq \\d+|Lemma \\d+|section \\d+|section \\d+ \\d+|From \\d+|Eqs[^a-z^A-Z]+\"\n",
    "\n",
    "test_str = papers[0].text\n",
    "\n",
    "result = re.sub(regex, \" \", test_str, 0, re.MULTILINE)\n",
    "result = re.sub(regex_empty, \" \", result, 0, re.MULTILINE).strip()\n",
    "result = re.sub(regex_eqns, \"\", result, 0, re.MULTILINE).strip()\n",
    "if result:\n",
    "    print (result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [Paper(path) for path in Path('./data/').rglob('*.json')]\n",
    "print(papers[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.txt','r') as f:\n",
    "    test_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = [paper.abstract for paper in papers] + [test_text]\n",
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beamforming, user scheduling and transmit power on existing interference management schemes in multi-cell mmWave networks have been independently controlled due to the high computational complexity of the problem. In this paper, we formulate a long-term utility maximization problem where beam activation, user scheduling and transmit power are incorporated in a single framework.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the widely used multilayer perceptrons (MLPs), there exist singularities in the parameter space where Fisher information matrix (FIM) degenerates on these subspaces. The singularities seriously influence the learning dynamics of MLPs which have attracted many researchers’ attentions. As FIM plays key role in investigating the singular learning dynamics of MLPs, it is very important to obtain t...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "term_freq_matrix=count_vect.fit_transform(data_set)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tf_idf_matrix = tfidf.fit_transform(term_freq_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 1171)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between 2 documents is:  0.05819476225102631\n"
     ]
    }
   ],
   "source": [
    "similarity=cosine_similarity(tf_idf_matrix[0], tf_idf_matrix[50])\n",
    "print('The similarity between 2 documents is: ',similarity[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9973293'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0].json['articleNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between text and paper 9973293 documents is:  5.819476225102631 %\n",
      "The similarity between text and paper 9973315 documents is:  11.416628339836473 %\n",
      "The similarity between text and paper 9976057 documents is:  11.886337702160521 %\n",
      "The similarity between text and paper 9973235 documents is:  96.87320554765432 %\n",
      "The similarity between text and paper 9973236 documents is:  8.73169377014394 %\n",
      "The similarity between text and paper 9973237 documents is:  3.353209925704058 %\n",
      "The similarity between text and paper 9973238 documents is:  4.381576733228687 %\n",
      "The similarity between text and paper 9973239 documents is:  5.700446612519094 %\n",
      "The similarity between text and paper 9973241 documents is:  6.340685401795887 %\n",
      "The similarity between text and paper 9973243 documents is:  11.731553880252788 %\n",
      "The similarity between text and paper 9973244 documents is:  5.577007547929773 %\n",
      "The similarity between text and paper 9973245 documents is:  7.780611339087515 %\n",
      "The similarity between text and paper 9973290 documents is:  5.771779989617764 %\n",
      "The similarity between text and paper 9978293 documents is:  3.809994095665499 %\n",
      "The similarity between text and paper 9978604 documents is:  3.154822809731719 %\n",
      "The similarity between text and paper 9978612 documents is:  5.353692417335316 %\n",
      "The similarity between text and paper 9978613 documents is:  3.2120141193347322 %\n",
      "The similarity between text and paper 9978623 documents is:  7.759197902884518 %\n",
      "The similarity between text and paper 9978631 documents is:  4.497587301844839 %\n",
      "The similarity between text and paper 9978635 documents is:  4.844401993721192 %\n",
      "The similarity between text and paper 9975322 documents is:  7.937458112370063 %\n",
      "The similarity between text and paper 9975326 documents is:  6.577883953091244 %\n",
      "The similarity between text and paper 9975798 documents is:  5.498029981178605 %\n",
      "The similarity between text and paper 9975799 documents is:  3.437236947823673 %\n",
      "The similarity between text and paper 9976036 documents is:  8.083545232191668 %\n",
      "The similarity between text and paper 9976049 documents is:  9.952927080166491 %\n",
      "The similarity between text and paper 9976053 documents is:  4.548477667855021 %\n",
      "The similarity between text and paper 9976054 documents is:  3.8099093601106317 %\n",
      "The similarity between text and paper 9976056 documents is:  5.437072855037252 %\n",
      "The similarity between text and paper 9973316 documents is:  4.4856757170356785 %\n",
      "The similarity between text and paper 9973317 documents is:  4.711409246515408 %\n",
      "The similarity between text and paper 9975279 documents is:  5.264681935957354 %\n",
      "The similarity between text and paper 9975290 documents is:  8.855062354553493 %\n",
      "The similarity between text and paper 9975294 documents is:  8.777287723202253 %\n",
      "The similarity between text and paper 9975297 documents is:  4.642373688985192 %\n",
      "The similarity between text and paper 9975313 documents is:  5.77154055176468 %\n",
      "The similarity between text and paper 9975314 documents is:  10.316842570419345 %\n",
      "The similarity between text and paper 9975317 documents is:  5.059534698654974 %\n",
      "The similarity between text and paper 9975319 documents is:  10.208840176273329 %\n",
      "The similarity between text and paper 9973294 documents is:  8.815774381260185 %\n",
      "The similarity between text and paper 9973295 documents is:  6.198784179308351 %\n",
      "The similarity between text and paper 9973300 documents is:  9.348144428548126 %\n",
      "The similarity between text and paper 9973304 documents is:  12.707635177224935 %\n",
      "The similarity between text and paper 9973307 documents is:  11.030266982876636 %\n",
      "The similarity between text and paper 9973308 documents is:  3.1975193666209623 %\n",
      "The similarity between text and paper 9973309 documents is:  6.124421751354717 %\n",
      "The similarity between text and paper 9973310 documents is:  6.068198651212069 %\n",
      "The similarity between text and paper 9973311 documents is:  6.003727652403302 %\n",
      "The similarity between text and paper 9973312 documents is:  8.083875055070898 %\n",
      "The similarity between text and paper 9973314 documents is:  1.6953425184641662 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_set)-1):\n",
    "    similarity = cosine_similarity(tf_idf_matrix[len(data_set)-1], tf_idf_matrix[i])\n",
    "    paper_number = papers[i].json['articleNumber']\n",
    "    print(f'The similarity between text and paper {paper_number} documents is: ',similarity[0][0]*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bf7e0b0143500d177395d33944895b89f60a685ffd080af28fb1437d9cbe83c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
